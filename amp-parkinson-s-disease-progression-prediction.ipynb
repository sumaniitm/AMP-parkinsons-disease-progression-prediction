{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc3cf935",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-03-25T13:51:41.269932Z",
     "iopub.status.busy": "2023-03-25T13:51:41.268695Z",
     "iopub.status.idle": "2023-03-25T13:51:42.522712Z",
     "shell.execute_reply": "2023-03-25T13:51:42.520761Z"
    },
    "papermill": {
     "duration": 1.268553,
     "end_time": "2023-03-25T13:51:42.527267",
     "exception": false,
     "start_time": "2023-03-25T13:51:41.258714",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/amp-parkinsons-disease-progression-prediction/train_proteins.csv\n",
      "/kaggle/input/amp-parkinsons-disease-progression-prediction/train_clinical_data.csv\n",
      "/kaggle/input/amp-parkinsons-disease-progression-prediction/public_timeseries_testing_util.py\n",
      "/kaggle/input/amp-parkinsons-disease-progression-prediction/supplemental_clinical_data.csv\n",
      "/kaggle/input/amp-parkinsons-disease-progression-prediction/train_peptides.csv\n",
      "/kaggle/input/amp-parkinsons-disease-progression-prediction/amp_pd_peptide/competition.cpython-37m-x86_64-linux-gnu.so\n",
      "/kaggle/input/amp-parkinsons-disease-progression-prediction/amp_pd_peptide/__init__.py\n",
      "/kaggle/input/amp-parkinsons-disease-progression-prediction/example_test_files/sample_submission.csv\n",
      "/kaggle/input/amp-parkinsons-disease-progression-prediction/example_test_files/test_proteins.csv\n",
      "/kaggle/input/amp-parkinsons-disease-progression-prediction/example_test_files/test_peptides.csv\n",
      "/kaggle/input/amp-parkinsons-disease-progression-prediction/example_test_files/test.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "import gc\n",
    "from pandas.plotting import scatter_matrix\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d23c2d",
   "metadata": {
    "papermill": {
     "duration": 0.006197,
     "end_time": "2023-03-25T13:51:42.539843",
     "exception": false,
     "start_time": "2023-03-25T13:51:42.533646",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "* #### Get the relevant training datasets and combine them to form the full training set with Proteins and Peptides\n",
    "* #### Remove the NaNs from the UPDRS test scores, using the mean from within the same group of UPDRS test scores, e.g. NaNs in updrs_4 are filled with mean of updrs_4\n",
    "* #### Create new mean and median based features and get rid of Proteins Expressions (NPX) and Peptide Abundance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96f17d72",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-25T13:51:42.553739Z",
     "iopub.status.busy": "2023-03-25T13:51:42.553272Z",
     "iopub.status.idle": "2023-03-25T13:51:46.052428Z",
     "shell.execute_reply": "2023-03-25T13:51:46.050918Z"
    },
    "papermill": {
     "duration": 3.509865,
     "end_time": "2023-03-25T13:51:46.055519",
     "exception": false,
     "start_time": "2023-03-25T13:51:42.545654",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>visit_id</th>\n",
       "      <th>visit_month</th>\n",
       "      <th>npx_mean</th>\n",
       "      <th>npx_median</th>\n",
       "      <th>peptide_mean</th>\n",
       "      <th>peptide_median</th>\n",
       "      <th>updrs_1</th>\n",
       "      <th>updrs_2</th>\n",
       "      <th>updrs_3</th>\n",
       "      <th>updrs_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>55_0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.028789e+07</td>\n",
       "      <td>1221530.0</td>\n",
       "      <td>748153.907014</td>\n",
       "      <td>93134.80</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>931</td>\n",
       "      <td>1517_0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.579576e+07</td>\n",
       "      <td>897182.0</td>\n",
       "      <td>618823.150490</td>\n",
       "      <td>65253.60</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1833</td>\n",
       "      <td>1923_0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.889800e+07</td>\n",
       "      <td>1299230.0</td>\n",
       "      <td>763459.201459</td>\n",
       "      <td>92280.90</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2710</td>\n",
       "      <td>2660_0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.298973e+07</td>\n",
       "      <td>1078570.0</td>\n",
       "      <td>532250.381374</td>\n",
       "      <td>73461.05</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3620</td>\n",
       "      <td>3636_0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.367422e+07</td>\n",
       "      <td>776581.0</td>\n",
       "      <td>501743.931250</td>\n",
       "      <td>54660.20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4495</td>\n",
       "      <td>3863_0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.279134e+07</td>\n",
       "      <td>885864.0</td>\n",
       "      <td>806928.584862</td>\n",
       "      <td>78719.90</td>\n",
       "      <td>8.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5291</td>\n",
       "      <td>4161_0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.647734e+07</td>\n",
       "      <td>1067620.0</td>\n",
       "      <td>699803.391029</td>\n",
       "      <td>77037.80</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6191</td>\n",
       "      <td>4172_0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.729472e+07</td>\n",
       "      <td>874171.0</td>\n",
       "      <td>620558.476752</td>\n",
       "      <td>68208.05</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7115</td>\n",
       "      <td>5027_0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.281632e+07</td>\n",
       "      <td>1134880.0</td>\n",
       "      <td>764893.568584</td>\n",
       "      <td>71828.35</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8025</td>\n",
       "      <td>5178_0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.815310e+07</td>\n",
       "      <td>998682.0</td>\n",
       "      <td>689200.799757</td>\n",
       "      <td>79225.50</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index visit_id  visit_month      npx_mean  npx_median   peptide_mean  \\\n",
       "0      0     55_0            0  2.028789e+07   1221530.0  748153.907014   \n",
       "1    931   1517_0            0  1.579576e+07    897182.0  618823.150490   \n",
       "2   1833   1923_0            0  1.889800e+07   1299230.0  763459.201459   \n",
       "3   2710   2660_0            0  1.298973e+07   1078570.0  532250.381374   \n",
       "4   3620   3636_0            0  1.367422e+07    776581.0  501743.931250   \n",
       "5   4495   3863_0            0  2.279134e+07    885864.0  806928.584862   \n",
       "6   5291   4161_0            0  1.647734e+07   1067620.0  699803.391029   \n",
       "7   6191   4172_0            0  1.729472e+07    874171.0  620558.476752   \n",
       "8   7115   5027_0            0  2.281632e+07   1134880.0  764893.568584   \n",
       "9   8025   5178_0            0  1.815310e+07    998682.0  689200.799757   \n",
       "\n",
       "   peptide_median  updrs_1  updrs_2  updrs_3  updrs_4  \n",
       "0        93134.80     10.0      6.0     15.0      2.0  \n",
       "1        65253.60     11.0      6.0     25.0      5.0  \n",
       "2        92280.90      2.0      0.0      0.0      2.0  \n",
       "3        73461.05      2.0      0.0      0.0      2.0  \n",
       "4        54660.20      1.0      2.0      9.0      2.0  \n",
       "5        78719.90      8.0     13.0     36.0      4.0  \n",
       "6        77037.80      6.0      1.0      0.0      2.0  \n",
       "7        68208.05      2.0      0.0      0.0      2.0  \n",
       "8        71828.35      1.0      0.0      0.0      2.0  \n",
       "9        79225.50      9.0      1.0      3.0      2.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_proteins_df = pd.read_csv('/kaggle/input/amp-parkinsons-disease-progression-prediction/train_proteins.csv')\n",
    "#print(train_proteins_df.shape)\n",
    "#print(train_proteins_df.memory_usage(deep=True).sum()/1024/1024, \" MBs\")\n",
    "#train_proteins_df.head(10)\n",
    "\n",
    "train_peptides_df = pd.read_csv('/kaggle/input/amp-parkinsons-disease-progression-prediction/train_peptides.csv')\n",
    "#print(train_peptides_df.shape)\n",
    "#print(train_peptides_df.memory_usage(deep=True).sum()/1024/1024, \" MBs\")\n",
    "#train_peptides_df.head(10)\n",
    "\n",
    "pro_pep_join = pd.merge(train_proteins_df, train_peptides_df, on=['patient_id','visit_id','visit_month','UniProt'], how='inner')\n",
    "\n",
    "del train_proteins_df, train_peptides_df\n",
    "gc.collect()\n",
    "\n",
    "train_clinical_data_df = pd.read_csv('/kaggle/input/amp-parkinsons-disease-progression-prediction/train_clinical_data.csv')\n",
    "#print(train_clinical_data_df.shape)\n",
    "#print(train_clinical_data_df.memory_usage(deep=True).sum()/1024/1024, \" MBs\")\n",
    "\n",
    "merged_data = pd.merge(pro_pep_join, train_clinical_data_df, on=['patient_id','visit_id','visit_month'], how='inner')\n",
    "\n",
    "del pro_pep_join, train_clinical_data_df\n",
    "gc.collect()\n",
    "\n",
    "full_training_data = pd.DataFrame()\n",
    "\n",
    "for i in [0,6,12,24]:\n",
    "    temp = merged_data[merged_data['visit_month']==i]\n",
    "    full_training_data = full_training_data.append(temp)\n",
    "\n",
    "#print(full_training_data.head(10))\n",
    "    \n",
    "full_training_data = full_training_data.drop(columns=['UniProt','Peptide','upd23b_clinical_state_on_medication','patient_id'])\n",
    "\n",
    "\"\"\"full_training_data_melted = full_training_data.melt(id_vars=['visit_id','visit_month','NPX','PeptideAbundance']\n",
    "                                                    , value_vars=['updrs_1','updrs_2','updrs_3','updrs_4'],var_name='updrs_test', value_name='updrs_test_score')\"\"\"\n",
    "\n",
    "## list_of_updrs_tests = full_training_data_melted.updrs_test.unique()\n",
    "list_of_updrs_tests = ['updrs_1','updrs_2','updrs_3','updrs_4']\n",
    "\n",
    "\"\"\"temp_df = full_training_data_melted.groupby(['updrs_test']).agg(visit_month_per_patient=('visit_id', 'count')\n",
    "                                                      , mean_updrs_test_score=('updrs_test_score', 'mean') ).reset_index(level=['updrs_test'])\"\"\"\n",
    "\n",
    "for i in range(len(list_of_updrs_tests)):\n",
    "    #print(list_of_updrs_tests[i])\n",
    "    #updrs_test_mean = full_training_data[list_of_updrs_tests[i]].mean().round(decimals = 0)\n",
    "    #print(updrs_test_mean)\n",
    "    #full_training_data[list_of_updrs_tests[i]].fillna({list_of_updrs_tests[i]:updrs_test_mean}, inplace=True)\n",
    "    full_training_data[list_of_updrs_tests[i]].fillna(full_training_data[list_of_updrs_tests[i]].mean().round(decimals = 0), inplace=True)\n",
    "\n",
    "#full_training_data[list_of_updrs_tests[i]].fillna(full_training_data['updrs_4'].mean(), inplace=True)\n",
    "#full_training_data.head(10)\n",
    "new_features = full_training_data.groupby(['visit_id','visit_month']).agg(npx_mean=('NPX', 'mean'), npx_median=('NPX', 'median')\n",
    "                                                                          , peptide_mean=('PeptideAbundance', 'mean'), peptide_median=('PeptideAbundance', 'median')\n",
    "                                                          ).reset_index(level=['visit_id','visit_month'])\n",
    "\n",
    "full_training_data = pd.merge(full_training_data, new_features, on=['visit_id','visit_month'], how='inner')\n",
    "full_training_data = full_training_data.drop(columns=['NPX','PeptideAbundance'])\n",
    "full_training_data = full_training_data.drop_duplicates(keep='first')\n",
    "full_training_data = full_training_data[['visit_id','visit_month','npx_mean','npx_median','peptide_mean','peptide_median','updrs_1','updrs_2','updrs_3','updrs_4']]\n",
    "\n",
    "full_training_data = full_training_data.reset_index()\n",
    "#print(full_training_data.shape)\n",
    "full_training_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e59f49",
   "metadata": {
    "papermill": {
     "duration": 0.005785,
     "end_time": "2023-03-25T13:51:46.067391",
     "exception": false,
     "start_time": "2023-03-25T13:51:46.061606",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Check for NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5390a1c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-25T13:51:46.081798Z",
     "iopub.status.busy": "2023-03-25T13:51:46.081342Z",
     "iopub.status.idle": "2023-03-25T13:51:46.093325Z",
     "shell.execute_reply": "2023-03-25T13:51:46.091848Z"
    },
    "papermill": {
     "duration": 0.022852,
     "end_time": "2023-03-25T13:51:46.096372",
     "exception": false,
     "start_time": "2023-03-25T13:51:46.073520",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index             0\n",
       "visit_id          0\n",
       "visit_month       0\n",
       "npx_mean          0\n",
       "npx_median        0\n",
       "peptide_mean      0\n",
       "peptide_median    0\n",
       "updrs_1           0\n",
       "updrs_2           0\n",
       "updrs_3           0\n",
       "updrs_4           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_training_data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441d34c7",
   "metadata": {
    "papermill": {
     "duration": 0.005883,
     "end_time": "2023-03-25T13:51:46.108361",
     "exception": false,
     "start_time": "2023-03-25T13:51:46.102478",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### We will attempt to train one model each for each of the UPDRS tests. To do that, we will also proceed to create a train-test split on the Training dataset specific to each of the UPDRS test, to test out the accuracy of the developed models\n",
    "#### We will store all the models in a dictionary\n",
    "#### The following cells (except the declaration of the model dict) will be repeated for all UPDRS tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b88dc7a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-25T13:51:46.123370Z",
     "iopub.status.busy": "2023-03-25T13:51:46.122616Z",
     "iopub.status.idle": "2023-03-25T13:51:46.246117Z",
     "shell.execute_reply": "2023-03-25T13:51:46.244165Z"
    },
    "papermill": {
     "duration": 0.135779,
     "end_time": "2023-03-25T13:51:46.250203",
     "exception": false,
     "start_time": "2023-03-25T13:51:46.114424",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(505, 8)\n",
      "(127, 8)\n",
      "{'updrs_1': LinearRegression()}\n",
      "(505, 8)\n",
      "(127, 8)\n",
      "{'updrs_1': LinearRegression(), 'updrs_2': LinearRegression()}\n",
      "(505, 8)\n",
      "(127, 8)\n",
      "{'updrs_1': LinearRegression(), 'updrs_2': LinearRegression(), 'updrs_3': LinearRegression()}\n",
      "(505, 8)\n",
      "(127, 8)\n",
      "{'updrs_1': LinearRegression(), 'updrs_2': LinearRegression(), 'updrs_3': LinearRegression(), 'updrs_4': LinearRegression()}\n"
     ]
    }
   ],
   "source": [
    "model_dict = {}\n",
    "\n",
    "for i in [1,2,3,4]:\n",
    "    if (i == 1) | (i == 2):\n",
    "        full_training_data['updrs_'+str(i)+'_category'] = pd.cut(full_training_data['updrs_'+str(i)],bins=[-np.inf, 15., np.inf],labels=[1,2])\n",
    "    elif i == 3:\n",
    "        full_training_data['updrs_'+str(i)+'_category'] = pd.cut(full_training_data['updrs_'+str(i)],bins=[-np.inf, 20., 40., np.inf],labels=[1,2,3])\n",
    "    else:\n",
    "        full_training_data['updrs_'+str(i)+'_category'] = pd.cut(full_training_data['updrs_'+str(i)],bins=[-np.inf, 7.5, np.inf],labels=[1,2])\n",
    "        \n",
    "    split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "    for train_index, test_index in split.split(full_training_data, full_training_data['updrs_'+str(i)+'_category']):\n",
    "        strat_train_set = full_training_data.loc[train_index]\n",
    "        strat_test_set = full_training_data.loc[test_index]\n",
    "        \n",
    "    if i == 1:\n",
    "        strat_train_set = strat_train_set.drop(columns=['updrs_1_category'])\n",
    "        strat_test_set = strat_test_set.drop(columns=['updrs_1_category'])\n",
    "    elif i == 2:\n",
    "        strat_train_set = strat_train_set.drop(columns=['updrs_1_category','updrs_2_category'])\n",
    "        strat_test_set = strat_test_set.drop(columns=['updrs_1_category','updrs_2_category'])\n",
    "    elif i == 3:\n",
    "        strat_train_set = strat_train_set.drop(columns=['updrs_1_category','updrs_2_category','updrs_3_category'])\n",
    "        strat_test_set = strat_test_set.drop(columns=['updrs_1_category','updrs_2_category','updrs_3_category'])\n",
    "    else:\n",
    "        strat_train_set = strat_train_set.drop(columns=['updrs_1_category','updrs_2_category','updrs_3_category','updrs_4_category'])\n",
    "        strat_test_set = strat_test_set.drop(columns=['updrs_1_category','updrs_2_category','updrs_3_category','updrs_4_category'])\n",
    "    \n",
    "    strat_train_set_wo_labels = strat_train_set.drop(columns=['updrs_1','updrs_2','updrs_3','updrs_4','index'])\n",
    "    strat_train_set_labels = strat_train_set['updrs_'+str(i)].copy()\n",
    "    strat_train_set_numeric = strat_train_set_wo_labels.drop(columns=['visit_id','visit_month'])\n",
    "    strat_train_set_cat = strat_train_set_wo_labels[['visit_month']]\n",
    "\n",
    "    strat_test_set_wo_labels = strat_test_set.drop(columns=['updrs_1','updrs_2','updrs_3','updrs_4','index'])\n",
    "    strat_test_set_labels = strat_test_set['updrs_'+str(i)].copy()\n",
    "    \n",
    "    numeric_pipeline = Pipeline([\n",
    "        ('standard_scaler', StandardScaler())\n",
    "    ])\n",
    "\n",
    "    numeric_attributes = list(strat_train_set_numeric)\n",
    "    categorical_attributes = list(strat_train_set_cat)\n",
    "\n",
    "    full_pipeline = ColumnTransformer([\n",
    "        ('num', numeric_pipeline, numeric_attributes),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_attributes)\n",
    "    ])\n",
    "\n",
    "    strat_train_set_prepared = full_pipeline.fit_transform(strat_train_set_wo_labels)\n",
    "    print(strat_train_set_prepared.shape)\n",
    "    strat_test_set_prepared = full_pipeline.transform(strat_test_set_wo_labels)\n",
    "    print(strat_test_set_prepared.shape)\n",
    "    \n",
    "    lin_reg = LinearRegression()\n",
    "\n",
    "    model_dict['updrs_'+str(i)] = lin_reg.fit(strat_train_set_prepared, strat_train_set_labels)\n",
    "    print(model_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eeeb314",
   "metadata": {
    "papermill": {
     "duration": 0.005964,
     "end_time": "2023-03-25T13:51:46.262652",
     "exception": false,
     "start_time": "2023-03-25T13:51:46.256688",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### The commands below are for debugging only, these were used to determine the bins corresponding to the train-test split specific to UPDRS tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1620cb85",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-25T13:51:46.277738Z",
     "iopub.status.busy": "2023-03-25T13:51:46.277287Z",
     "iopub.status.idle": "2023-03-25T13:51:46.282315Z",
     "shell.execute_reply": "2023-03-25T13:51:46.280916Z"
    },
    "papermill": {
     "duration": 0.015789,
     "end_time": "2023-03-25T13:51:46.284869",
     "exception": false,
     "start_time": "2023-03-25T13:51:46.269080",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#full_training_data_melted[['updrs_test_score','PeptideAbundance','NPX','group_key']].corr()\n",
    "#full_training_data[['updrs_1','updrs_2','updrs_3','updrs_4']].hist(figsize=(20,15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "039f5638",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-25T13:51:46.300534Z",
     "iopub.status.busy": "2023-03-25T13:51:46.299045Z",
     "iopub.status.idle": "2023-03-25T13:51:46.309056Z",
     "shell.execute_reply": "2023-03-25T13:51:46.307644Z"
    },
    "papermill": {
     "duration": 0.021087,
     "end_time": "2023-03-25T13:51:46.312146",
     "exception": false,
     "start_time": "2023-03-25T13:51:46.291059",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"full_training_data['updrs_2_category'] = pd.cut(full_training_data['updrs_2'],\\n                                                          bins=[-np.inf, 15., np.inf],\\n                                                          labels=[1,2])\\n\\nfull_training_data['updrs_3_category'] = pd.cut(full_training_data['updrs_3'],\\n                                                          bins=[-np.inf, 20., 40., np.inf],\\n                                                          labels=[1,2,3])\\n\\nfull_training_data['updrs_4_category'] = pd.cut(full_training_data['updrs_4'],\\n                                                          bins=[-np.inf, 7.5, np.inf],\\n                                                          labels=[1,2])\\n\\nfull_training_data['updrs_4_category'].hist()\\n\\nfull_training_data['updrs_4_category'].unique()\\nsplit = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\\nfor train_index, test_index in split.split(full_training_data, full_training_data['updrs_4_category']):\\n    strat_train_set = full_training_data.loc[train_index]\\n    strat_test_set = full_training_data.loc[test_index]\\n    \\nprint(strat_test_set['updrs_4_category'].value_counts()/len(strat_test_set))\\nprint(strat_train_set['updrs_4_category'].value_counts()/len(strat_train_set))\\n\\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"full_training_data['updrs_2_category'] = pd.cut(full_training_data['updrs_2'],\n",
    "                                                          bins=[-np.inf, 15., np.inf],\n",
    "                                                          labels=[1,2])\n",
    "\n",
    "full_training_data['updrs_3_category'] = pd.cut(full_training_data['updrs_3'],\n",
    "                                                          bins=[-np.inf, 20., 40., np.inf],\n",
    "                                                          labels=[1,2,3])\n",
    "\n",
    "full_training_data['updrs_4_category'] = pd.cut(full_training_data['updrs_4'],\n",
    "                                                          bins=[-np.inf, 7.5, np.inf],\n",
    "                                                          labels=[1,2])\n",
    "\n",
    "full_training_data['updrs_4_category'].hist()\n",
    "\n",
    "full_training_data['updrs_4_category'].unique()\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "for train_index, test_index in split.split(full_training_data, full_training_data['updrs_4_category']):\n",
    "    strat_train_set = full_training_data.loc[train_index]\n",
    "    strat_test_set = full_training_data.loc[test_index]\n",
    "    \n",
    "print(strat_test_set['updrs_4_category'].value_counts()/len(strat_test_set))\n",
    "print(strat_train_set['updrs_4_category'].value_counts()/len(strat_train_set))\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11125d3d",
   "metadata": {
    "papermill": {
     "duration": 0.006141,
     "end_time": "2023-03-25T13:51:46.325494",
     "exception": false,
     "start_time": "2023-03-25T13:51:46.319353",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Testing the RMSE\n",
    "#### RMSE <= 0.75 : Very good accuracy | 0.75 < RMSE <= 1.0 : Good accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291ced16",
   "metadata": {
    "papermill": {
     "duration": 0.006536,
     "end_time": "2023-03-25T13:51:46.338533",
     "exception": false,
     "start_time": "2023-03-25T13:51:46.331997",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### First on train data (train split from the full training dataset)\n",
    "#### 2nd on test data (test split from the full training dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0b24a2e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-25T13:51:46.354297Z",
     "iopub.status.busy": "2023-03-25T13:51:46.353791Z",
     "iopub.status.idle": "2023-03-25T13:51:46.361917Z",
     "shell.execute_reply": "2023-03-25T13:51:46.360510Z"
    },
    "papermill": {
     "duration": 0.019138,
     "end_time": "2023-03-25T13:51:46.364513",
     "exception": false,
     "start_time": "2023-03-25T13:51:46.345375",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"train_df_predictions = lin_reg_model_updrs_4.predict(strat_train_set_prepared)\\nmse = mean_squared_error(strat_train_set_labels, train_df_predictions)\\nrmse = np.sqrt(mse)\\nprint(rmse)\\n\\ntest_df_predictions = lin_reg_model_updrs_4.predict(strat_test_set_prepared)\\nmse = mean_squared_error(strat_test_set_labels, test_df_predictions)\\nrmse = np.sqrt(mse)\\nprint(rmse)\\n\\nmodel_dict['updrs_4'] = lin_reg_model_updrs_4\\nmodel_dict\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"train_df_predictions = lin_reg_model_updrs_4.predict(strat_train_set_prepared)\n",
    "mse = mean_squared_error(strat_train_set_labels, train_df_predictions)\n",
    "rmse = np.sqrt(mse)\n",
    "print(rmse)\n",
    "\n",
    "test_df_predictions = lin_reg_model_updrs_4.predict(strat_test_set_prepared)\n",
    "mse = mean_squared_error(strat_test_set_labels, test_df_predictions)\n",
    "rmse = np.sqrt(mse)\n",
    "print(rmse)\n",
    "\n",
    "model_dict['updrs_4'] = lin_reg_model_updrs_4\n",
    "model_dict\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb1bb6ec",
   "metadata": {
    "papermill": {
     "duration": 0.007251,
     "end_time": "2023-03-25T13:51:46.378270",
     "exception": false,
     "start_time": "2023-03-25T13:51:46.371019",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### The below cell is only for debugging the function get_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a8df698",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-25T13:51:46.393687Z",
     "iopub.status.busy": "2023-03-25T13:51:46.392944Z",
     "iopub.status.idle": "2023-03-25T13:51:46.402723Z",
     "shell.execute_reply": "2023-03-25T13:51:46.401435Z"
    },
    "papermill": {
     "duration": 0.020646,
     "end_time": "2023-03-25T13:51:46.405317",
     "exception": false,
     "start_time": "2023-03-25T13:51:46.384671",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"df_proteins = pd.read_csv('/kaggle/input/amp-parkinsons-disease-progression-prediction/example_test_files/test_proteins.csv')\\nprint(df_proteins.shape)\\n\\ndf_peptides = pd.read_csv('/kaggle/input/amp-parkinsons-disease-progression-prediction/example_test_files/test_peptides.csv')\\nprint(df_peptides.shape)\\n\\npro_pep_join = pd.merge(df_proteins, df_peptides, on=['patient_id','visit_id','visit_month','UniProt'], how='inner')\\ndel df_proteins, df_peptides\\ngc.collect()\\n\\nfull_test_data = pd.DataFrame()\\n\\nfor i in [0,6,12,24]:\\n    temp = pro_pep_join[pro_pep_join['visit_month']==i]\\n    full_test_data = full_test_data.append(temp)\\n\\nfull_test_data = full_test_data.drop(columns=['UniProt','Peptide','patient_id','group_key_x','group_key_y'])\\n\\nlist_of_updrs_tests = ['updrs_1','updrs_2','updrs_3','updrs_4']\\n    \\nnew_features = full_test_data.groupby(['visit_id','visit_month']).agg(npx_mean=('NPX', 'mean'), npx_median=('NPX', 'median')\\n                                                                          , peptide_mean=('PeptideAbundance', 'mean'), peptide_median=('PeptideAbundance', 'median')\\n                                                          ).reset_index(level=['visit_id','visit_month'])\\n\\nfull_test_data = pd.merge(full_test_data, new_features, on=['visit_id','visit_month'], how='inner')\\nfull_test_data = full_test_data.drop(columns=['NPX','PeptideAbundance'])\\nfull_test_data = full_test_data.drop_duplicates(keep='first')\\nfull_test_data = full_test_data[['visit_id','visit_month','npx_mean','npx_median','peptide_mean','peptide_median']]\\n\\nfull_test_data = full_test_data.reset_index()\\nfull_test_data = full_test_data.drop(columns=['index'])\\n\\ndf_prepared = full_pipeline.transform(full_test_data)\\nprint(df_prepared.shape)\\n\\nfor u in list_of_updrs_tests:\\n    full_test_data['result_' + str(u)] = pd.DataFrame(model_dict[u].predict(df_prepared),columns=['rating']).round(decimals=0)\\n    \\nresult = pd.DataFrame()\\n\\nfor m in [0, 6, 12, 24]:\\n    for u in [1, 2, 3, 4]:\\n        temp = full_test_data[['visit_id', 'result_updrs_' + str(u)]]\\n        temp['prediction_id'] = temp['visit_id'] + '_updrs_' + str(u) + '_plus_' + str(m) + '_months'\\n        temp['rating'] = temp['result_updrs_' + str(u)]\\n        temp['group_key'] = str(m)\\n        temp = temp [['prediction_id', 'rating', 'group_key']]\\n\\n        result = result.append(temp)\\n\\nresult = result.drop_duplicates(subset=['prediction_id', 'rating'])\\n\\nresult\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"df_proteins = pd.read_csv('/kaggle/input/amp-parkinsons-disease-progression-prediction/example_test_files/test_proteins.csv')\n",
    "print(df_proteins.shape)\n",
    "\n",
    "df_peptides = pd.read_csv('/kaggle/input/amp-parkinsons-disease-progression-prediction/example_test_files/test_peptides.csv')\n",
    "print(df_peptides.shape)\n",
    "\n",
    "pro_pep_join = pd.merge(df_proteins, df_peptides, on=['patient_id','visit_id','visit_month','UniProt'], how='inner')\n",
    "del df_proteins, df_peptides\n",
    "gc.collect()\n",
    "\n",
    "full_test_data = pd.DataFrame()\n",
    "\n",
    "for i in [0,6,12,24]:\n",
    "    temp = pro_pep_join[pro_pep_join['visit_month']==i]\n",
    "    full_test_data = full_test_data.append(temp)\n",
    "\n",
    "full_test_data = full_test_data.drop(columns=['UniProt','Peptide','patient_id','group_key_x','group_key_y'])\n",
    "\n",
    "list_of_updrs_tests = ['updrs_1','updrs_2','updrs_3','updrs_4']\n",
    "    \n",
    "new_features = full_test_data.groupby(['visit_id','visit_month']).agg(npx_mean=('NPX', 'mean'), npx_median=('NPX', 'median')\n",
    "                                                                          , peptide_mean=('PeptideAbundance', 'mean'), peptide_median=('PeptideAbundance', 'median')\n",
    "                                                          ).reset_index(level=['visit_id','visit_month'])\n",
    "\n",
    "full_test_data = pd.merge(full_test_data, new_features, on=['visit_id','visit_month'], how='inner')\n",
    "full_test_data = full_test_data.drop(columns=['NPX','PeptideAbundance'])\n",
    "full_test_data = full_test_data.drop_duplicates(keep='first')\n",
    "full_test_data = full_test_data[['visit_id','visit_month','npx_mean','npx_median','peptide_mean','peptide_median']]\n",
    "\n",
    "full_test_data = full_test_data.reset_index()\n",
    "full_test_data = full_test_data.drop(columns=['index'])\n",
    "\n",
    "df_prepared = full_pipeline.transform(full_test_data)\n",
    "print(df_prepared.shape)\n",
    "\n",
    "for u in list_of_updrs_tests:\n",
    "    full_test_data['result_' + str(u)] = pd.DataFrame(model_dict[u].predict(df_prepared),columns=['rating']).round(decimals=0)\n",
    "    \n",
    "result = pd.DataFrame()\n",
    "\n",
    "for m in [0, 6, 12, 24]:\n",
    "    for u in [1, 2, 3, 4]:\n",
    "        temp = full_test_data[['visit_id', 'result_updrs_' + str(u)]]\n",
    "        temp['prediction_id'] = temp['visit_id'] + '_updrs_' + str(u) + '_plus_' + str(m) + '_months'\n",
    "        temp['rating'] = temp['result_updrs_' + str(u)]\n",
    "        temp['group_key'] = str(m)\n",
    "        temp = temp [['prediction_id', 'rating', 'group_key']]\n",
    "\n",
    "        result = result.append(temp)\n",
    "\n",
    "result = result.drop_duplicates(subset=['prediction_id', 'rating'])\n",
    "\n",
    "result\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2211762",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-25T13:51:46.420763Z",
     "iopub.status.busy": "2023-03-25T13:51:46.420301Z",
     "iopub.status.idle": "2023-03-25T13:51:46.444677Z",
     "shell.execute_reply": "2023-03-25T13:51:46.443572Z"
    },
    "papermill": {
     "duration": 0.03536,
     "end_time": "2023-03-25T13:51:46.447430",
     "exception": false,
     "start_time": "2023-03-25T13:51:46.412070",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_full_test_data(df_proteins=pd.DataFrame(), df_peptides=pd.DataFrame()):\n",
    "    \n",
    "    if  (df_proteins.shape[1] == 0) & (df_peptides.shape[1] == 0):\n",
    "        ## returning empty submissions, since empty test dataframes have been passed\n",
    "        print('in first if')\n",
    "        full_test_data = pd.DataFrame(columns=['visit_id','visit_month','npx_mean','npx_median','peptide_mean','peptide_median'])\n",
    "        return full_test_data\n",
    "    \n",
    "    elif (df_proteins.shape[0] == 0) & (df_peptides.shape[0] != 0):\n",
    "        ## no data in the proteins dataset, but the columns are present and peptides dataset is non-empty\n",
    "        print('in first elif')\n",
    "        full_test_data = pd.DataFrame()\n",
    "\n",
    "        for i in [0,6,12,24]:\n",
    "            temp = df_peptides[df_peptides['visit_month']==i]\n",
    "            full_test_data = full_test_data.append(temp)\n",
    "            \n",
    "        new_features = full_test_data.groupby(['visit_id','visit_month']).agg(peptide_mean=('PeptideAbundance', 'mean'), peptide_median=('PeptideAbundance', 'median')\n",
    "                                                              ).reset_index(level=['visit_id','visit_month'])\n",
    "\n",
    "        full_test_data = pd.merge(full_test_data, new_features, on=['visit_id','visit_month'], how='inner')\n",
    "        full_test_data['npx_mean'] = 0\n",
    "        full_test_data['npx_median'] = 0\n",
    "        full_test_data = full_test_data.drop_duplicates(keep='first')\n",
    "        full_test_data = full_test_data[['visit_id','visit_month','npx_mean','npx_median','peptide_mean','peptide_median']]\n",
    "\n",
    "        full_test_data = full_test_data.reset_index()\n",
    "        full_test_data = full_test_data.drop(columns=['index'])\n",
    "        \n",
    "        return full_test_data\n",
    "            \n",
    "    elif (df_peptides.shape[0] == 0) & (df_proteins.shape[0] != 0):\n",
    "        ## no data in the peptides dataset, but the columns are present and proteins dataset is non-empty\n",
    "        print('in 2nd elif')\n",
    "        full_test_data = pd.DataFrame()\n",
    "\n",
    "        for i in [0,6,12,24]:\n",
    "            temp = df_proteins[df_proteins['visit_month']==i]\n",
    "            full_test_data = full_test_data.append(temp)\n",
    "            \n",
    "        new_features = full_test_data.groupby(['visit_id','visit_month']).agg(npx_mean=('NPX', 'mean'), npx_median=('NPX', 'median')\n",
    "                                                              ).reset_index(level=['visit_id','visit_month'])\n",
    "\n",
    "        full_test_data = pd.merge(full_test_data, new_features, on=['visit_id','visit_month'], how='inner')\n",
    "        full_test_data['peptide_mean'] = 0\n",
    "        full_test_data['peptide_median'] = 0\n",
    "        full_test_data = full_test_data.drop_duplicates(keep='first')\n",
    "        full_test_data = full_test_data[['visit_id','visit_month','npx_mean','npx_median','peptide_mean','peptide_median']]\n",
    "\n",
    "        full_test_data = full_test_data.reset_index()\n",
    "        full_test_data = full_test_data.drop(columns=['index'])\n",
    "        \n",
    "        return full_test_data\n",
    "        \n",
    "    else:\n",
    "        ## both datasets are present in full glory\n",
    "        print('in else')\n",
    "        \n",
    "        pro_pep_join = pd.merge(df_proteins, df_peptides, on=['patient_id','visit_id','visit_month','UniProt'], suffixes=['_left','_right'], how='outer')\n",
    "        del df_proteins, df_peptides\n",
    "        \n",
    "        pro_pep_join['NPX'] = np.where(pro_pep_join['NPX'].isna(), 0, pro_pep_join['NPX'])\n",
    "        pro_pep_join['PeptideAbundance'] = np.where(pro_pep_join['PeptideAbundance'].isna(), 0, pro_pep_join['PeptideAbundance'])\n",
    "        \n",
    "        gc.collect()\n",
    "\n",
    "        full_test_data = pd.DataFrame()\n",
    "\n",
    "        for i in [0,6,12,24]:\n",
    "            temp = pro_pep_join[pro_pep_join['visit_month']==i]\n",
    "            full_test_data = full_test_data.append(temp)\n",
    "\n",
    "        new_features = full_test_data.groupby(['visit_id','visit_month']).agg(npx_mean=('NPX', 'mean'), npx_median=('NPX', 'median')\n",
    "                                                                                  , peptide_mean=('PeptideAbundance', 'mean')\n",
    "                                                                              , peptide_median=('PeptideAbundance', 'median')\n",
    "                                                                  ).reset_index(level=['visit_id','visit_month'])\n",
    "\n",
    "        full_test_data = pd.merge(full_test_data, new_features, on=['visit_id','visit_month'], how='inner')\n",
    "        full_test_data = full_test_data.drop_duplicates(keep='first')\n",
    "        full_test_data = full_test_data[['visit_id','visit_month','npx_mean','npx_median','peptide_mean','peptide_median']]\n",
    "\n",
    "        full_test_data = full_test_data.reset_index()\n",
    "        full_test_data = full_test_data.drop(columns=['index'])\n",
    "        \n",
    "        return full_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ef92937",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-25T13:51:46.463357Z",
     "iopub.status.busy": "2023-03-25T13:51:46.462494Z",
     "iopub.status.idle": "2023-03-25T13:51:46.474245Z",
     "shell.execute_reply": "2023-03-25T13:51:46.473045Z"
    },
    "papermill": {
     "duration": 0.023071,
     "end_time": "2023-03-25T13:51:46.477142",
     "exception": false,
     "start_time": "2023-03-25T13:51:46.454071",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_predictions(model_dict, sklearn_pipeline, df_proteins=pd.DataFrame(), df_peptides=pd.DataFrame()):\n",
    "    \n",
    "    list_of_updrs_tests = ['updrs_1','updrs_2','updrs_3','updrs_4']\n",
    "    result = pd.DataFrame()\n",
    "    \n",
    "    full_test_data = get_full_test_data(df_proteins=df_proteins, df_peptides=df_peptides)\n",
    "    \n",
    "    if full_test_data.shape[0] != 0:\n",
    "        df_prepared = sklearn_pipeline.transform(full_test_data)\n",
    "        print(df_prepared.shape)\n",
    "\n",
    "        for u in list_of_updrs_tests:\n",
    "            full_test_data['result_' + str(u)] = pd.DataFrame(model_dict[u].predict(df_prepared),columns=['rating']).round(decimals=0)\n",
    "\n",
    "        for m in [0, 6, 12, 24]:\n",
    "            for u in [1, 2, 3, 4]:\n",
    "                temp = full_test_data[['visit_id', 'result_updrs_' + str(u)]]\n",
    "                temp['prediction_id'] = temp['visit_id'] + '_updrs_' + str(u) + '_plus_' + str(m) + '_months'\n",
    "                temp[\"rating\"] = temp[\"result_updrs_\" + str(u)]\n",
    "                #temp['group_key'] = str(m)\n",
    "                temp = temp [['prediction_id', 'rating']]\n",
    "\n",
    "                result = result.append(temp)\n",
    "\n",
    "        result = result.drop_duplicates(subset=['prediction_id', 'rating'])\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a6f86770",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-25T13:51:46.492822Z",
     "iopub.status.busy": "2023-03-25T13:51:46.492119Z",
     "iopub.status.idle": "2023-03-25T13:51:46.497677Z",
     "shell.execute_reply": "2023-03-25T13:51:46.496752Z"
    },
    "papermill": {
     "duration": 0.016389,
     "end_time": "2023-03-25T13:51:46.500108",
     "exception": false,
     "start_time": "2023-03-25T13:51:46.483719",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#test_proteins = pd.read_csv('/kaggle/input/amp-parkinsons-disease-progression-prediction/example_test_files/test_proteins.csv')\n",
    "#result = get_predictions(model_dict=model_dict, sklearn_pipeline=full_pipeline, df_proteins=test_proteins, df_peptides=pd.DataFrame())\n",
    "\n",
    "#test_peptides = pd.read_csv('/kaggle/input/amp-parkinsons-disease-progression-prediction/example_test_files/test_peptides.csv')\n",
    "#result = get_predictions(model_dict=model_dict, sklearn_pipeline=full_pipeline, df_proteins=pd.DataFrame(), df_peptides=test_peptides)\n",
    "\n",
    "#result = get_predictions(model_dict=model_dict, sklearn_pipeline=full_pipeline, df_proteins=test_proteins, df_peptides=test_peptides)\n",
    "\n",
    "#result = get_predictions(model_dict=model_dict, sklearn_pipeline=full_pipeline)\n",
    "\n",
    "#result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ffe022ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-25T13:51:46.515623Z",
     "iopub.status.busy": "2023-03-25T13:51:46.514860Z",
     "iopub.status.idle": "2023-03-25T13:51:47.065450Z",
     "shell.execute_reply": "2023-03-25T13:51:47.063970Z"
    },
    "papermill": {
     "duration": 0.563169,
     "end_time": "2023-03-25T13:51:47.069745",
     "exception": false,
     "start_time": "2023-03-25T13:51:46.506576",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This version of the API is not optimized and should not be used to estimate the runtime of your code on the hidden test set.\n",
      "in else\n",
      "(1021, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in else\n",
      "(1036, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "import amp_pd_peptide\n",
    "env = amp_pd_peptide.make_env()   # initialize the environment\n",
    "iter_test = env.iter_test()\n",
    "\n",
    "for (test, test_peptides, test_proteins, submission) in iter_test:\n",
    "    result = get_predictions(model_dict=model_dict, sklearn_pipeline=full_pipeline, df_proteins=test_proteins, df_peptides=test_peptides)\n",
    "    env.predict(result)\n",
    "    \n",
    "##result.to_csv('/kaggle/working/submission.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "481baff4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-25T13:51:47.086748Z",
     "iopub.status.busy": "2023-03-25T13:51:47.086285Z",
     "iopub.status.idle": "2023-03-25T13:51:47.094912Z",
     "shell.execute_reply": "2023-03-25T13:51:47.093446Z"
    },
    "papermill": {
     "duration": 0.020592,
     "end_time": "2023-03-25T13:51:47.097842",
     "exception": false,
     "start_time": "2023-03-25T13:51:47.077250",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"submission = pd.read_csv('/kaggle/working/submission.csv')\\nsubmission\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"submission = pd.read_csv('/kaggle/working/submission.csv')\n",
    "submission\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 17.433838,
   "end_time": "2023-03-25T13:51:47.931807",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-03-25T13:51:30.497969",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
