{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nimport gc\nfrom pandas.plotting import scatter_matrix\n%matplotlib inline\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import StratifiedShuffleSplit\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\n\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.tree import DecisionTreeRegressor\n\nfrom statsmodels.tsa.seasonal import seasonal_decompose\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-04-01T03:25:06.491049Z","iopub.execute_input":"2023-04-01T03:25:06.491394Z","iopub.status.idle":"2023-04-01T03:25:07.287742Z","shell.execute_reply.started":"2023-04-01T03:25:06.491362Z","shell.execute_reply":"2023-04-01T03:25:07.286738Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/amp-parkinsons-disease-progression-prediction/train_proteins.csv\n/kaggle/input/amp-parkinsons-disease-progression-prediction/train_clinical_data.csv\n/kaggle/input/amp-parkinsons-disease-progression-prediction/public_timeseries_testing_util.py\n/kaggle/input/amp-parkinsons-disease-progression-prediction/supplemental_clinical_data.csv\n/kaggle/input/amp-parkinsons-disease-progression-prediction/train_peptides.csv\n/kaggle/input/amp-parkinsons-disease-progression-prediction/amp_pd_peptide/competition.cpython-37m-x86_64-linux-gnu.so\n/kaggle/input/amp-parkinsons-disease-progression-prediction/amp_pd_peptide/__init__.py\n/kaggle/input/amp-parkinsons-disease-progression-prediction/example_test_files/sample_submission.csv\n/kaggle/input/amp-parkinsons-disease-progression-prediction/example_test_files/test_proteins.csv\n/kaggle/input/amp-parkinsons-disease-progression-prediction/example_test_files/test_peptides.csv\n/kaggle/input/amp-parkinsons-disease-progression-prediction/example_test_files/test.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"train_proteins_df = pd.read_csv('/kaggle/input/amp-parkinsons-disease-progression-prediction/train_proteins.csv')\nprint('proteins :', train_proteins_df.shape)\nprint('proteins unique visit_ids:', train_proteins_df.visit_id.nunique())\nprint(train_proteins_df.columns)\n\ntrain_peptides_df = pd.read_csv('/kaggle/input/amp-parkinsons-disease-progression-prediction/train_peptides.csv')\nprint('')\nprint('peptides :', train_peptides_df.shape)\nprint('peptides unique visit_ids:', train_peptides_df.visit_id.nunique())\nprint(train_peptides_df.columns)\n\ntrain_clinical_data_df = pd.read_csv('/kaggle/input/amp-parkinsons-disease-progression-prediction/train_clinical_data.csv')\nprint('')\nprint('clinical :', train_clinical_data_df.shape)\nprint('clinical unique visit_ids:', train_clinical_data_df.visit_id.nunique())\nprint(train_clinical_data_df.columns)\n\nsupp_clinical_data_df = pd.read_csv('/kaggle/input/amp-parkinsons-disease-progression-prediction/supplemental_clinical_data.csv')\nprint('')\nprint('supplemental :', supp_clinical_data_df.shape)\nprint('supplemental unique visit_ids:', supp_clinical_data_df.visit_id.nunique())\nprint(supp_clinical_data_df.columns)","metadata":{"execution":{"iopub.status.busy":"2023-04-01T04:01:59.022515Z","iopub.execute_input":"2023-04-01T04:01:59.022881Z","iopub.status.idle":"2023-04-01T04:01:59.650442Z","shell.execute_reply.started":"2023-04-01T04:01:59.022848Z","shell.execute_reply":"2023-04-01T04:01:59.649149Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"proteins : (232741, 5)\nproteins unique visit_ids: 1113\nIndex(['visit_id', 'visit_month', 'patient_id', 'UniProt', 'NPX'], dtype='object')\n\npeptides : (981834, 6)\npeptides unique visit_ids: 1113\nIndex(['visit_id', 'visit_month', 'patient_id', 'UniProt', 'Peptide',\n       'PeptideAbundance'],\n      dtype='object')\n\nclinical : (2615, 8)\nclinical unique visit_ids: 2615\nIndex(['visit_id', 'patient_id', 'visit_month', 'updrs_1', 'updrs_2',\n       'updrs_3', 'updrs_4', 'upd23b_clinical_state_on_medication'],\n      dtype='object')\n\nsupplemental : (2223, 8)\nsupplemental unique visit_ids: 2223\nIndex(['visit_id', 'patient_id', 'visit_month', 'updrs_1', 'updrs_2',\n       'updrs_3', 'updrs_4', 'upd23b_clinical_state_on_medication'],\n      dtype='object')\n","output_type":"stream"}]},{"cell_type":"markdown","source":"* #### Get the relevant training datasets and combine them to form the full training set with Proteins and Peptides\n* #### Remove the NaNs from the UPDRS test scores, using the mean from within the same group of UPDRS test scores, e.g. NaNs in updrs_4 are filled with mean of updrs_4\n* #### Create new mean and median based features and get rid of Proteins Expressions (NPX) and Peptide Abundance","metadata":{}},{"cell_type":"code","source":"clinical_data = pd.merge(supp_clinical_data_df, train_clinical_data_df, on=['patient_id','visit_id','visit_month'], how='outer')\n\nfor i in [1,2,3,4]:\n    clinical_data['updrs_'+str(i)] = np.where(clinical_data['updrs_'+str(i)+'_x'].isna(), clinical_data['updrs_'+str(i)+'_y'], clinical_data['updrs_'+str(i)+'_x'])\n    clinical_data.drop(columns=['updrs_'+str(i)+'_x', 'updrs_'+str(i)+'_y'], inplace=True)\n    \nclinical_data.drop(columns=['upd23b_clinical_state_on_medication_x', 'upd23b_clinical_state_on_medication_y'], inplace=True)\n\nprint(clinical_data.shape)\nprint(clinical_data.visit_id.nunique())\n\ndel supp_clinical_data_df, train_clinical_data_df\n\nclinical_data.head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pro_pep_join = pd.merge(train_proteins_df, train_peptides_df, on=['patient_id','visit_id','visit_month','UniProt'], how='outer')\n\nprint(pro_pep_join.shape)\nprint(pro_pep_join.visit_id.nunique())\n\ndel train_proteins_df, train_peptides_df\npro_pep_join.head(5)","metadata":{"execution":{"iopub.status.busy":"2023-04-01T04:02:06.657359Z","iopub.execute_input":"2023-04-01T04:02:06.657840Z","iopub.status.idle":"2023-04-01T04:02:07.077599Z","shell.execute_reply.started":"2023-04-01T04:02:06.657795Z","shell.execute_reply":"2023-04-01T04:02:07.076328Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"(981834, 7)\n1113\n","output_type":"stream"},{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"  visit_id  visit_month  patient_id UniProt       NPX  \\\n0     55_0            0          55  O00391   11254.3   \n1     55_0            0          55  O00533  732430.0   \n2     55_0            0          55  O00533  732430.0   \n3     55_0            0          55  O00533  732430.0   \n4     55_0            0          55  O00533  732430.0   \n\n                                  Peptide  PeptideAbundance  \n0                           NEQEQPLGQWHLS           11254.3  \n1                             GNPEPTFSWTK          102060.0  \n2                         IEIPSSVQQVPTIIK          174185.0  \n3  KPQSAVYSTGSNGILLC(UniMod_4)EAEGEPQPTIK           27278.9  \n4                            SMEQNGPGLEYR           30838.7  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>visit_id</th>\n      <th>visit_month</th>\n      <th>patient_id</th>\n      <th>UniProt</th>\n      <th>NPX</th>\n      <th>Peptide</th>\n      <th>PeptideAbundance</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>55_0</td>\n      <td>0</td>\n      <td>55</td>\n      <td>O00391</td>\n      <td>11254.3</td>\n      <td>NEQEQPLGQWHLS</td>\n      <td>11254.3</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>55_0</td>\n      <td>0</td>\n      <td>55</td>\n      <td>O00533</td>\n      <td>732430.0</td>\n      <td>GNPEPTFSWTK</td>\n      <td>102060.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>55_0</td>\n      <td>0</td>\n      <td>55</td>\n      <td>O00533</td>\n      <td>732430.0</td>\n      <td>IEIPSSVQQVPTIIK</td>\n      <td>174185.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>55_0</td>\n      <td>0</td>\n      <td>55</td>\n      <td>O00533</td>\n      <td>732430.0</td>\n      <td>KPQSAVYSTGSNGILLC(UniMod_4)EAEGEPQPTIK</td>\n      <td>27278.9</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>55_0</td>\n      <td>0</td>\n      <td>55</td>\n      <td>O00533</td>\n      <td>732430.0</td>\n      <td>SMEQNGPGLEYR</td>\n      <td>30838.7</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"full_training_data = pd.merge(pro_pep_join, clinical_data, on=['patient_id','visit_id','visit_month'], how='outer')\n\nprint(full_training_data.shape)\nprint(full_training_data.visit_id.nunique())\n\ndel pro_pep_join, clinical_data\ngc.collect()\n\nfull_training_data.head(5)","metadata":{"execution":{"iopub.status.busy":"2023-04-01T04:02:11.226747Z","iopub.execute_input":"2023-04-01T04:02:11.227175Z","iopub.status.idle":"2023-04-01T04:02:12.018786Z","shell.execute_reply.started":"2023-04-01T04:02:11.227137Z","shell.execute_reply":"2023-04-01T04:02:12.017599Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"(985604, 11)\n4883\n","output_type":"stream"},{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"  visit_id  visit_month  patient_id UniProt       NPX  \\\n0     55_0            0          55  O00391   11254.3   \n1     55_0            0          55  O00533  732430.0   \n2     55_0            0          55  O00533  732430.0   \n3     55_0            0          55  O00533  732430.0   \n4     55_0            0          55  O00533  732430.0   \n\n                                  Peptide  PeptideAbundance  updrs_1  updrs_2  \\\n0                           NEQEQPLGQWHLS           11254.3     10.0      6.0   \n1                             GNPEPTFSWTK          102060.0     10.0      6.0   \n2                         IEIPSSVQQVPTIIK          174185.0     10.0      6.0   \n3  KPQSAVYSTGSNGILLC(UniMod_4)EAEGEPQPTIK           27278.9     10.0      6.0   \n4                            SMEQNGPGLEYR           30838.7     10.0      6.0   \n\n   updrs_3  updrs_4  \n0     15.0      NaN  \n1     15.0      NaN  \n2     15.0      NaN  \n3     15.0      NaN  \n4     15.0      NaN  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>visit_id</th>\n      <th>visit_month</th>\n      <th>patient_id</th>\n      <th>UniProt</th>\n      <th>NPX</th>\n      <th>Peptide</th>\n      <th>PeptideAbundance</th>\n      <th>updrs_1</th>\n      <th>updrs_2</th>\n      <th>updrs_3</th>\n      <th>updrs_4</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>55_0</td>\n      <td>0</td>\n      <td>55</td>\n      <td>O00391</td>\n      <td>11254.3</td>\n      <td>NEQEQPLGQWHLS</td>\n      <td>11254.3</td>\n      <td>10.0</td>\n      <td>6.0</td>\n      <td>15.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>55_0</td>\n      <td>0</td>\n      <td>55</td>\n      <td>O00533</td>\n      <td>732430.0</td>\n      <td>GNPEPTFSWTK</td>\n      <td>102060.0</td>\n      <td>10.0</td>\n      <td>6.0</td>\n      <td>15.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>55_0</td>\n      <td>0</td>\n      <td>55</td>\n      <td>O00533</td>\n      <td>732430.0</td>\n      <td>IEIPSSVQQVPTIIK</td>\n      <td>174185.0</td>\n      <td>10.0</td>\n      <td>6.0</td>\n      <td>15.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>55_0</td>\n      <td>0</td>\n      <td>55</td>\n      <td>O00533</td>\n      <td>732430.0</td>\n      <td>KPQSAVYSTGSNGILLC(UniMod_4)EAEGEPQPTIK</td>\n      <td>27278.9</td>\n      <td>10.0</td>\n      <td>6.0</td>\n      <td>15.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>55_0</td>\n      <td>0</td>\n      <td>55</td>\n      <td>O00533</td>\n      <td>732430.0</td>\n      <td>SMEQNGPGLEYR</td>\n      <td>30838.7</td>\n      <td>10.0</td>\n      <td>6.0</td>\n      <td>15.0</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"full_training_data = full_training_data.drop(columns=['UniProt','Peptide','patient_id'])\n\ncolumns_to_remove_nan_from = ['updrs_1','updrs_2','updrs_3','updrs_4', 'NPX', 'PeptideAbundance']\n\nfor i in columns_to_remove_nan_from:\n    full_training_data[i].fillna(full_training_data[i].median().round(decimals = 0), inplace=True)\n\nnew_features = full_training_data.groupby(['visit_id','visit_month']).agg(npx_mean=('NPX', 'mean'), npx_median=('NPX', 'median')\n                                                                          , peptide_mean=('PeptideAbundance', 'mean'), peptide_median=('PeptideAbundance', 'median')\n                                                          ).reset_index(level=['visit_id','visit_month'])\n\nfull_training_data = pd.merge(full_training_data, new_features, on=['visit_id','visit_month'], how='inner')\n\n#full_training_data['NPX_standardised'] = (full_training_data['NPX'] - full_training_data['NPX'].mean())/full_training_data['NPX'].std()\n#full_training_data['Pep_standardised'] = (full_training_data['PeptideAbundance'] - full_training_data['PeptideAbundance'].mean())/full_training_data['PeptideAbundance'].std()\n\n#full_training_data = full_training_data.drop(columns=['NPX','PeptideAbundance'])\nfull_training_data = full_training_data.drop_duplicates(keep='first')\nfull_training_data = full_training_data[['visit_id','visit_month', 'npx_mean','npx_median','peptide_mean'\n                                         ,'peptide_median','updrs_1','updrs_2','updrs_3','updrs_4']]\n#full_training_data = full_training_data[['visit_id','visit_month','NPX_standardised','Pep_standardised','updrs_1','updrs_2','updrs_3','updrs_4']]\n\nfull_training_data = full_training_data.reset_index()\nfull_training_data = full_training_data.drop(columns=['index'])\nfull_training_data.head(10)","metadata":{"execution":{"iopub.status.busy":"2023-04-01T04:02:27.142741Z","iopub.execute_input":"2023-04-01T04:02:27.143133Z","iopub.status.idle":"2023-04-01T04:02:28.317596Z","shell.execute_reply.started":"2023-04-01T04:02:27.143096Z","shell.execute_reply":"2023-04-01T04:02:28.315812Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"  visit_id  visit_month      npx_mean  npx_median   peptide_mean  \\\n0     55_0            0  2.028789e+07   1221530.0  748153.907014   \n1     55_0            0  2.028789e+07   1221530.0  748153.907014   \n2     55_0            0  2.028789e+07   1221530.0  748153.907014   \n3     55_0            0  2.028789e+07   1221530.0  748153.907014   \n4     55_0            0  2.028789e+07   1221530.0  748153.907014   \n5     55_0            0  2.028789e+07   1221530.0  748153.907014   \n6     55_0            0  2.028789e+07   1221530.0  748153.907014   \n7     55_0            0  2.028789e+07   1221530.0  748153.907014   \n8     55_0            0  2.028789e+07   1221530.0  748153.907014   \n9     55_0            0  2.028789e+07   1221530.0  748153.907014   \n\n   peptide_median  updrs_1  updrs_2  updrs_3  updrs_4  \n0         93134.8     10.0      6.0     15.0      0.0  \n1         93134.8     10.0      6.0     15.0      0.0  \n2         93134.8     10.0      6.0     15.0      0.0  \n3         93134.8     10.0      6.0     15.0      0.0  \n4         93134.8     10.0      6.0     15.0      0.0  \n5         93134.8     10.0      6.0     15.0      0.0  \n6         93134.8     10.0      6.0     15.0      0.0  \n7         93134.8     10.0      6.0     15.0      0.0  \n8         93134.8     10.0      6.0     15.0      0.0  \n9         93134.8     10.0      6.0     15.0      0.0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>visit_id</th>\n      <th>visit_month</th>\n      <th>npx_mean</th>\n      <th>npx_median</th>\n      <th>peptide_mean</th>\n      <th>peptide_median</th>\n      <th>updrs_1</th>\n      <th>updrs_2</th>\n      <th>updrs_3</th>\n      <th>updrs_4</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>55_0</td>\n      <td>0</td>\n      <td>2.028789e+07</td>\n      <td>1221530.0</td>\n      <td>748153.907014</td>\n      <td>93134.8</td>\n      <td>10.0</td>\n      <td>6.0</td>\n      <td>15.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>55_0</td>\n      <td>0</td>\n      <td>2.028789e+07</td>\n      <td>1221530.0</td>\n      <td>748153.907014</td>\n      <td>93134.8</td>\n      <td>10.0</td>\n      <td>6.0</td>\n      <td>15.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>55_0</td>\n      <td>0</td>\n      <td>2.028789e+07</td>\n      <td>1221530.0</td>\n      <td>748153.907014</td>\n      <td>93134.8</td>\n      <td>10.0</td>\n      <td>6.0</td>\n      <td>15.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>55_0</td>\n      <td>0</td>\n      <td>2.028789e+07</td>\n      <td>1221530.0</td>\n      <td>748153.907014</td>\n      <td>93134.8</td>\n      <td>10.0</td>\n      <td>6.0</td>\n      <td>15.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>55_0</td>\n      <td>0</td>\n      <td>2.028789e+07</td>\n      <td>1221530.0</td>\n      <td>748153.907014</td>\n      <td>93134.8</td>\n      <td>10.0</td>\n      <td>6.0</td>\n      <td>15.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>55_0</td>\n      <td>0</td>\n      <td>2.028789e+07</td>\n      <td>1221530.0</td>\n      <td>748153.907014</td>\n      <td>93134.8</td>\n      <td>10.0</td>\n      <td>6.0</td>\n      <td>15.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>55_0</td>\n      <td>0</td>\n      <td>2.028789e+07</td>\n      <td>1221530.0</td>\n      <td>748153.907014</td>\n      <td>93134.8</td>\n      <td>10.0</td>\n      <td>6.0</td>\n      <td>15.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>55_0</td>\n      <td>0</td>\n      <td>2.028789e+07</td>\n      <td>1221530.0</td>\n      <td>748153.907014</td>\n      <td>93134.8</td>\n      <td>10.0</td>\n      <td>6.0</td>\n      <td>15.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>55_0</td>\n      <td>0</td>\n      <td>2.028789e+07</td>\n      <td>1221530.0</td>\n      <td>748153.907014</td>\n      <td>93134.8</td>\n      <td>10.0</td>\n      <td>6.0</td>\n      <td>15.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>55_0</td>\n      <td>0</td>\n      <td>2.028789e+07</td>\n      <td>1221530.0</td>\n      <td>748153.907014</td>\n      <td>93134.8</td>\n      <td>10.0</td>\n      <td>6.0</td>\n      <td>15.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"#### Check for NaNs","metadata":{}},{"cell_type":"code","source":"full_training_data.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2023-04-01T04:02:42.407380Z","iopub.execute_input":"2023-04-01T04:02:42.407849Z","iopub.status.idle":"2023-04-01T04:02:42.468729Z","shell.execute_reply.started":"2023-04-01T04:02:42.407799Z","shell.execute_reply":"2023-04-01T04:02:42.467401Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"visit_id          0\nvisit_month       0\nnpx_mean          0\nnpx_median        0\npeptide_mean      0\npeptide_median    0\nupdrs_1           0\nupdrs_2           0\nupdrs_3           0\nupdrs_4           0\ndtype: int64"},"metadata":{}}]},{"cell_type":"markdown","source":"#### We will attempt to train one model each for each of the UPDRS tests. To do that, we will also proceed to create a train-test split on the Training dataset specific to each of the UPDRS test, to test out the accuracy of the developed models\n#### We will store all the models in a dictionary\n#### The following cells (except the declaration of the model dict) will be repeated for all UPDRS tests","metadata":{}},{"cell_type":"code","source":"\"\"\"model_dict = {}\n\nfor i in [1,2,3,4]:\n    if (i == 1) | (i == 2):\n        full_training_data['updrs_'+str(i)+'_category'] = pd.cut(full_training_data['updrs_'+str(i)],bins=[-np.inf, 15., np.inf],labels=[1,2])\n    elif i == 3:\n        full_training_data['updrs_'+str(i)+'_category'] = pd.cut(full_training_data['updrs_'+str(i)],bins=[-np.inf, 20., 40., np.inf],labels=[1,2,3])\n    else:\n        full_training_data['updrs_'+str(i)+'_category'] = pd.cut(full_training_data['updrs_'+str(i)],bins=[-np.inf, 7.5, np.inf],labels=[1,2])\n        \n    split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n    for train_index, test_index in split.split(full_training_data, full_training_data['updrs_'+str(i)+'_category']):\n        strat_train_set = full_training_data.loc[train_index]\n        strat_test_set = full_training_data.loc[test_index]\n        \n    if i == 1:\n        strat_train_set = strat_train_set.drop(columns=['updrs_1_category'])\n        strat_test_set = strat_test_set.drop(columns=['updrs_1_category'])\n    elif i == 2:\n        strat_train_set = strat_train_set.drop(columns=['updrs_1_category','updrs_2_category'])\n        strat_test_set = strat_test_set.drop(columns=['updrs_1_category','updrs_2_category'])\n    elif i == 3:\n        strat_train_set = strat_train_set.drop(columns=['updrs_1_category','updrs_2_category','updrs_3_category'])\n        strat_test_set = strat_test_set.drop(columns=['updrs_1_category','updrs_2_category','updrs_3_category'])\n    else:\n        strat_train_set = strat_train_set.drop(columns=['updrs_1_category','updrs_2_category','updrs_3_category','updrs_4_category'])\n        strat_test_set = strat_test_set.drop(columns=['updrs_1_category','updrs_2_category','updrs_3_category','updrs_4_category'])\n    \n    strat_train_set_wo_labels = strat_train_set.drop(columns=['updrs_1','updrs_2','updrs_3','updrs_4','index'])\n    strat_train_set_labels = strat_train_set['updrs_'+str(i)].copy()\n    strat_train_set_numeric = strat_train_set_wo_labels.drop(columns=['visit_id','visit_month'])\n    strat_train_set_cat = strat_train_set_wo_labels[['visit_month']]\n\n    strat_test_set_wo_labels = strat_test_set.drop(columns=['updrs_1','updrs_2','updrs_3','updrs_4','index'])\n    strat_test_set_labels = strat_test_set['updrs_'+str(i)].copy()\n    \n    numeric_pipeline = Pipeline([\n        ('standard_scaler', StandardScaler())\n    ])\n\n    numeric_attributes = list(strat_train_set_numeric)\n    categorical_attributes = list(strat_train_set_cat)\n\n    full_pipeline = ColumnTransformer([\n        ('num', numeric_pipeline, numeric_attributes),\n        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_attributes)\n    ])\n\n    strat_train_set_prepared = full_pipeline.fit_transform(strat_train_set_wo_labels)\n    print(strat_train_set_prepared.shape)\n    strat_test_set_prepared = full_pipeline.transform(strat_test_set_wo_labels)\n    print(strat_test_set_prepared.shape)\n    \n    lin_reg = LinearRegression()\n\n    model_dict['updrs_'+str(i)] = lin_reg.fit(strat_train_set_prepared, strat_train_set_labels)\n    print(model_dict)\"\"\"","metadata":{"execution":{"iopub.status.busy":"2023-03-26T05:11:20.768067Z","iopub.execute_input":"2023-03-26T05:11:20.768490Z","iopub.status.idle":"2023-03-26T05:11:20.888631Z","shell.execute_reply.started":"2023-03-26T05:11:20.768454Z","shell.execute_reply":"2023-03-26T05:11:20.887060Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"model_dict = {}\n\nfor u in list_of_updrs_tests:\n        \n    # Drop NAs\n    temp = full_training_data.dropna(subset=[u]) \n    print(u)\n    # Train data\n    #X = temp[['visit_month','npx_mean','npx_median','peptide_mean','peptide_median']]\n    X = temp[['visit_month','NPX_standardised','Pep_standardised']]\n    print(X.shape)\n    y = temp[u]\n    print(y.shape)\n    trained = LinearRegression().fit(X, y)\n    \n    # Save model\n    model_dict[u] = trained\"\"\"","metadata":{"execution":{"iopub.status.busy":"2023-03-26T13:28:07.753185Z","iopub.execute_input":"2023-03-26T13:28:07.753995Z","iopub.status.idle":"2023-03-26T13:28:08.120896Z","shell.execute_reply.started":"2023-03-26T13:28:07.753944Z","shell.execute_reply":"2023-03-26T13:28:08.119749Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"poly_model_dict = {}\nlist_of_updrs_tests = ['updrs_1', 'updrs_2', 'updrs_3', 'updrs_4']\n\nfor u in list_of_updrs_tests:\n        \n    # Drop NAs\n    temp = full_training_data.dropna(subset=[u]) \n    print(u)\n    # Train data\n    X = temp[['visit_month','npx_mean','npx_median','peptide_mean','peptide_median']]\n    #X = temp[['visit_month','NPX_standardised','Pep_standardised']]\n    print(X.shape)\n    y = temp[u]\n    print(y.shape)\n    poly = PolynomialFeatures(degree = 5)\n    X_poly = poly.fit_transform(X)\n    poly.fit(X_poly, y)\n    print(X_poly.shape)\n    trained = LinearRegression().fit(X_poly, y)\n    \n    # Save model\n    poly_model_dict[u] = trained","metadata":{"execution":{"iopub.status.busy":"2023-04-01T04:04:23.555464Z","iopub.execute_input":"2023-04-01T04:04:23.555850Z","iopub.status.idle":"2023-04-01T04:05:24.110782Z","shell.execute_reply.started":"2023-04-01T04:04:23.555817Z","shell.execute_reply":"2023-04-01T04:05:24.109892Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"updrs_1\n(985597, 5)\n(985597,)\n(985597, 252)\nupdrs_2\n(985597, 5)\n(985597,)\n(985597, 252)\nupdrs_3\n(985597, 5)\n(985597,)\n(985597, 252)\nupdrs_4\n(985597, 5)\n(985597,)\n(985597, 252)\n","output_type":"stream"}]},{"cell_type":"code","source":"\"\"\"decision_model_dict = {}\n\nfor u in list_of_updrs_tests:\n        \n    # Drop NAs\n    temp = full_training_data.dropna(subset=[u]) \n    print(u)\n    # Train data\n    X = temp[['visit_month','npx_mean','npx_median','peptide_mean','peptide_median']]\n    print(X.shape)\n    y = temp[u]\n    print(y.shape)\n    trained = DecisionTreeRegressor().fit(X, y)\n    \n    # Save model\n    decision_model_dict[u] = trained\"\"\"","metadata":{"execution":{"iopub.status.busy":"2023-03-27T18:10:24.776985Z","iopub.execute_input":"2023-03-27T18:10:24.777465Z","iopub.status.idle":"2023-03-27T18:10:24.822656Z","shell.execute_reply.started":"2023-03-27T18:10:24.777419Z","shell.execute_reply":"2023-03-27T18:10:24.821093Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### The commands below are for debugging only, these were used to determine the bins corresponding to the train-test split specific to UPDRS tests","metadata":{}},{"cell_type":"code","source":"def smape(y_true, y_pred):\n    smap = np.zeros(len(y_true))\n\n    num = np.abs(y_true - y_pred)\n    dem = ((np.abs(y_true) + np.abs(y_pred)) / 2)\n\n    pos_ind = dem != 0\n    smap[pos_ind] = num[pos_ind] / dem[pos_ind]\n\n    return 100 * np.mean(smap)\n\n\"\"\"train_true_all = [1,2,3,4,150,0,0,0,0]\ntrain_yhat_all = [0,0,0,0,0,0,0,0,0]\nprint('SMAPE: ',smape(np.array(train_true_all), np.round(np.array(train_yhat_all))))\nprint('SMAPE+1: ',smape(np.array(train_true_all)+1, np.round(np.array(train_yhat_all)+1)))\"\"\"","metadata":{"execution":{"iopub.status.busy":"2023-04-01T04:05:50.622011Z","iopub.execute_input":"2023-04-01T04:05:50.622385Z","iopub.status.idle":"2023-04-01T04:05:50.632763Z","shell.execute_reply.started":"2023-04-01T04:05:50.622352Z","shell.execute_reply":"2023-04-01T04:05:50.631376Z"},"trusted":true},"execution_count":28,"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"\"train_true_all = [1,2,3,4,150,0,0,0,0]\\ntrain_yhat_all = [0,0,0,0,0,0,0,0,0]\\nprint('SMAPE: ',smape(np.array(train_true_all), np.round(np.array(train_yhat_all))))\\nprint('SMAPE+1: ',smape(np.array(train_true_all)+1, np.round(np.array(train_yhat_all)+1)))\""},"metadata":{}}]},{"cell_type":"code","source":"\"\"\"for u in list_of_updrs_tests:\n    \n    #X = full_training_data[['visit_month','npx_mean','npx_median','peptide_mean','peptide_median']]\n    X = full_training_data[['visit_month','NPX_standardised','Pep_standardised']]\n\n    y_true = full_training_data[u]\n    y_pred = np.ceil(model_dict[u].predict(X))\n    \n    print('Linear regression SMAPE + 1 for', u, ':', smape(np.array(y_true), np.array(y_pred)))\"\"\"","metadata":{"execution":{"iopub.status.busy":"2023-03-26T13:29:18.275687Z","iopub.execute_input":"2023-03-26T13:29:18.276087Z","iopub.status.idle":"2023-03-26T13:29:18.427565Z","shell.execute_reply.started":"2023-03-26T13:29:18.276036Z","shell.execute_reply":"2023-03-26T13:29:18.426261Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for u in list_of_updrs_tests:\n    \n    X = full_training_data[['visit_month','npx_mean','npx_median','peptide_mean','peptide_median']]\n    #X = full_training_data[['visit_month','NPX_standardised','Pep_standardised']]\n    poly = PolynomialFeatures(degree = 5)\n    X_poly = poly.fit_transform(X)\n    \n    y_true = full_training_data[u]\n    y_pred = np.ceil(poly_model_dict[u].predict(X_poly))\n    \n    print('Polynomial regression SMAPE + 1 for', u, ':', smape(np.array(y_true), np.array(y_pred)))\n    \n    mse = mean_squared_error(y_true, y_pred)\n    rmse = np.sqrt(mse)\n    print('RMSE with Polynomial regression model', rmse)","metadata":{"execution":{"iopub.status.busy":"2023-04-01T04:05:55.090629Z","iopub.execute_input":"2023-04-01T04:05:55.090999Z","iopub.status.idle":"2023-04-01T04:06:02.392504Z","shell.execute_reply.started":"2023-04-01T04:05:55.090966Z","shell.execute_reply":"2023-04-01T04:06:02.390468Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"Polynomial regression SMAPE + 1 for updrs_1 : 69.35512194426818\nRMSE with Polynomial regression model 5.129797895170094\nPolynomial regression SMAPE + 1 for updrs_2 : 92.87810491175821\nRMSE with Polynomial regression model 5.573765696798581\nPolynomial regression SMAPE + 1 for updrs_3 : 83.79547121367017\nRMSE with Polynomial regression model 13.989449842412869\nPolynomial regression SMAPE + 1 for updrs_4 : 161.80922667158126\nRMSE with Polynomial regression model 2.2937830167484643\n","output_type":"stream"}]},{"cell_type":"code","source":"\"\"\"for u in list_of_updrs_tests:\n    \n    X = full_training_data[['visit_month','npx_mean','npx_median','peptide_mean','peptide_median']]\n\n    y_true = full_training_data[u]\n    y_pred = np.ceil(decision_model_dict[u].predict(X))\n    \n    print('Decision Tree regression SMAPE + 1 for', u, ':', smape(np.array(y_true), np.array(y_pred)))\n    \n    mse = mean_squared_error(y_true, y_pred)\n    rmse = np.sqrt(mse)\n    print('RMSE with Decision Tree Regressor model', rmse)\"\"\"","metadata":{"execution":{"iopub.status.busy":"2023-03-28T03:35:11.922340Z","iopub.execute_input":"2023-03-28T03:35:11.922740Z","iopub.status.idle":"2023-03-28T03:35:11.930670Z","shell.execute_reply.started":"2023-03-28T03:35:11.922704Z","shell.execute_reply":"2023-03-28T03:35:11.929415Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#full_training_data[['updrs_1','updrs_2','updrs_3','updrs_4']].hist(figsize=(20,15))","metadata":{"execution":{"iopub.status.busy":"2023-03-22T12:22:49.299064Z","iopub.execute_input":"2023-03-22T12:22:49.300575Z","iopub.status.idle":"2023-03-22T12:22:50.277328Z","shell.execute_reply.started":"2023-03-22T12:22:49.300526Z","shell.execute_reply":"2023-03-22T12:22:50.275981Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"full_training_data['updrs_2_category'] = pd.cut(full_training_data['updrs_2'],\n                                                          bins=[-np.inf, 15., np.inf],\n                                                          labels=[1,2])\n\nfull_training_data['updrs_3_category'] = pd.cut(full_training_data['updrs_3'],\n                                                          bins=[-np.inf, 20., 40., np.inf],\n                                                          labels=[1,2,3])\n\nfull_training_data['updrs_4_category'] = pd.cut(full_training_data['updrs_4'],\n                                                          bins=[-np.inf, 7.5, np.inf],\n                                                          labels=[1,2])\n\nfull_training_data['updrs_4_category'].hist()\n\nfull_training_data['updrs_4_category'].unique()\nsplit = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\nfor train_index, test_index in split.split(full_training_data, full_training_data['updrs_4_category']):\n    strat_train_set = full_training_data.loc[train_index]\n    strat_test_set = full_training_data.loc[test_index]\n    \nprint(strat_test_set['updrs_4_category'].value_counts()/len(strat_test_set))\nprint(strat_train_set['updrs_4_category'].value_counts()/len(strat_train_set))\n\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2023-03-22T11:44:02.441395Z","iopub.execute_input":"2023-03-22T11:44:02.441911Z","iopub.status.idle":"2023-03-22T11:44:02.670492Z","shell.execute_reply.started":"2023-03-22T11:44:02.441872Z","shell.execute_reply":"2023-03-22T11:44:02.668016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Testing the RMSE\n#### RMSE <= 0.75 : Very good accuracy | 0.75 < RMSE <= 1.0 : Good accuracy","metadata":{}},{"cell_type":"markdown","source":"#### First on train data (train split from the full training dataset)\n#### 2nd on test data (test split from the full training dataset)","metadata":{}},{"cell_type":"code","source":"\"\"\"train_df_predictions = lin_reg_model_updrs_4.predict(strat_train_set_prepared)\nmse = mean_squared_error(strat_train_set_labels, train_df_predictions)\nrmse = np.sqrt(mse)\nprint(rmse)\n\ntest_df_predictions = lin_reg_model_updrs_4.predict(strat_test_set_prepared)\nmse = mean_squared_error(strat_test_set_labels, test_df_predictions)\nrmse = np.sqrt(mse)\nprint(rmse)\n\nmodel_dict['updrs_4'] = lin_reg_model_updrs_4\nmodel_dict\"\"\"","metadata":{"execution":{"iopub.status.busy":"2023-03-22T11:45:29.720400Z","iopub.execute_input":"2023-03-22T11:45:29.720875Z","iopub.status.idle":"2023-03-22T11:45:29.730490Z","shell.execute_reply.started":"2023-03-22T11:45:29.720835Z","shell.execute_reply":"2023-03-22T11:45:29.728867Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### The below cell is only for debugging the function get_predictions()","metadata":{}},{"cell_type":"code","source":"def get_full_test_data(df_test, df_proteins=pd.DataFrame(), df_peptides=pd.DataFrame()):\n    \n    if  (df_proteins.shape[0] == 0) & (df_peptides.shape[0] == 0):\n        \n        print('only the test dataframe has data, proteins and peptides info absent')\n        full_test_data = df_test[['visit_id','visit_month']]\n        full_test_data['npx_mean'] = 0\n        full_test_data['npx_median'] = 0\n        full_test_data['peptide_mean'] = 0\n        full_test_data['peptide_median'] = 0\n        \n        #full_test_data['NPX_standardised'] = 0\n        #full_test_data['Pep_standardised'] = 0\n        \n        full_test_data = full_test_data.drop_duplicates(keep='first')\n        full_test_data = full_test_data[['visit_id','visit_month','npx_mean','npx_median','peptide_mean','peptide_median']]\n        #full_test_data = full_test_data[['visit_id','visit_month','NPX_standardised','Pep_standardised']]\n\n        full_test_data = full_test_data.reset_index()\n        full_test_data = full_test_data.drop(columns=['index'])\n        return full_test_data\n    \n    elif (df_proteins.shape[0] == 0) & (df_peptides.shape[0] != 0):\n        \n        print('no proteins only peptides')\n        print('df_test shape and number of unique visit_ids:', df_test.shape, df_test.visit_id.nunique())\n        print('df_peptides shape and number of unique visit_ids:', df_peptides.shape, df_peptides.visit_id.nunique())\n        \n        df_peptides = pd.merge(df_test, df_peptides, on=['patient_id','visit_id','visit_month'], suffixes=['_left','_right'], how='left')\n        df_peptides['PeptideAbundance'] = np.where(df_peptides['PeptideAbundance'].isna(), 0, df_peptides['PeptideAbundance'])\n\n        \"\"\"\n        full_test_data = pd.DataFrame()\n        for i in [0,6,12,24]:\n            temp = df_peptides[df_peptides['visit_month']==i]\n            full_test_data = full_test_data.append(temp)\n        \n        del df_proteins, df_peptides\n        \"\"\"\n        full_test_data = df_peptides\n        print('full_test_data shape and number of unique visit_ids:', full_test_data.shape, full_test_data.visit_id.nunique())\n            \n        new_features = full_test_data.groupby(['visit_id','visit_month']).agg(peptide_mean=('PeptideAbundance', 'mean'), peptide_median=('PeptideAbundance', 'median')\n                                                              ).reset_index(level=['visit_id','visit_month'])\n\n        full_test_data = pd.merge(full_test_data, new_features, on=['visit_id','visit_month'], how='inner')\n        full_test_data['npx_mean'] = 0\n        full_test_data['npx_median'] = 0\n        \n        #full_test_data['NPX_standardised'] = 0\n        #full_test_data['Pep_standardised'] = (full_test_data['PeptideAbundance'] - full_test_data['PeptideAbundance'].mean())/full_test_data['PeptideAbundance'].std()\n        \n        full_test_data = full_test_data.drop_duplicates(keep='first')\n        full_test_data = full_test_data[['visit_id','visit_month','npx_mean','npx_median','peptide_mean','peptide_median']]\n        #full_test_data = full_test_data[['visit_id','visit_month','NPX_standardised','Pep_standardised']]\n\n        full_test_data = full_test_data.reset_index()\n        full_test_data = full_test_data.drop(columns=['index'])\n        \n        return full_test_data\n            \n    elif (df_peptides.shape[0] == 0) & (df_proteins.shape[0] != 0):\n        \n        print('no peptides only proteins')\n        print('df_test shape and number of unique visit_ids:', df_test.shape, df_test.visit_id.nunique())\n        print('df_proteins shape and number of unique visit_ids:', df_proteins.shape, df_proteins.visit_id.nunique())\n        \n        df_proteins = pd.merge(df_test, df_proteins, on=['patient_id','visit_id','visit_month'], suffixes=['_left','_right'], how='left')\n        df_proteins['NPX'] = np.where(df_proteins['NPX'].isna(), 0, df_proteins['NPX'])\n\n        \"\"\"\n        full_test_data = pd.DataFrame()\n        for i in [0,6,12,24]:\n            temp = df_proteins[df_proteins['visit_month']==i]\n            full_test_data = full_test_data.append(temp)\n        \"\"\"\n        full_test_data = df_proteins\n        print('full_test_data shape and number of unique visit_ids:', full_test_data.shape, full_test_data.visit_id.nunique())\n            \n        new_features = full_test_data.groupby(['visit_id','visit_month']).agg(npx_mean=('NPX', 'mean'), npx_median=('NPX', 'median')\n                                                              ).reset_index(level=['visit_id','visit_month'])\n\n        full_test_data = pd.merge(full_test_data, new_features, on=['visit_id','visit_month'], how='inner')\n        full_test_data['peptide_mean'] = 0\n        full_test_data['peptide_median'] = 0\n        \n        #full_test_data['NPX_standardised'] = (full_test_data['NPX'] - full_test_data['NPX'].mean())/full_test_data['NPX'].std()\n        #full_test_data['Pep_standardised'] = 0\n        \n        full_test_data = full_test_data.drop_duplicates(keep='first')\n        full_test_data = full_test_data[['visit_id','visit_month','npx_mean','npx_median','peptide_mean','peptide_median']]\n        #full_test_data = full_test_data[['visit_id','visit_month','NPX_standardised','Pep_standardised']]\n\n        full_test_data = full_test_data.reset_index()\n        full_test_data = full_test_data.drop(columns=['index'])\n        \n        return full_test_data\n        \n    else:\n        \n        print('both proteins and peptides are present')\n        \n        pro_pep_join = pd.merge(df_proteins, df_peptides, on=['patient_id','visit_id','visit_month','UniProt'], suffixes=['_left','_right'], how='outer')\n        #del df_proteins, df_peptides\n        print('df_proteins shape and number of unique visit_ids:', df_proteins.shape, df_proteins.visit_id.nunique())\n        print('df_peptides shape and number of unique visit_ids:', df_peptides.shape, df_peptides.visit_id.nunique())\n        print('pro_pep_join shape and number of unique visit_ids:', pro_pep_join.shape, pro_pep_join.visit_id.nunique())\n        \n        pro_pep_join_test = pd.merge(df_test, pro_pep_join, on=['patient_id','visit_id','visit_month'], suffixes=['_left','_right'], how='left')\n        \n        pro_pep_join_test['NPX'] = np.where(pro_pep_join_test['NPX'].isna(), 0, pro_pep_join_test['NPX'])\n        pro_pep_join_test['PeptideAbundance'] = np.where(pro_pep_join_test['PeptideAbundance'].isna(), 0, pro_pep_join_test['PeptideAbundance'])\n        \n        del pro_pep_join\n        gc.collect()\n\n        \"\"\"\n        full_test_data = pd.DataFrame()\n\n        for i in [0,6,12,24]:\n            temp = pro_pep_join_test[pro_pep_join_test['visit_month']==i]\n            full_test_data = full_test_data.append(temp)\n        \"\"\"\n        full_test_data = pro_pep_join_test \n        print('full_test_data shape and number of unique visit_ids:', full_test_data.shape, full_test_data.visit_id.nunique())\n\n        new_features = full_test_data.groupby(['visit_id','visit_month']).agg(npx_mean=('NPX', 'mean'), npx_median=('NPX', 'median')\n                                                                                  , peptide_mean=('PeptideAbundance', 'mean')\n                                                                              , peptide_median=('PeptideAbundance', 'median')\n                                                                  ).reset_index(level=['visit_id','visit_month'])\n\n        full_test_data = pd.merge(full_test_data, new_features, on=['visit_id','visit_month'], how='inner')\n        \n        #full_test_data['NPX_standardised'] = (full_test_data['NPX'] - full_test_data['NPX'].mean())/full_test_data['NPX'].std()\n        #full_test_data['Pep_standardised'] = (full_test_data['PeptideAbundance'] - full_test_data['PeptideAbundance'].mean())/full_test_data['PeptideAbundance'].std()\n        \n        full_test_data = full_test_data.drop_duplicates(keep='first')\n        full_test_data = full_test_data[['visit_id','visit_month','npx_mean','npx_median','peptide_mean','peptide_median']]\n        #full_test_data = full_test_data[['visit_id','visit_month','NPX_standardised','Pep_standardised']]\n\n        full_test_data = full_test_data.reset_index()\n        full_test_data = full_test_data.drop(columns=['index'])\n        \n        return full_test_data","metadata":{"execution":{"iopub.status.busy":"2023-04-01T04:17:55.549874Z","iopub.execute_input":"2023-04-01T04:17:55.550298Z","iopub.status.idle":"2023-04-01T04:17:55.576274Z","shell.execute_reply.started":"2023-04-01T04:17:55.550261Z","shell.execute_reply":"2023-04-01T04:17:55.575181Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"#def get_predictions(model_dict, sklearn_pipeline, df_test, df_proteins=pd.DataFrame(), df_peptides=pd.DataFrame()):\ndef get_predictions(model_dict, df_test, df_proteins=pd.DataFrame(), df_peptides=pd.DataFrame()):\n    \n    list_of_updrs_tests = ['updrs_1','updrs_2','updrs_3','updrs_4']\n    result = pd.DataFrame()\n    \n    full_test_data = get_full_test_data(df_test=df_test, df_proteins=df_proteins, df_peptides=df_peptides)\n    \n    if full_test_data.shape[0] != 0:\n        \"\"\"df_prepared = sklearn_pipeline.transform(full_test_data)\n        print(df_prepared.shape)\"\"\"\n\n        for u in list_of_updrs_tests:\n            X = full_test_data[['visit_month','npx_mean','npx_median','peptide_mean','peptide_median']]\n            #X = full_test_data[['visit_month','NPX_standardised','Pep_standardised']]\n            ## for poly model\n            poly = PolynomialFeatures(degree = 5)\n            X_poly = poly.fit_transform(X)\n            full_test_data['result_' + str(u)] = np.ceil(model_dict[u].predict(X_poly))\n            #full_test_data['result_' + str(u)] = pd.DataFrame(model_dict[u].predict(df_prepared),columns=['rating']).round(decimals=0)\n            ## for all other models\n            #full_test_data['result_' + str(u)] = np.ceil(model_dict[u].predict(X))\n\n        for m in [0, 6, 12, 24]:\n            for u in [1, 2, 3, 4]:\n                temp = full_test_data[['visit_id', 'visit_month', 'result_updrs_' + str(u)]]\n                temp['prediction_id'] = temp['visit_id'] + '_updrs_' + str(u) + '_plus_' + str(m) + '_months'\n                \n                if (u == 2) | (u == 4):\n                    temp[\"rating\"] = 0\n                else:\n                    temp[\"rating\"] = temp[\"result_updrs_\" + str(u)].apply(lambda x: 0 if x < 0 else x)\n                \n                #temp = temp[['visit_id', 'visit_month', 'prediction_id', 'rating']]\n                temp = temp[['prediction_id', 'rating']]\n\n                result = result.append(temp)\n\n        #result.sort_values(by=['visit_id', 'visit_month'], inplace=True)\n        #result = result[['prediction_id', 'rating']]\n        #result['prediction_id'] = result['prediction_id'].astype('string') \n        #result['rating'] = result['rating'].astype('int') \n        result = result.drop_duplicates(subset=['prediction_id', 'rating'])\n        result = result.reset_index()\n        result.drop(columns=['index'], inplace=True)\n    \n    return result","metadata":{"execution":{"iopub.status.busy":"2023-04-01T04:21:20.336150Z","iopub.execute_input":"2023-04-01T04:21:20.337140Z","iopub.status.idle":"2023-04-01T04:21:20.349081Z","shell.execute_reply.started":"2023-04-01T04:21:20.337095Z","shell.execute_reply":"2023-04-01T04:21:20.348238Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"\"\"\"test = pd.read_csv('/kaggle/input/amp-parkinsons-disease-progression-prediction/example_test_files/test.csv')\n\ntest_proteins = pd.read_csv('/kaggle/input/amp-parkinsons-disease-progression-prediction/example_test_files/test_proteins.csv')\n#result = get_predictions(model_dict=model_dict, sklearn_pipeline=full_pipeline, df_test=df_test, df_proteins=test_proteins, df_peptides=pd.DataFrame())\n\ntest_peptides = pd.read_csv('/kaggle/input/amp-parkinsons-disease-progression-prediction/example_test_files/test_peptides.csv')\n#result = get_predictions(model_dict=model_dict, sklearn_pipeline=full_pipeline, df_test=df_test, df_proteins=pd.DataFrame(), df_peptides=test_peptides)\n\nresult = get_predictions(model_dict=poly_model_dict, df_test=test, df_proteins=test_proteins, df_peptides=test_peptides)\n#result = get_predictions(model_dict=poly_model_dict, df_test=df_test)\n\n#result = get_predictions(model_dict=model_dict, sklearn_pipeline=full_pipeline)\n\nresult\"\"\"","metadata":{"execution":{"iopub.status.busy":"2023-04-01T04:21:23.201079Z","iopub.execute_input":"2023-04-01T04:21:23.201470Z","iopub.status.idle":"2023-04-01T04:21:23.906095Z","shell.execute_reply.started":"2023-04-01T04:21:23.201436Z","shell.execute_reply":"2023-04-01T04:21:23.905379Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stdout","text":"both proteins and peptides are present\ndf_proteins shape and number of unique visit_ids: (453, 6) 2\ndf_peptides shape and number of unique visit_ids: (2057, 7) 2\npro_pep_join shape and number of unique visit_ids: (2057, 9) 2\nfull_test_data shape and number of unique visit_ids: (8236, 12) 4\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:27: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:32: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:30: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","output_type":"stream"},{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"                     prediction_id  rating\n0     3342_0_updrs_1_plus_0_months     9.0\n1    50423_0_updrs_1_plus_0_months    22.0\n2     3342_6_updrs_1_plus_0_months     7.0\n3    50423_6_updrs_1_plus_0_months     9.0\n4     3342_0_updrs_2_plus_0_months     0.0\n..                             ...     ...\n59  50423_6_updrs_3_plus_24_months    28.0\n60   3342_0_updrs_4_plus_24_months     0.0\n61  50423_0_updrs_4_plus_24_months     0.0\n62   3342_6_updrs_4_plus_24_months     0.0\n63  50423_6_updrs_4_plus_24_months     0.0\n\n[64 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>prediction_id</th>\n      <th>rating</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3342_0_updrs_1_plus_0_months</td>\n      <td>9.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>50423_0_updrs_1_plus_0_months</td>\n      <td>22.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3342_6_updrs_1_plus_0_months</td>\n      <td>7.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>50423_6_updrs_1_plus_0_months</td>\n      <td>9.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3342_0_updrs_2_plus_0_months</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>59</th>\n      <td>50423_6_updrs_3_plus_24_months</td>\n      <td>28.0</td>\n    </tr>\n    <tr>\n      <th>60</th>\n      <td>3342_0_updrs_4_plus_24_months</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>61</th>\n      <td>50423_0_updrs_4_plus_24_months</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>62</th>\n      <td>3342_6_updrs_4_plus_24_months</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>63</th>\n      <td>50423_6_updrs_4_plus_24_months</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>64 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"#result.isna().sum()\n#result[result['rating']==-0.0]","metadata":{"execution":{"iopub.status.busy":"2023-04-01T04:21:45.578661Z","iopub.execute_input":"2023-04-01T04:21:45.579033Z","iopub.status.idle":"2023-04-01T04:21:45.589320Z","shell.execute_reply.started":"2023-04-01T04:21:45.579002Z","shell.execute_reply":"2023-04-01T04:21:45.588064Z"},"trusted":true},"execution_count":42,"outputs":[{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"prediction_id    0\nrating           0\ndtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"import amp_pd_peptide\n\nenv = amp_pd_peptide.make_env()   # initialize the environment for one run only\n\n#amp_pd_peptide.make_env.__called__ = False\n#type(env)._state = type(type(env)._state).__dict__['INIT']\n\niter_test = env.iter_test()\n\nfor (test, test_peptides, test_proteins, submission) in iter_test:\n    #result = get_predictions(model_dict=poly_model_dict, df_test=test)\n    #result = get_predictions(model_dict=decision_model_dict, df_test=test, df_peptides=test_peptides)\n    submission = get_predictions(model_dict=poly_model_dict, df_test=test, df_proteins=test_proteins, df_peptides=test_peptides)\n    env.predict(submission)\n    ","metadata":{"execution":{"iopub.status.busy":"2023-04-01T04:22:09.370416Z","iopub.execute_input":"2023-04-01T04:22:09.370824Z","iopub.status.idle":"2023-04-01T04:22:10.580695Z","shell.execute_reply.started":"2023-04-01T04:22:09.370788Z","shell.execute_reply":"2023-04-01T04:22:10.579492Z"},"trusted":true},"execution_count":43,"outputs":[{"name":"stdout","text":"This version of the API is not optimized and should not be used to estimate the runtime of your code on the hidden test set.\nboth proteins and peptides are present\ndf_proteins shape and number of unique visit_ids: (227, 5) 1\ndf_peptides shape and number of unique visit_ids: (1021, 6) 1\npro_pep_join shape and number of unique visit_ids: (1021, 7) 1\nfull_test_data shape and number of unique visit_ids: (4088, 9) 2\nboth proteins and peptides are present\ndf_proteins shape and number of unique visit_ids: (226, 5) 1\ndf_peptides shape and number of unique visit_ids: (1036, 6) 1\npro_pep_join shape and number of unique visit_ids: (1036, 7) 1\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:27: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:32: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:30: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","output_type":"stream"},{"name":"stdout","text":"full_test_data shape and number of unique visit_ids: (4148, 9) 2\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:27: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:32: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:30: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","output_type":"stream"}]},{"cell_type":"code","source":"\"\"\"submission = pd.read_csv('/kaggle/working/submission.csv')\nsubmission.drop_duplicates()\"\"\"","metadata":{"execution":{"iopub.status.busy":"2023-03-27T18:15:37.477579Z","iopub.execute_input":"2023-03-27T18:15:37.478615Z","iopub.status.idle":"2023-03-27T18:15:37.498215Z","shell.execute_reply.started":"2023-03-27T18:15:37.478558Z","shell.execute_reply":"2023-03-27T18:15:37.496929Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"import amp_pd_peptide\nenv = amp_pd_peptide.make_env()\n\namp_pd_peptide.make_env.__called__ = False\ntype(env)._state = type(type(env)._state).__dict__['INIT'] # initialize the environment for multiple runs\niter_test = env.iter_test()\n\nfor (test, test_peptides, test_proteins, submission) in iter_test:\n    result = get_predictions(model_dict=decision_model_dict, df_test=test, df_proteins=test_proteins, df_peptides=test_peptides)\n    env.predict(result)\"\"\"","metadata":{"execution":{"iopub.status.busy":"2023-03-26T12:46:06.373392Z","iopub.execute_input":"2023-03-26T12:46:06.373894Z","iopub.status.idle":"2023-03-26T12:46:07.125058Z","shell.execute_reply.started":"2023-03-26T12:46:06.373850Z","shell.execute_reply":"2023-03-26T12:46:07.123605Z"},"trusted":true},"execution_count":null,"outputs":[]}]}