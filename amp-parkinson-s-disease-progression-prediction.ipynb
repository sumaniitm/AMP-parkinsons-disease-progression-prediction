{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f7bc90c",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-03-26T04:54:44.664043Z",
     "iopub.status.busy": "2023-03-26T04:54:44.663617Z",
     "iopub.status.idle": "2023-03-26T04:54:45.990709Z",
     "shell.execute_reply": "2023-03-26T04:54:45.989371Z"
    },
    "papermill": {
     "duration": 1.338841,
     "end_time": "2023-03-26T04:54:45.994049",
     "exception": false,
     "start_time": "2023-03-26T04:54:44.655208",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/amp-parkinsons-disease-progression-prediction/train_proteins.csv\n",
      "/kaggle/input/amp-parkinsons-disease-progression-prediction/train_clinical_data.csv\n",
      "/kaggle/input/amp-parkinsons-disease-progression-prediction/public_timeseries_testing_util.py\n",
      "/kaggle/input/amp-parkinsons-disease-progression-prediction/supplemental_clinical_data.csv\n",
      "/kaggle/input/amp-parkinsons-disease-progression-prediction/train_peptides.csv\n",
      "/kaggle/input/amp-parkinsons-disease-progression-prediction/amp_pd_peptide/competition.cpython-37m-x86_64-linux-gnu.so\n",
      "/kaggle/input/amp-parkinsons-disease-progression-prediction/amp_pd_peptide/__init__.py\n",
      "/kaggle/input/amp-parkinsons-disease-progression-prediction/example_test_files/sample_submission.csv\n",
      "/kaggle/input/amp-parkinsons-disease-progression-prediction/example_test_files/test_proteins.csv\n",
      "/kaggle/input/amp-parkinsons-disease-progression-prediction/example_test_files/test_peptides.csv\n",
      "/kaggle/input/amp-parkinsons-disease-progression-prediction/example_test_files/test.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "import gc\n",
    "from pandas.plotting import scatter_matrix\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c727852",
   "metadata": {
    "papermill": {
     "duration": 0.005018,
     "end_time": "2023-03-26T04:54:46.004992",
     "exception": false,
     "start_time": "2023-03-26T04:54:45.999974",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "* #### Get the relevant training datasets and combine them to form the full training set with Proteins and Peptides\n",
    "* #### Remove the NaNs from the UPDRS test scores, using the mean from within the same group of UPDRS test scores, e.g. NaNs in updrs_4 are filled with mean of updrs_4\n",
    "* #### Create new mean and median based features and get rid of Proteins Expressions (NPX) and Peptide Abundance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a3c36bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T04:54:46.017770Z",
     "iopub.status.busy": "2023-03-26T04:54:46.017345Z",
     "iopub.status.idle": "2023-03-26T04:54:49.468966Z",
     "shell.execute_reply": "2023-03-26T04:54:49.467492Z"
    },
    "papermill": {
     "duration": 3.46131,
     "end_time": "2023-03-26T04:54:49.471831",
     "exception": false,
     "start_time": "2023-03-26T04:54:46.010521",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>visit_id</th>\n",
       "      <th>visit_month</th>\n",
       "      <th>npx_mean</th>\n",
       "      <th>npx_median</th>\n",
       "      <th>peptide_mean</th>\n",
       "      <th>peptide_median</th>\n",
       "      <th>updrs_1</th>\n",
       "      <th>updrs_2</th>\n",
       "      <th>updrs_3</th>\n",
       "      <th>updrs_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>55_0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.028789e+07</td>\n",
       "      <td>1221530.0</td>\n",
       "      <td>748153.907014</td>\n",
       "      <td>93134.80</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>931</td>\n",
       "      <td>1517_0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.579576e+07</td>\n",
       "      <td>897182.0</td>\n",
       "      <td>618823.150490</td>\n",
       "      <td>65253.60</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1833</td>\n",
       "      <td>1923_0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.889800e+07</td>\n",
       "      <td>1299230.0</td>\n",
       "      <td>763459.201459</td>\n",
       "      <td>92280.90</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2710</td>\n",
       "      <td>2660_0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.298973e+07</td>\n",
       "      <td>1078570.0</td>\n",
       "      <td>532250.381374</td>\n",
       "      <td>73461.05</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3620</td>\n",
       "      <td>3636_0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.367422e+07</td>\n",
       "      <td>776581.0</td>\n",
       "      <td>501743.931250</td>\n",
       "      <td>54660.20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4495</td>\n",
       "      <td>3863_0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.279134e+07</td>\n",
       "      <td>885864.0</td>\n",
       "      <td>806928.584862</td>\n",
       "      <td>78719.90</td>\n",
       "      <td>8.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5291</td>\n",
       "      <td>4161_0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.647734e+07</td>\n",
       "      <td>1067620.0</td>\n",
       "      <td>699803.391029</td>\n",
       "      <td>77037.80</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6191</td>\n",
       "      <td>4172_0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.729472e+07</td>\n",
       "      <td>874171.0</td>\n",
       "      <td>620558.476752</td>\n",
       "      <td>68208.05</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7115</td>\n",
       "      <td>5027_0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.281632e+07</td>\n",
       "      <td>1134880.0</td>\n",
       "      <td>764893.568584</td>\n",
       "      <td>71828.35</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8025</td>\n",
       "      <td>5178_0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.815310e+07</td>\n",
       "      <td>998682.0</td>\n",
       "      <td>689200.799757</td>\n",
       "      <td>79225.50</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index visit_id  visit_month      npx_mean  npx_median   peptide_mean  \\\n",
       "0      0     55_0            0  2.028789e+07   1221530.0  748153.907014   \n",
       "1    931   1517_0            0  1.579576e+07    897182.0  618823.150490   \n",
       "2   1833   1923_0            0  1.889800e+07   1299230.0  763459.201459   \n",
       "3   2710   2660_0            0  1.298973e+07   1078570.0  532250.381374   \n",
       "4   3620   3636_0            0  1.367422e+07    776581.0  501743.931250   \n",
       "5   4495   3863_0            0  2.279134e+07    885864.0  806928.584862   \n",
       "6   5291   4161_0            0  1.647734e+07   1067620.0  699803.391029   \n",
       "7   6191   4172_0            0  1.729472e+07    874171.0  620558.476752   \n",
       "8   7115   5027_0            0  2.281632e+07   1134880.0  764893.568584   \n",
       "9   8025   5178_0            0  1.815310e+07    998682.0  689200.799757   \n",
       "\n",
       "   peptide_median  updrs_1  updrs_2  updrs_3  updrs_4  \n",
       "0        93134.80     10.0      6.0     15.0      2.0  \n",
       "1        65253.60     11.0      6.0     25.0      5.0  \n",
       "2        92280.90      2.0      0.0      0.0      2.0  \n",
       "3        73461.05      2.0      0.0      0.0      2.0  \n",
       "4        54660.20      1.0      2.0      9.0      2.0  \n",
       "5        78719.90      8.0     13.0     36.0      4.0  \n",
       "6        77037.80      6.0      1.0      0.0      2.0  \n",
       "7        68208.05      2.0      0.0      0.0      2.0  \n",
       "8        71828.35      1.0      0.0      0.0      2.0  \n",
       "9        79225.50      9.0      1.0      3.0      2.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_proteins_df = pd.read_csv('/kaggle/input/amp-parkinsons-disease-progression-prediction/train_proteins.csv')\n",
    "#print(train_proteins_df.shape)\n",
    "#print(train_proteins_df.memory_usage(deep=True).sum()/1024/1024, \" MBs\")\n",
    "#train_proteins_df.head(10)\n",
    "\n",
    "train_peptides_df = pd.read_csv('/kaggle/input/amp-parkinsons-disease-progression-prediction/train_peptides.csv')\n",
    "#print(train_peptides_df.shape)\n",
    "#print(train_peptides_df.memory_usage(deep=True).sum()/1024/1024, \" MBs\")\n",
    "#train_peptides_df.head(10)\n",
    "\n",
    "pro_pep_join = pd.merge(train_proteins_df, train_peptides_df, on=['patient_id','visit_id','visit_month','UniProt'], how='inner')\n",
    "\n",
    "del train_proteins_df, train_peptides_df\n",
    "gc.collect()\n",
    "\n",
    "train_clinical_data_df = pd.read_csv('/kaggle/input/amp-parkinsons-disease-progression-prediction/train_clinical_data.csv')\n",
    "#print(train_clinical_data_df.shape)\n",
    "#print(train_clinical_data_df.memory_usage(deep=True).sum()/1024/1024, \" MBs\")\n",
    "\n",
    "merged_data = pd.merge(pro_pep_join, train_clinical_data_df, on=['patient_id','visit_id','visit_month'], how='inner')\n",
    "\n",
    "del pro_pep_join, train_clinical_data_df\n",
    "gc.collect()\n",
    "\n",
    "full_training_data = pd.DataFrame()\n",
    "\n",
    "for i in [0,6,12,24]:\n",
    "    temp = merged_data[merged_data['visit_month']==i]\n",
    "    full_training_data = full_training_data.append(temp)\n",
    "\n",
    "#print(full_training_data.head(10))\n",
    "    \n",
    "full_training_data = full_training_data.drop(columns=['UniProt','Peptide','upd23b_clinical_state_on_medication','patient_id'])\n",
    "\n",
    "\"\"\"full_training_data_melted = full_training_data.melt(id_vars=['visit_id','visit_month','NPX','PeptideAbundance']\n",
    "                                                    , value_vars=['updrs_1','updrs_2','updrs_3','updrs_4'],var_name='updrs_test', value_name='updrs_test_score')\"\"\"\n",
    "\n",
    "## list_of_updrs_tests = full_training_data_melted.updrs_test.unique()\n",
    "list_of_updrs_tests = ['updrs_1','updrs_2','updrs_3','updrs_4']\n",
    "\n",
    "\"\"\"temp_df = full_training_data_melted.groupby(['updrs_test']).agg(visit_month_per_patient=('visit_id', 'count')\n",
    "                                                      , mean_updrs_test_score=('updrs_test_score', 'mean') ).reset_index(level=['updrs_test'])\"\"\"\n",
    "\n",
    "for i in range(len(list_of_updrs_tests)):\n",
    "    #print(list_of_updrs_tests[i])\n",
    "    #updrs_test_mean = full_training_data[list_of_updrs_tests[i]].mean().round(decimals = 0)\n",
    "    #print(updrs_test_mean)\n",
    "    #full_training_data[list_of_updrs_tests[i]].fillna({list_of_updrs_tests[i]:updrs_test_mean}, inplace=True)\n",
    "    full_training_data[list_of_updrs_tests[i]].fillna(full_training_data[list_of_updrs_tests[i]].mean().round(decimals = 0), inplace=True)\n",
    "\n",
    "#full_training_data[list_of_updrs_tests[i]].fillna(full_training_data['updrs_4'].mean(), inplace=True)\n",
    "#full_training_data.head(10)\n",
    "new_features = full_training_data.groupby(['visit_id','visit_month']).agg(npx_mean=('NPX', 'mean'), npx_median=('NPX', 'median')\n",
    "                                                                          , peptide_mean=('PeptideAbundance', 'mean'), peptide_median=('PeptideAbundance', 'median')\n",
    "                                                          ).reset_index(level=['visit_id','visit_month'])\n",
    "\n",
    "full_training_data = pd.merge(full_training_data, new_features, on=['visit_id','visit_month'], how='inner')\n",
    "full_training_data = full_training_data.drop(columns=['NPX','PeptideAbundance'])\n",
    "full_training_data = full_training_data.drop_duplicates(keep='first')\n",
    "full_training_data = full_training_data[['visit_id','visit_month','npx_mean','npx_median','peptide_mean','peptide_median','updrs_1','updrs_2','updrs_3','updrs_4']]\n",
    "\n",
    "full_training_data = full_training_data.reset_index()\n",
    "#print(full_training_data.shape)\n",
    "full_training_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7b4f3f",
   "metadata": {
    "papermill": {
     "duration": 0.005182,
     "end_time": "2023-03-26T04:54:49.482511",
     "exception": false,
     "start_time": "2023-03-26T04:54:49.477329",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Check for NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9d9308b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T04:54:49.495574Z",
     "iopub.status.busy": "2023-03-26T04:54:49.494783Z",
     "iopub.status.idle": "2023-03-26T04:54:49.505610Z",
     "shell.execute_reply": "2023-03-26T04:54:49.504396Z"
    },
    "papermill": {
     "duration": 0.020178,
     "end_time": "2023-03-26T04:54:49.508163",
     "exception": false,
     "start_time": "2023-03-26T04:54:49.487985",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index             0\n",
       "visit_id          0\n",
       "visit_month       0\n",
       "npx_mean          0\n",
       "npx_median        0\n",
       "peptide_mean      0\n",
       "peptide_median    0\n",
       "updrs_1           0\n",
       "updrs_2           0\n",
       "updrs_3           0\n",
       "updrs_4           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_training_data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e40438",
   "metadata": {
    "papermill": {
     "duration": 0.005286,
     "end_time": "2023-03-26T04:54:49.519205",
     "exception": false,
     "start_time": "2023-03-26T04:54:49.513919",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### We will attempt to train one model each for each of the UPDRS tests. To do that, we will also proceed to create a train-test split on the Training dataset specific to each of the UPDRS test, to test out the accuracy of the developed models\n",
    "#### We will store all the models in a dictionary\n",
    "#### The following cells (except the declaration of the model dict) will be repeated for all UPDRS tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f185b7b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T04:54:49.533049Z",
     "iopub.status.busy": "2023-03-26T04:54:49.532612Z",
     "iopub.status.idle": "2023-03-26T04:54:49.656625Z",
     "shell.execute_reply": "2023-03-26T04:54:49.654797Z"
    },
    "papermill": {
     "duration": 0.133863,
     "end_time": "2023-03-26T04:54:49.659271",
     "exception": false,
     "start_time": "2023-03-26T04:54:49.525408",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(505, 8)\n",
      "(127, 8)\n",
      "{'updrs_1': LinearRegression()}\n",
      "(505, 8)\n",
      "(127, 8)\n",
      "{'updrs_1': LinearRegression(), 'updrs_2': LinearRegression()}\n",
      "(505, 8)\n",
      "(127, 8)\n",
      "{'updrs_1': LinearRegression(), 'updrs_2': LinearRegression(), 'updrs_3': LinearRegression()}\n",
      "(505, 8)\n",
      "(127, 8)\n",
      "{'updrs_1': LinearRegression(), 'updrs_2': LinearRegression(), 'updrs_3': LinearRegression(), 'updrs_4': LinearRegression()}\n"
     ]
    }
   ],
   "source": [
    "model_dict = {}\n",
    "\n",
    "for i in [1,2,3,4]:\n",
    "    if (i == 1) | (i == 2):\n",
    "        full_training_data['updrs_'+str(i)+'_category'] = pd.cut(full_training_data['updrs_'+str(i)],bins=[-np.inf, 15., np.inf],labels=[1,2])\n",
    "    elif i == 3:\n",
    "        full_training_data['updrs_'+str(i)+'_category'] = pd.cut(full_training_data['updrs_'+str(i)],bins=[-np.inf, 20., 40., np.inf],labels=[1,2,3])\n",
    "    else:\n",
    "        full_training_data['updrs_'+str(i)+'_category'] = pd.cut(full_training_data['updrs_'+str(i)],bins=[-np.inf, 7.5, np.inf],labels=[1,2])\n",
    "        \n",
    "    split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "    for train_index, test_index in split.split(full_training_data, full_training_data['updrs_'+str(i)+'_category']):\n",
    "        strat_train_set = full_training_data.loc[train_index]\n",
    "        strat_test_set = full_training_data.loc[test_index]\n",
    "        \n",
    "    if i == 1:\n",
    "        strat_train_set = strat_train_set.drop(columns=['updrs_1_category'])\n",
    "        strat_test_set = strat_test_set.drop(columns=['updrs_1_category'])\n",
    "    elif i == 2:\n",
    "        strat_train_set = strat_train_set.drop(columns=['updrs_1_category','updrs_2_category'])\n",
    "        strat_test_set = strat_test_set.drop(columns=['updrs_1_category','updrs_2_category'])\n",
    "    elif i == 3:\n",
    "        strat_train_set = strat_train_set.drop(columns=['updrs_1_category','updrs_2_category','updrs_3_category'])\n",
    "        strat_test_set = strat_test_set.drop(columns=['updrs_1_category','updrs_2_category','updrs_3_category'])\n",
    "    else:\n",
    "        strat_train_set = strat_train_set.drop(columns=['updrs_1_category','updrs_2_category','updrs_3_category','updrs_4_category'])\n",
    "        strat_test_set = strat_test_set.drop(columns=['updrs_1_category','updrs_2_category','updrs_3_category','updrs_4_category'])\n",
    "    \n",
    "    strat_train_set_wo_labels = strat_train_set.drop(columns=['updrs_1','updrs_2','updrs_3','updrs_4','index'])\n",
    "    strat_train_set_labels = strat_train_set['updrs_'+str(i)].copy()\n",
    "    strat_train_set_numeric = strat_train_set_wo_labels.drop(columns=['visit_id','visit_month'])\n",
    "    strat_train_set_cat = strat_train_set_wo_labels[['visit_month']]\n",
    "\n",
    "    strat_test_set_wo_labels = strat_test_set.drop(columns=['updrs_1','updrs_2','updrs_3','updrs_4','index'])\n",
    "    strat_test_set_labels = strat_test_set['updrs_'+str(i)].copy()\n",
    "    \n",
    "    numeric_pipeline = Pipeline([\n",
    "        ('standard_scaler', StandardScaler())\n",
    "    ])\n",
    "\n",
    "    numeric_attributes = list(strat_train_set_numeric)\n",
    "    categorical_attributes = list(strat_train_set_cat)\n",
    "\n",
    "    full_pipeline = ColumnTransformer([\n",
    "        ('num', numeric_pipeline, numeric_attributes),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_attributes)\n",
    "    ])\n",
    "\n",
    "    strat_train_set_prepared = full_pipeline.fit_transform(strat_train_set_wo_labels)\n",
    "    print(strat_train_set_prepared.shape)\n",
    "    strat_test_set_prepared = full_pipeline.transform(strat_test_set_wo_labels)\n",
    "    print(strat_test_set_prepared.shape)\n",
    "    \n",
    "    lin_reg = LinearRegression()\n",
    "\n",
    "    model_dict['updrs_'+str(i)] = lin_reg.fit(strat_train_set_prepared, strat_train_set_labels)\n",
    "    print(model_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48aae9e1",
   "metadata": {
    "papermill": {
     "duration": 0.005407,
     "end_time": "2023-03-26T04:54:49.670657",
     "exception": false,
     "start_time": "2023-03-26T04:54:49.665250",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### The commands below are for debugging only, these were used to determine the bins corresponding to the train-test split specific to UPDRS tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be77322e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T04:54:49.684740Z",
     "iopub.status.busy": "2023-03-26T04:54:49.684267Z",
     "iopub.status.idle": "2023-03-26T04:54:49.689826Z",
     "shell.execute_reply": "2023-03-26T04:54:49.688481Z"
    },
    "papermill": {
     "duration": 0.015651,
     "end_time": "2023-03-26T04:54:49.692546",
     "exception": false,
     "start_time": "2023-03-26T04:54:49.676895",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#full_training_data_melted[['updrs_test_score','PeptideAbundance','NPX','group_key']].corr()\n",
    "#full_training_data[['updrs_1','updrs_2','updrs_3','updrs_4']].hist(figsize=(20,15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "278cfaf1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T04:54:49.707332Z",
     "iopub.status.busy": "2023-03-26T04:54:49.705840Z",
     "iopub.status.idle": "2023-03-26T04:54:49.715982Z",
     "shell.execute_reply": "2023-03-26T04:54:49.714553Z"
    },
    "papermill": {
     "duration": 0.020453,
     "end_time": "2023-03-26T04:54:49.718882",
     "exception": false,
     "start_time": "2023-03-26T04:54:49.698429",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"full_training_data['updrs_2_category'] = pd.cut(full_training_data['updrs_2'],\\n                                                          bins=[-np.inf, 15., np.inf],\\n                                                          labels=[1,2])\\n\\nfull_training_data['updrs_3_category'] = pd.cut(full_training_data['updrs_3'],\\n                                                          bins=[-np.inf, 20., 40., np.inf],\\n                                                          labels=[1,2,3])\\n\\nfull_training_data['updrs_4_category'] = pd.cut(full_training_data['updrs_4'],\\n                                                          bins=[-np.inf, 7.5, np.inf],\\n                                                          labels=[1,2])\\n\\nfull_training_data['updrs_4_category'].hist()\\n\\nfull_training_data['updrs_4_category'].unique()\\nsplit = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\\nfor train_index, test_index in split.split(full_training_data, full_training_data['updrs_4_category']):\\n    strat_train_set = full_training_data.loc[train_index]\\n    strat_test_set = full_training_data.loc[test_index]\\n    \\nprint(strat_test_set['updrs_4_category'].value_counts()/len(strat_test_set))\\nprint(strat_train_set['updrs_4_category'].value_counts()/len(strat_train_set))\\n\\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"full_training_data['updrs_2_category'] = pd.cut(full_training_data['updrs_2'],\n",
    "                                                          bins=[-np.inf, 15., np.inf],\n",
    "                                                          labels=[1,2])\n",
    "\n",
    "full_training_data['updrs_3_category'] = pd.cut(full_training_data['updrs_3'],\n",
    "                                                          bins=[-np.inf, 20., 40., np.inf],\n",
    "                                                          labels=[1,2,3])\n",
    "\n",
    "full_training_data['updrs_4_category'] = pd.cut(full_training_data['updrs_4'],\n",
    "                                                          bins=[-np.inf, 7.5, np.inf],\n",
    "                                                          labels=[1,2])\n",
    "\n",
    "full_training_data['updrs_4_category'].hist()\n",
    "\n",
    "full_training_data['updrs_4_category'].unique()\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "for train_index, test_index in split.split(full_training_data, full_training_data['updrs_4_category']):\n",
    "    strat_train_set = full_training_data.loc[train_index]\n",
    "    strat_test_set = full_training_data.loc[test_index]\n",
    "    \n",
    "print(strat_test_set['updrs_4_category'].value_counts()/len(strat_test_set))\n",
    "print(strat_train_set['updrs_4_category'].value_counts()/len(strat_train_set))\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6b5181",
   "metadata": {
    "papermill": {
     "duration": 0.005467,
     "end_time": "2023-03-26T04:54:49.730475",
     "exception": false,
     "start_time": "2023-03-26T04:54:49.725008",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Testing the RMSE\n",
    "#### RMSE <= 0.75 : Very good accuracy | 0.75 < RMSE <= 1.0 : Good accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aafb11b2",
   "metadata": {
    "papermill": {
     "duration": 0.005629,
     "end_time": "2023-03-26T04:54:49.742508",
     "exception": false,
     "start_time": "2023-03-26T04:54:49.736879",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### First on train data (train split from the full training dataset)\n",
    "#### 2nd on test data (test split from the full training dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "169c5d2e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T04:54:49.756382Z",
     "iopub.status.busy": "2023-03-26T04:54:49.755880Z",
     "iopub.status.idle": "2023-03-26T04:54:49.762607Z",
     "shell.execute_reply": "2023-03-26T04:54:49.761625Z"
    },
    "papermill": {
     "duration": 0.016495,
     "end_time": "2023-03-26T04:54:49.764998",
     "exception": false,
     "start_time": "2023-03-26T04:54:49.748503",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"train_df_predictions = lin_reg_model_updrs_4.predict(strat_train_set_prepared)\\nmse = mean_squared_error(strat_train_set_labels, train_df_predictions)\\nrmse = np.sqrt(mse)\\nprint(rmse)\\n\\ntest_df_predictions = lin_reg_model_updrs_4.predict(strat_test_set_prepared)\\nmse = mean_squared_error(strat_test_set_labels, test_df_predictions)\\nrmse = np.sqrt(mse)\\nprint(rmse)\\n\\nmodel_dict['updrs_4'] = lin_reg_model_updrs_4\\nmodel_dict\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"train_df_predictions = lin_reg_model_updrs_4.predict(strat_train_set_prepared)\n",
    "mse = mean_squared_error(strat_train_set_labels, train_df_predictions)\n",
    "rmse = np.sqrt(mse)\n",
    "print(rmse)\n",
    "\n",
    "test_df_predictions = lin_reg_model_updrs_4.predict(strat_test_set_prepared)\n",
    "mse = mean_squared_error(strat_test_set_labels, test_df_predictions)\n",
    "rmse = np.sqrt(mse)\n",
    "print(rmse)\n",
    "\n",
    "model_dict['updrs_4'] = lin_reg_model_updrs_4\n",
    "model_dict\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f4fd1c",
   "metadata": {
    "papermill": {
     "duration": 0.005757,
     "end_time": "2023-03-26T04:54:49.776852",
     "exception": false,
     "start_time": "2023-03-26T04:54:49.771095",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### The below cell is only for debugging the function get_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa105275",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T04:54:49.791257Z",
     "iopub.status.busy": "2023-03-26T04:54:49.790855Z",
     "iopub.status.idle": "2023-03-26T04:54:49.818787Z",
     "shell.execute_reply": "2023-03-26T04:54:49.817746Z"
    },
    "papermill": {
     "duration": 0.038816,
     "end_time": "2023-03-26T04:54:49.821822",
     "exception": false,
     "start_time": "2023-03-26T04:54:49.783006",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_full_test_data(df_test, df_proteins=pd.DataFrame(), df_peptides=pd.DataFrame()):\n",
    "    \n",
    "    if  (df_proteins.shape[0] == 0) & (df_peptides.shape[0] == 0):\n",
    "        \n",
    "        print('only the test dataframe has data, proteins and peptides info absent')\n",
    "        full_test_data = df_test[['visit_id','visit_month']]\n",
    "        full_test_data['npx_mean'] = 0\n",
    "        full_test_data['npx_median'] = 0\n",
    "        full_test_data['peptide_mean'] = 0\n",
    "        full_test_data['peptide_median'] = 0\n",
    "        \n",
    "        full_test_data = full_test_data.drop_duplicates(keep='first')\n",
    "        full_test_data = full_test_data[['visit_id','visit_month','npx_mean','npx_median','peptide_mean','peptide_median']]\n",
    "\n",
    "        full_test_data = full_test_data.reset_index()\n",
    "        full_test_data = full_test_data.drop(columns=['index'])\n",
    "        return full_test_data\n",
    "    \n",
    "    elif (df_proteins.shape[0] == 0) & (df_peptides.shape[0] != 0):\n",
    "        \n",
    "        print('no proteins only peptides')\n",
    "        full_test_data = pd.DataFrame()\n",
    "        \n",
    "        df_peptides = pd.merge(df_peptides, df_test, on=['patient_id','visit_id','visit_month'], suffixes=['_left','_right'], how='outer')\n",
    "        df_peptides['PeptideAbundance'] = np.where(df_peptides['PeptideAbundance'].isna(), 0, df_peptides['PeptideAbundance'])\n",
    "\n",
    "        for i in [0,6,12,24]:\n",
    "            temp = df_peptides[df_peptides['visit_month']==i]\n",
    "            full_test_data = full_test_data.append(temp)\n",
    "        \n",
    "        del df_proteins, df_peptides\n",
    "            \n",
    "        new_features = full_test_data.groupby(['visit_id','visit_month']).agg(peptide_mean=('PeptideAbundance', 'mean'), peptide_median=('PeptideAbundance', 'median')\n",
    "                                                              ).reset_index(level=['visit_id','visit_month'])\n",
    "\n",
    "        full_test_data = pd.merge(full_test_data, new_features, on=['visit_id','visit_month'], how='inner')\n",
    "        full_test_data['npx_mean'] = 0\n",
    "        full_test_data['npx_median'] = 0\n",
    "        full_test_data = full_test_data.drop_duplicates(keep='first')\n",
    "        full_test_data = full_test_data[['visit_id','visit_month','npx_mean','npx_median','peptide_mean','peptide_median']]\n",
    "\n",
    "        full_test_data = full_test_data.reset_index()\n",
    "        full_test_data = full_test_data.drop(columns=['index'])\n",
    "        \n",
    "        return full_test_data\n",
    "            \n",
    "    elif (df_peptides.shape[0] == 0) & (df_proteins.shape[0] != 0):\n",
    "        \n",
    "        print('no peptides only proteins')\n",
    "        full_test_data = pd.DataFrame()\n",
    "        \n",
    "        df_proteins = pd.merge(df_proteins, df_test, on=['patient_id','visit_id','visit_month'], suffixes=['_left','_right'], how='outer')\n",
    "        df_proteins['NPX'] = np.where(df_proteins['NPX'].isna(), 0, df_proteins['NPX'])\n",
    "\n",
    "        for i in [0,6,12,24]:\n",
    "            temp = df_proteins[df_proteins['visit_month']==i]\n",
    "            full_test_data = full_test_data.append(temp)\n",
    "            \n",
    "        new_features = full_test_data.groupby(['visit_id','visit_month']).agg(npx_mean=('NPX', 'mean'), npx_median=('NPX', 'median')\n",
    "                                                              ).reset_index(level=['visit_id','visit_month'])\n",
    "\n",
    "        full_test_data = pd.merge(full_test_data, new_features, on=['visit_id','visit_month'], how='inner')\n",
    "        full_test_data['peptide_mean'] = 0\n",
    "        full_test_data['peptide_median'] = 0\n",
    "        full_test_data = full_test_data.drop_duplicates(keep='first')\n",
    "        full_test_data = full_test_data[['visit_id','visit_month','npx_mean','npx_median','peptide_mean','peptide_median']]\n",
    "\n",
    "        full_test_data = full_test_data.reset_index()\n",
    "        full_test_data = full_test_data.drop(columns=['index'])\n",
    "        \n",
    "        return full_test_data\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        print('both proteins and peptides are present')\n",
    "        \n",
    "        pro_pep_join = pd.merge(df_proteins, df_peptides, on=['patient_id','visit_id','visit_month','UniProt'], suffixes=['_left','_right'], how='outer')\n",
    "        del df_proteins, df_peptides\n",
    "        \n",
    "        pro_pep_join_test = pd.merge(pro_pep_join, df_test, on=['patient_id','visit_id','visit_month'], suffixes=['_left','_right'], how='outer')\n",
    "        \n",
    "        pro_pep_join_test['NPX'] = np.where(pro_pep_join_test['NPX'].isna(), 0, pro_pep_join_test['NPX'])\n",
    "        pro_pep_join_test['PeptideAbundance'] = np.where(pro_pep_join_test['PeptideAbundance'].isna(), 0, pro_pep_join_test['PeptideAbundance'])\n",
    "        \n",
    "        del pro_pep_join\n",
    "        gc.collect()\n",
    "\n",
    "        full_test_data = pd.DataFrame()\n",
    "\n",
    "        for i in [0,6,12,24]:\n",
    "            temp = pro_pep_join_test[pro_pep_join_test['visit_month']==i]\n",
    "            full_test_data = full_test_data.append(temp)\n",
    "\n",
    "        new_features = full_test_data.groupby(['visit_id','visit_month']).agg(npx_mean=('NPX', 'mean'), npx_median=('NPX', 'median')\n",
    "                                                                                  , peptide_mean=('PeptideAbundance', 'mean')\n",
    "                                                                              , peptide_median=('PeptideAbundance', 'median')\n",
    "                                                                  ).reset_index(level=['visit_id','visit_month'])\n",
    "\n",
    "        full_test_data = pd.merge(full_test_data, new_features, on=['visit_id','visit_month'], how='inner')\n",
    "        full_test_data = full_test_data.drop_duplicates(keep='first')\n",
    "        full_test_data = full_test_data[['visit_id','visit_month','npx_mean','npx_median','peptide_mean','peptide_median']]\n",
    "\n",
    "        full_test_data = full_test_data.reset_index()\n",
    "        full_test_data = full_test_data.drop(columns=['index'])\n",
    "        \n",
    "        return full_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ccaaf0ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T04:54:49.837149Z",
     "iopub.status.busy": "2023-03-26T04:54:49.836753Z",
     "iopub.status.idle": "2023-03-26T04:54:49.849877Z",
     "shell.execute_reply": "2023-03-26T04:54:49.848421Z"
    },
    "papermill": {
     "duration": 0.02346,
     "end_time": "2023-03-26T04:54:49.852547",
     "exception": false,
     "start_time": "2023-03-26T04:54:49.829087",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_predictions(model_dict, sklearn_pipeline, df_test, df_proteins=pd.DataFrame(), df_peptides=pd.DataFrame()):\n",
    "    \n",
    "    list_of_updrs_tests = ['updrs_1','updrs_2','updrs_3','updrs_4']\n",
    "    result = pd.DataFrame()\n",
    "    \n",
    "    full_test_data = get_full_test_data(df_test=df_test, df_proteins=df_proteins, df_peptides=df_peptides)\n",
    "    \n",
    "    if full_test_data.shape[0] != 0:\n",
    "        df_prepared = sklearn_pipeline.transform(full_test_data)\n",
    "        print(df_prepared.shape)\n",
    "\n",
    "        for u in list_of_updrs_tests:\n",
    "            full_test_data['result_' + str(u)] = pd.DataFrame(model_dict[u].predict(df_prepared),columns=['rating']).round(decimals=0)\n",
    "\n",
    "        for m in [0, 6, 12, 24]:\n",
    "            for u in [1, 2, 3, 4]:\n",
    "                temp = full_test_data[['visit_id', 'visit_month', 'result_updrs_' + str(u)]]\n",
    "                temp['prediction_id'] = temp['visit_id'] + '_updrs_' + str(u) + '_plus_' + str(m) + '_months'\n",
    "                temp[\"rating\"] = temp[\"result_updrs_\" + str(u)]\n",
    "                \n",
    "                temp = temp[['visit_id', 'visit_month', 'prediction_id', 'rating']]\n",
    "\n",
    "                result = result.append(temp)\n",
    "\n",
    "        result.sort_values(by=['visit_id', 'visit_month'], inplace=True)\n",
    "        result = result[['prediction_id', 'rating']]\n",
    "        result['prediction_id'] = result['prediction_id'].astype('string') \n",
    "        result['rating'] = result['rating'].astype('int') \n",
    "        result = result.drop_duplicates(subset=['prediction_id', 'rating'])\n",
    "        result = result.reset_index()\n",
    "        result.drop(columns=['index'], inplace=True)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c456c7c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T04:54:49.867278Z",
     "iopub.status.busy": "2023-03-26T04:54:49.866866Z",
     "iopub.status.idle": "2023-03-26T04:54:49.875190Z",
     "shell.execute_reply": "2023-03-26T04:54:49.873945Z"
    },
    "papermill": {
     "duration": 0.019226,
     "end_time": "2023-03-26T04:54:49.877780",
     "exception": false,
     "start_time": "2023-03-26T04:54:49.858554",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"df_test = pd.read_csv('/kaggle/input/amp-parkinsons-disease-progression-prediction/example_test_files/test.csv')\\n\\ntest_proteins = pd.read_csv('/kaggle/input/amp-parkinsons-disease-progression-prediction/example_test_files/test_proteins.csv')\\n#result = get_predictions(model_dict=model_dict, sklearn_pipeline=full_pipeline, df_test=df_test, df_proteins=test_proteins, df_peptides=pd.DataFrame())\\n\\ntest_peptides = pd.read_csv('/kaggle/input/amp-parkinsons-disease-progression-prediction/example_test_files/test_peptides.csv')\\n#result = get_predictions(model_dict=model_dict, sklearn_pipeline=full_pipeline, df_test=df_test, df_proteins=pd.DataFrame(), df_peptides=test_peptides)\\n\\nresult = get_predictions(model_dict=model_dict, sklearn_pipeline=full_pipeline, df_test=df_test, df_proteins=test_proteins, df_peptides=test_peptides)\\n\\n#result = get_predictions(model_dict=model_dict, sklearn_pipeline=full_pipeline)\\n\\n#result\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"df_test = pd.read_csv('/kaggle/input/amp-parkinsons-disease-progression-prediction/example_test_files/test.csv')\n",
    "\n",
    "test_proteins = pd.read_csv('/kaggle/input/amp-parkinsons-disease-progression-prediction/example_test_files/test_proteins.csv')\n",
    "#result = get_predictions(model_dict=model_dict, sklearn_pipeline=full_pipeline, df_test=df_test, df_proteins=test_proteins, df_peptides=pd.DataFrame())\n",
    "\n",
    "test_peptides = pd.read_csv('/kaggle/input/amp-parkinsons-disease-progression-prediction/example_test_files/test_peptides.csv')\n",
    "#result = get_predictions(model_dict=model_dict, sklearn_pipeline=full_pipeline, df_test=df_test, df_proteins=pd.DataFrame(), df_peptides=test_peptides)\n",
    "\n",
    "result = get_predictions(model_dict=model_dict, sklearn_pipeline=full_pipeline, df_test=df_test, df_proteins=test_proteins, df_peptides=test_peptides)\n",
    "\n",
    "#result = get_predictions(model_dict=model_dict, sklearn_pipeline=full_pipeline)\n",
    "\n",
    "#result\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "efd613a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T04:54:49.892056Z",
     "iopub.status.busy": "2023-03-26T04:54:49.891608Z",
     "iopub.status.idle": "2023-03-26T04:54:50.785557Z",
     "shell.execute_reply": "2023-03-26T04:54:50.784139Z"
    },
    "papermill": {
     "duration": 0.904703,
     "end_time": "2023-03-26T04:54:50.788636",
     "exception": false,
     "start_time": "2023-03-26T04:54:49.883933",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This version of the API is not optimized and should not be used to estimate the runtime of your code on the hidden test set.\n",
      "['3342_0' '50423_0']\n",
      "['50423_0']\n",
      "['50423_0']\n",
      "both proteins and peptides are present\n",
      "(4088, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['3342_6' '50423_6']\n",
      "['3342_6']\n",
      "['3342_6']\n",
      "both proteins and peptides are present\n",
      "(4148, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "import amp_pd_peptide\n",
    "env = amp_pd_peptide.make_env()   # initialize the environment\n",
    "iter_test = env.iter_test()\n",
    "\n",
    "for (test, test_peptides, test_proteins, submission) in iter_test:\n",
    "    print(test.visit_id.unique())\n",
    "    print(test_peptides.visit_id.unique())\n",
    "    print(test_proteins.visit_id.unique())\n",
    "    result = get_predictions(model_dict=model_dict, sklearn_pipeline=full_pipeline, df_test=test, df_proteins=test_proteins, df_peptides=test_peptides)\n",
    "    env.predict(result)\n",
    "    \n",
    "##result.to_csv('/kaggle/working/submission.csv', header=True, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 17.73762,
   "end_time": "2023-03-26T04:54:51.619340",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-03-26T04:54:33.881720",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
