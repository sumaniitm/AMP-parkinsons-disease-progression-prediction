{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4426fa8",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-03-26T06:32:08.290936Z",
     "iopub.status.busy": "2023-03-26T06:32:08.290466Z",
     "iopub.status.idle": "2023-03-26T06:32:09.634472Z",
     "shell.execute_reply": "2023-03-26T06:32:09.633073Z"
    },
    "papermill": {
     "duration": 1.35759,
     "end_time": "2023-03-26T06:32:09.638088",
     "exception": false,
     "start_time": "2023-03-26T06:32:08.280498",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/amp-parkinsons-disease-progression-prediction/train_proteins.csv\n",
      "/kaggle/input/amp-parkinsons-disease-progression-prediction/train_clinical_data.csv\n",
      "/kaggle/input/amp-parkinsons-disease-progression-prediction/public_timeseries_testing_util.py\n",
      "/kaggle/input/amp-parkinsons-disease-progression-prediction/supplemental_clinical_data.csv\n",
      "/kaggle/input/amp-parkinsons-disease-progression-prediction/train_peptides.csv\n",
      "/kaggle/input/amp-parkinsons-disease-progression-prediction/amp_pd_peptide/competition.cpython-37m-x86_64-linux-gnu.so\n",
      "/kaggle/input/amp-parkinsons-disease-progression-prediction/amp_pd_peptide/__init__.py\n",
      "/kaggle/input/amp-parkinsons-disease-progression-prediction/example_test_files/sample_submission.csv\n",
      "/kaggle/input/amp-parkinsons-disease-progression-prediction/example_test_files/test_proteins.csv\n",
      "/kaggle/input/amp-parkinsons-disease-progression-prediction/example_test_files/test_peptides.csv\n",
      "/kaggle/input/amp-parkinsons-disease-progression-prediction/example_test_files/test.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "import gc\n",
    "from pandas.plotting import scatter_matrix\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20918fca",
   "metadata": {
    "papermill": {
     "duration": 0.007001,
     "end_time": "2023-03-26T06:32:09.652139",
     "exception": false,
     "start_time": "2023-03-26T06:32:09.645138",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "* #### Get the relevant training datasets and combine them to form the full training set with Proteins and Peptides\n",
    "* #### Remove the NaNs from the UPDRS test scores, using the mean from within the same group of UPDRS test scores, e.g. NaNs in updrs_4 are filled with mean of updrs_4\n",
    "* #### Create new mean and median based features and get rid of Proteins Expressions (NPX) and Peptide Abundance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d1cfe24",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T06:32:09.668012Z",
     "iopub.status.busy": "2023-03-26T06:32:09.667182Z",
     "iopub.status.idle": "2023-03-26T06:32:12.977125Z",
     "shell.execute_reply": "2023-03-26T06:32:12.975815Z"
    },
    "papermill": {
     "duration": 3.321125,
     "end_time": "2023-03-26T06:32:12.979970",
     "exception": false,
     "start_time": "2023-03-26T06:32:09.658845",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>visit_id</th>\n",
       "      <th>visit_month</th>\n",
       "      <th>npx_mean</th>\n",
       "      <th>npx_median</th>\n",
       "      <th>peptide_mean</th>\n",
       "      <th>peptide_median</th>\n",
       "      <th>updrs_1</th>\n",
       "      <th>updrs_2</th>\n",
       "      <th>updrs_3</th>\n",
       "      <th>updrs_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>55_0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.028789e+07</td>\n",
       "      <td>1221530.0</td>\n",
       "      <td>748153.907014</td>\n",
       "      <td>93134.80</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>931</td>\n",
       "      <td>1517_0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.579576e+07</td>\n",
       "      <td>897182.0</td>\n",
       "      <td>618823.150490</td>\n",
       "      <td>65253.60</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1833</td>\n",
       "      <td>1923_0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.889800e+07</td>\n",
       "      <td>1299230.0</td>\n",
       "      <td>763459.201459</td>\n",
       "      <td>92280.90</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2710</td>\n",
       "      <td>2660_0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.298973e+07</td>\n",
       "      <td>1078570.0</td>\n",
       "      <td>532250.381374</td>\n",
       "      <td>73461.05</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3620</td>\n",
       "      <td>3636_0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.367422e+07</td>\n",
       "      <td>776581.0</td>\n",
       "      <td>501743.931250</td>\n",
       "      <td>54660.20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4495</td>\n",
       "      <td>3863_0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.279134e+07</td>\n",
       "      <td>885864.0</td>\n",
       "      <td>806928.584862</td>\n",
       "      <td>78719.90</td>\n",
       "      <td>8.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5291</td>\n",
       "      <td>4161_0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.647734e+07</td>\n",
       "      <td>1067620.0</td>\n",
       "      <td>699803.391029</td>\n",
       "      <td>77037.80</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6191</td>\n",
       "      <td>4172_0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.729472e+07</td>\n",
       "      <td>874171.0</td>\n",
       "      <td>620558.476752</td>\n",
       "      <td>68208.05</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7115</td>\n",
       "      <td>5027_0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.281632e+07</td>\n",
       "      <td>1134880.0</td>\n",
       "      <td>764893.568584</td>\n",
       "      <td>71828.35</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8025</td>\n",
       "      <td>5178_0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.815310e+07</td>\n",
       "      <td>998682.0</td>\n",
       "      <td>689200.799757</td>\n",
       "      <td>79225.50</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index visit_id  visit_month      npx_mean  npx_median   peptide_mean  \\\n",
       "0      0     55_0            0  2.028789e+07   1221530.0  748153.907014   \n",
       "1    931   1517_0            0  1.579576e+07    897182.0  618823.150490   \n",
       "2   1833   1923_0            0  1.889800e+07   1299230.0  763459.201459   \n",
       "3   2710   2660_0            0  1.298973e+07   1078570.0  532250.381374   \n",
       "4   3620   3636_0            0  1.367422e+07    776581.0  501743.931250   \n",
       "5   4495   3863_0            0  2.279134e+07    885864.0  806928.584862   \n",
       "6   5291   4161_0            0  1.647734e+07   1067620.0  699803.391029   \n",
       "7   6191   4172_0            0  1.729472e+07    874171.0  620558.476752   \n",
       "8   7115   5027_0            0  2.281632e+07   1134880.0  764893.568584   \n",
       "9   8025   5178_0            0  1.815310e+07    998682.0  689200.799757   \n",
       "\n",
       "   peptide_median  updrs_1  updrs_2  updrs_3  updrs_4  \n",
       "0        93134.80     10.0      6.0     15.0      2.0  \n",
       "1        65253.60     11.0      6.0     25.0      5.0  \n",
       "2        92280.90      2.0      0.0      0.0      2.0  \n",
       "3        73461.05      2.0      0.0      0.0      2.0  \n",
       "4        54660.20      1.0      2.0      9.0      2.0  \n",
       "5        78719.90      8.0     13.0     36.0      4.0  \n",
       "6        77037.80      6.0      1.0      0.0      2.0  \n",
       "7        68208.05      2.0      0.0      0.0      2.0  \n",
       "8        71828.35      1.0      0.0      0.0      2.0  \n",
       "9        79225.50      9.0      1.0      3.0      2.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_proteins_df = pd.read_csv('/kaggle/input/amp-parkinsons-disease-progression-prediction/train_proteins.csv')\n",
    "\n",
    "train_peptides_df = pd.read_csv('/kaggle/input/amp-parkinsons-disease-progression-prediction/train_peptides.csv')\n",
    "\n",
    "pro_pep_join = pd.merge(train_proteins_df, train_peptides_df, on=['patient_id','visit_id','visit_month','UniProt'], how='inner')\n",
    "\n",
    "del train_proteins_df, train_peptides_df\n",
    "gc.collect()\n",
    "\n",
    "train_clinical_data_df = pd.read_csv('/kaggle/input/amp-parkinsons-disease-progression-prediction/train_clinical_data.csv')\n",
    "\n",
    "merged_data = pd.merge(pro_pep_join, train_clinical_data_df, on=['patient_id','visit_id','visit_month'], how='inner')\n",
    "\n",
    "del pro_pep_join, train_clinical_data_df\n",
    "gc.collect()\n",
    "\n",
    "full_training_data = pd.DataFrame()\n",
    "\n",
    "for i in [0,6,12,24]:\n",
    "    temp = merged_data[merged_data['visit_month']==i]\n",
    "    full_training_data = full_training_data.append(temp)\n",
    "    \n",
    "full_training_data = full_training_data.drop(columns=['UniProt','Peptide','upd23b_clinical_state_on_medication','patient_id'])\n",
    "\n",
    "list_of_updrs_tests = ['updrs_1','updrs_2','updrs_3','updrs_4']\n",
    "\n",
    "for i in range(len(list_of_updrs_tests)):\n",
    "    full_training_data[list_of_updrs_tests[i]].fillna(full_training_data[list_of_updrs_tests[i]].mean().round(decimals = 0), inplace=True)\n",
    "\n",
    "new_features = full_training_data.groupby(['visit_id','visit_month']).agg(npx_mean=('NPX', 'mean'), npx_median=('NPX', 'median')\n",
    "                                                                          , peptide_mean=('PeptideAbundance', 'mean'), peptide_median=('PeptideAbundance', 'median')\n",
    "                                                          ).reset_index(level=['visit_id','visit_month'])\n",
    "\n",
    "full_training_data = pd.merge(full_training_data, new_features, on=['visit_id','visit_month'], how='inner')\n",
    "full_training_data = full_training_data.drop(columns=['NPX','PeptideAbundance'])\n",
    "full_training_data = full_training_data.drop_duplicates(keep='first')\n",
    "full_training_data = full_training_data[['visit_id','visit_month','npx_mean','npx_median','peptide_mean','peptide_median','updrs_1','updrs_2','updrs_3','updrs_4']]\n",
    "\n",
    "full_training_data = full_training_data.reset_index()\n",
    "full_training_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21361603",
   "metadata": {
    "papermill": {
     "duration": 0.006697,
     "end_time": "2023-03-26T06:32:12.993832",
     "exception": false,
     "start_time": "2023-03-26T06:32:12.987135",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Check for NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f966411",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T06:32:13.010013Z",
     "iopub.status.busy": "2023-03-26T06:32:13.009581Z",
     "iopub.status.idle": "2023-03-26T06:32:13.020036Z",
     "shell.execute_reply": "2023-03-26T06:32:13.018827Z"
    },
    "papermill": {
     "duration": 0.021692,
     "end_time": "2023-03-26T06:32:13.022558",
     "exception": false,
     "start_time": "2023-03-26T06:32:13.000866",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index             0\n",
       "visit_id          0\n",
       "visit_month       0\n",
       "npx_mean          0\n",
       "npx_median        0\n",
       "peptide_mean      0\n",
       "peptide_median    0\n",
       "updrs_1           0\n",
       "updrs_2           0\n",
       "updrs_3           0\n",
       "updrs_4           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_training_data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e6c084",
   "metadata": {
    "papermill": {
     "duration": 0.00683,
     "end_time": "2023-03-26T06:32:13.036607",
     "exception": false,
     "start_time": "2023-03-26T06:32:13.029777",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### We will attempt to train one model each for each of the UPDRS tests. To do that, we will also proceed to create a train-test split on the Training dataset specific to each of the UPDRS test, to test out the accuracy of the developed models\n",
    "#### We will store all the models in a dictionary\n",
    "#### The following cells (except the declaration of the model dict) will be repeated for all UPDRS tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc1189a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T06:32:13.053090Z",
     "iopub.status.busy": "2023-03-26T06:32:13.052652Z",
     "iopub.status.idle": "2023-03-26T06:32:13.062758Z",
     "shell.execute_reply": "2023-03-26T06:32:13.061424Z"
    },
    "papermill": {
     "duration": 0.02117,
     "end_time": "2023-03-26T06:32:13.064965",
     "exception": false,
     "start_time": "2023-03-26T06:32:13.043795",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"model_dict = {}\\n\\nfor i in [1,2,3,4]:\\n    if (i == 1) | (i == 2):\\n        full_training_data['updrs_'+str(i)+'_category'] = pd.cut(full_training_data['updrs_'+str(i)],bins=[-np.inf, 15., np.inf],labels=[1,2])\\n    elif i == 3:\\n        full_training_data['updrs_'+str(i)+'_category'] = pd.cut(full_training_data['updrs_'+str(i)],bins=[-np.inf, 20., 40., np.inf],labels=[1,2,3])\\n    else:\\n        full_training_data['updrs_'+str(i)+'_category'] = pd.cut(full_training_data['updrs_'+str(i)],bins=[-np.inf, 7.5, np.inf],labels=[1,2])\\n        \\n    split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\\n    for train_index, test_index in split.split(full_training_data, full_training_data['updrs_'+str(i)+'_category']):\\n        strat_train_set = full_training_data.loc[train_index]\\n        strat_test_set = full_training_data.loc[test_index]\\n        \\n    if i == 1:\\n        strat_train_set = strat_train_set.drop(columns=['updrs_1_category'])\\n        strat_test_set = strat_test_set.drop(columns=['updrs_1_category'])\\n    elif i == 2:\\n        strat_train_set = strat_train_set.drop(columns=['updrs_1_category','updrs_2_category'])\\n        strat_test_set = strat_test_set.drop(columns=['updrs_1_category','updrs_2_category'])\\n    elif i == 3:\\n        strat_train_set = strat_train_set.drop(columns=['updrs_1_category','updrs_2_category','updrs_3_category'])\\n        strat_test_set = strat_test_set.drop(columns=['updrs_1_category','updrs_2_category','updrs_3_category'])\\n    else:\\n        strat_train_set = strat_train_set.drop(columns=['updrs_1_category','updrs_2_category','updrs_3_category','updrs_4_category'])\\n        strat_test_set = strat_test_set.drop(columns=['updrs_1_category','updrs_2_category','updrs_3_category','updrs_4_category'])\\n    \\n    strat_train_set_wo_labels = strat_train_set.drop(columns=['updrs_1','updrs_2','updrs_3','updrs_4','index'])\\n    strat_train_set_labels = strat_train_set['updrs_'+str(i)].copy()\\n    strat_train_set_numeric = strat_train_set_wo_labels.drop(columns=['visit_id','visit_month'])\\n    strat_train_set_cat = strat_train_set_wo_labels[['visit_month']]\\n\\n    strat_test_set_wo_labels = strat_test_set.drop(columns=['updrs_1','updrs_2','updrs_3','updrs_4','index'])\\n    strat_test_set_labels = strat_test_set['updrs_'+str(i)].copy()\\n    \\n    numeric_pipeline = Pipeline([\\n        ('standard_scaler', StandardScaler())\\n    ])\\n\\n    numeric_attributes = list(strat_train_set_numeric)\\n    categorical_attributes = list(strat_train_set_cat)\\n\\n    full_pipeline = ColumnTransformer([\\n        ('num', numeric_pipeline, numeric_attributes),\\n        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_attributes)\\n    ])\\n\\n    strat_train_set_prepared = full_pipeline.fit_transform(strat_train_set_wo_labels)\\n    print(strat_train_set_prepared.shape)\\n    strat_test_set_prepared = full_pipeline.transform(strat_test_set_wo_labels)\\n    print(strat_test_set_prepared.shape)\\n    \\n    lin_reg = LinearRegression()\\n\\n    model_dict['updrs_'+str(i)] = lin_reg.fit(strat_train_set_prepared, strat_train_set_labels)\\n    print(model_dict)\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"model_dict = {}\n",
    "\n",
    "for i in [1,2,3,4]:\n",
    "    if (i == 1) | (i == 2):\n",
    "        full_training_data['updrs_'+str(i)+'_category'] = pd.cut(full_training_data['updrs_'+str(i)],bins=[-np.inf, 15., np.inf],labels=[1,2])\n",
    "    elif i == 3:\n",
    "        full_training_data['updrs_'+str(i)+'_category'] = pd.cut(full_training_data['updrs_'+str(i)],bins=[-np.inf, 20., 40., np.inf],labels=[1,2,3])\n",
    "    else:\n",
    "        full_training_data['updrs_'+str(i)+'_category'] = pd.cut(full_training_data['updrs_'+str(i)],bins=[-np.inf, 7.5, np.inf],labels=[1,2])\n",
    "        \n",
    "    split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "    for train_index, test_index in split.split(full_training_data, full_training_data['updrs_'+str(i)+'_category']):\n",
    "        strat_train_set = full_training_data.loc[train_index]\n",
    "        strat_test_set = full_training_data.loc[test_index]\n",
    "        \n",
    "    if i == 1:\n",
    "        strat_train_set = strat_train_set.drop(columns=['updrs_1_category'])\n",
    "        strat_test_set = strat_test_set.drop(columns=['updrs_1_category'])\n",
    "    elif i == 2:\n",
    "        strat_train_set = strat_train_set.drop(columns=['updrs_1_category','updrs_2_category'])\n",
    "        strat_test_set = strat_test_set.drop(columns=['updrs_1_category','updrs_2_category'])\n",
    "    elif i == 3:\n",
    "        strat_train_set = strat_train_set.drop(columns=['updrs_1_category','updrs_2_category','updrs_3_category'])\n",
    "        strat_test_set = strat_test_set.drop(columns=['updrs_1_category','updrs_2_category','updrs_3_category'])\n",
    "    else:\n",
    "        strat_train_set = strat_train_set.drop(columns=['updrs_1_category','updrs_2_category','updrs_3_category','updrs_4_category'])\n",
    "        strat_test_set = strat_test_set.drop(columns=['updrs_1_category','updrs_2_category','updrs_3_category','updrs_4_category'])\n",
    "    \n",
    "    strat_train_set_wo_labels = strat_train_set.drop(columns=['updrs_1','updrs_2','updrs_3','updrs_4','index'])\n",
    "    strat_train_set_labels = strat_train_set['updrs_'+str(i)].copy()\n",
    "    strat_train_set_numeric = strat_train_set_wo_labels.drop(columns=['visit_id','visit_month'])\n",
    "    strat_train_set_cat = strat_train_set_wo_labels[['visit_month']]\n",
    "\n",
    "    strat_test_set_wo_labels = strat_test_set.drop(columns=['updrs_1','updrs_2','updrs_3','updrs_4','index'])\n",
    "    strat_test_set_labels = strat_test_set['updrs_'+str(i)].copy()\n",
    "    \n",
    "    numeric_pipeline = Pipeline([\n",
    "        ('standard_scaler', StandardScaler())\n",
    "    ])\n",
    "\n",
    "    numeric_attributes = list(strat_train_set_numeric)\n",
    "    categorical_attributes = list(strat_train_set_cat)\n",
    "\n",
    "    full_pipeline = ColumnTransformer([\n",
    "        ('num', numeric_pipeline, numeric_attributes),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_attributes)\n",
    "    ])\n",
    "\n",
    "    strat_train_set_prepared = full_pipeline.fit_transform(strat_train_set_wo_labels)\n",
    "    print(strat_train_set_prepared.shape)\n",
    "    strat_test_set_prepared = full_pipeline.transform(strat_test_set_wo_labels)\n",
    "    print(strat_test_set_prepared.shape)\n",
    "    \n",
    "    lin_reg = LinearRegression()\n",
    "\n",
    "    model_dict['updrs_'+str(i)] = lin_reg.fit(strat_train_set_prepared, strat_train_set_labels)\n",
    "    print(model_dict)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80e4b1b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T06:32:13.081842Z",
     "iopub.status.busy": "2023-03-26T06:32:13.081120Z",
     "iopub.status.idle": "2023-03-26T06:32:13.125836Z",
     "shell.execute_reply": "2023-03-26T06:32:13.124440Z"
    },
    "papermill": {
     "duration": 0.056472,
     "end_time": "2023-03-26T06:32:13.128738",
     "exception": false,
     "start_time": "2023-03-26T06:32:13.072266",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updrs_1\n",
      "(632, 5)\n",
      "(632,)\n",
      "updrs_2\n",
      "(632, 5)\n",
      "(632,)\n",
      "updrs_3\n",
      "(632, 5)\n",
      "(632,)\n",
      "updrs_4\n",
      "(632, 5)\n",
      "(632,)\n"
     ]
    }
   ],
   "source": [
    "model_dict = {}\n",
    "\n",
    "for u in list_of_updrs_tests:\n",
    "        \n",
    "    # Drop NAs\n",
    "    temp = full_training_data.dropna(subset=[u]) \n",
    "    print(u)\n",
    "    # Train data\n",
    "    X = temp[['visit_month','npx_mean','npx_median','peptide_mean','peptide_median']]\n",
    "    print(X.shape)\n",
    "    y = temp[u]\n",
    "    print(y.shape)\n",
    "    trained = LinearRegression().fit(X, y)\n",
    "    \n",
    "    # Save model\n",
    "    model_dict[u] = trained"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09774fcd",
   "metadata": {
    "papermill": {
     "duration": 0.007033,
     "end_time": "2023-03-26T06:32:13.143269",
     "exception": false,
     "start_time": "2023-03-26T06:32:13.136236",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### The commands below are for debugging only, these were used to determine the bins corresponding to the train-test split specific to UPDRS tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f255ca1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T06:32:13.160503Z",
     "iopub.status.busy": "2023-03-26T06:32:13.159611Z",
     "iopub.status.idle": "2023-03-26T06:32:13.165081Z",
     "shell.execute_reply": "2023-03-26T06:32:13.163796Z"
    },
    "papermill": {
     "duration": 0.017006,
     "end_time": "2023-03-26T06:32:13.167691",
     "exception": false,
     "start_time": "2023-03-26T06:32:13.150685",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#full_training_data_melted[['updrs_test_score','PeptideAbundance','NPX','group_key']].corr()\n",
    "#full_training_data[['updrs_1','updrs_2','updrs_3','updrs_4']].hist(figsize=(20,15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1513215f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T06:32:13.184603Z",
     "iopub.status.busy": "2023-03-26T06:32:13.184197Z",
     "iopub.status.idle": "2023-03-26T06:32:13.192205Z",
     "shell.execute_reply": "2023-03-26T06:32:13.191003Z"
    },
    "papermill": {
     "duration": 0.019579,
     "end_time": "2023-03-26T06:32:13.194808",
     "exception": false,
     "start_time": "2023-03-26T06:32:13.175229",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"full_training_data['updrs_2_category'] = pd.cut(full_training_data['updrs_2'],\\n                                                          bins=[-np.inf, 15., np.inf],\\n                                                          labels=[1,2])\\n\\nfull_training_data['updrs_3_category'] = pd.cut(full_training_data['updrs_3'],\\n                                                          bins=[-np.inf, 20., 40., np.inf],\\n                                                          labels=[1,2,3])\\n\\nfull_training_data['updrs_4_category'] = pd.cut(full_training_data['updrs_4'],\\n                                                          bins=[-np.inf, 7.5, np.inf],\\n                                                          labels=[1,2])\\n\\nfull_training_data['updrs_4_category'].hist()\\n\\nfull_training_data['updrs_4_category'].unique()\\nsplit = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\\nfor train_index, test_index in split.split(full_training_data, full_training_data['updrs_4_category']):\\n    strat_train_set = full_training_data.loc[train_index]\\n    strat_test_set = full_training_data.loc[test_index]\\n    \\nprint(strat_test_set['updrs_4_category'].value_counts()/len(strat_test_set))\\nprint(strat_train_set['updrs_4_category'].value_counts()/len(strat_train_set))\\n\\n\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"full_training_data['updrs_2_category'] = pd.cut(full_training_data['updrs_2'],\n",
    "                                                          bins=[-np.inf, 15., np.inf],\n",
    "                                                          labels=[1,2])\n",
    "\n",
    "full_training_data['updrs_3_category'] = pd.cut(full_training_data['updrs_3'],\n",
    "                                                          bins=[-np.inf, 20., 40., np.inf],\n",
    "                                                          labels=[1,2,3])\n",
    "\n",
    "full_training_data['updrs_4_category'] = pd.cut(full_training_data['updrs_4'],\n",
    "                                                          bins=[-np.inf, 7.5, np.inf],\n",
    "                                                          labels=[1,2])\n",
    "\n",
    "full_training_data['updrs_4_category'].hist()\n",
    "\n",
    "full_training_data['updrs_4_category'].unique()\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "for train_index, test_index in split.split(full_training_data, full_training_data['updrs_4_category']):\n",
    "    strat_train_set = full_training_data.loc[train_index]\n",
    "    strat_test_set = full_training_data.loc[test_index]\n",
    "    \n",
    "print(strat_test_set['updrs_4_category'].value_counts()/len(strat_test_set))\n",
    "print(strat_train_set['updrs_4_category'].value_counts()/len(strat_train_set))\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d30b14",
   "metadata": {
    "papermill": {
     "duration": 0.007068,
     "end_time": "2023-03-26T06:32:13.210496",
     "exception": false,
     "start_time": "2023-03-26T06:32:13.203428",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Testing the RMSE\n",
    "#### RMSE <= 0.75 : Very good accuracy | 0.75 < RMSE <= 1.0 : Good accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e713e94",
   "metadata": {
    "papermill": {
     "duration": 0.007108,
     "end_time": "2023-03-26T06:32:13.225053",
     "exception": false,
     "start_time": "2023-03-26T06:32:13.217945",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### First on train data (train split from the full training dataset)\n",
    "#### 2nd on test data (test split from the full training dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e89fcb7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T06:32:13.242422Z",
     "iopub.status.busy": "2023-03-26T06:32:13.241998Z",
     "iopub.status.idle": "2023-03-26T06:32:13.250207Z",
     "shell.execute_reply": "2023-03-26T06:32:13.248816Z"
    },
    "papermill": {
     "duration": 0.020202,
     "end_time": "2023-03-26T06:32:13.252913",
     "exception": false,
     "start_time": "2023-03-26T06:32:13.232711",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"train_df_predictions = lin_reg_model_updrs_4.predict(strat_train_set_prepared)\\nmse = mean_squared_error(strat_train_set_labels, train_df_predictions)\\nrmse = np.sqrt(mse)\\nprint(rmse)\\n\\ntest_df_predictions = lin_reg_model_updrs_4.predict(strat_test_set_prepared)\\nmse = mean_squared_error(strat_test_set_labels, test_df_predictions)\\nrmse = np.sqrt(mse)\\nprint(rmse)\\n\\nmodel_dict['updrs_4'] = lin_reg_model_updrs_4\\nmodel_dict\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"train_df_predictions = lin_reg_model_updrs_4.predict(strat_train_set_prepared)\n",
    "mse = mean_squared_error(strat_train_set_labels, train_df_predictions)\n",
    "rmse = np.sqrt(mse)\n",
    "print(rmse)\n",
    "\n",
    "test_df_predictions = lin_reg_model_updrs_4.predict(strat_test_set_prepared)\n",
    "mse = mean_squared_error(strat_test_set_labels, test_df_predictions)\n",
    "rmse = np.sqrt(mse)\n",
    "print(rmse)\n",
    "\n",
    "model_dict['updrs_4'] = lin_reg_model_updrs_4\n",
    "model_dict\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a9bb60",
   "metadata": {
    "papermill": {
     "duration": 0.007269,
     "end_time": "2023-03-26T06:32:13.267805",
     "exception": false,
     "start_time": "2023-03-26T06:32:13.260536",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### The below cell is only for debugging the function get_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bddb742d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T06:32:13.285284Z",
     "iopub.status.busy": "2023-03-26T06:32:13.284881Z",
     "iopub.status.idle": "2023-03-26T06:32:13.313444Z",
     "shell.execute_reply": "2023-03-26T06:32:13.312202Z"
    },
    "papermill": {
     "duration": 0.040725,
     "end_time": "2023-03-26T06:32:13.316136",
     "exception": false,
     "start_time": "2023-03-26T06:32:13.275411",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_full_test_data(df_test, df_proteins=pd.DataFrame(), df_peptides=pd.DataFrame()):\n",
    "    \n",
    "    if  (df_proteins.shape[0] == 0) & (df_peptides.shape[0] == 0):\n",
    "        \n",
    "        print('only the test dataframe has data, proteins and peptides info absent')\n",
    "        full_test_data = df_test[['visit_id','visit_month']]\n",
    "        full_test_data['npx_mean'] = 0\n",
    "        full_test_data['npx_median'] = 0\n",
    "        full_test_data['peptide_mean'] = 0\n",
    "        full_test_data['peptide_median'] = 0\n",
    "        \n",
    "        full_test_data = full_test_data.drop_duplicates(keep='first')\n",
    "        full_test_data = full_test_data[['visit_id','visit_month','npx_mean','npx_median','peptide_mean','peptide_median']]\n",
    "\n",
    "        full_test_data = full_test_data.reset_index()\n",
    "        full_test_data = full_test_data.drop(columns=['index'])\n",
    "        return full_test_data\n",
    "    \n",
    "    elif (df_proteins.shape[0] == 0) & (df_peptides.shape[0] != 0):\n",
    "        \n",
    "        print('no proteins only peptides')\n",
    "        full_test_data = pd.DataFrame()\n",
    "        \n",
    "        df_peptides = pd.merge(df_peptides, df_test, on=['patient_id','visit_id','visit_month'], suffixes=['_left','_right'], how='outer')\n",
    "        df_peptides['PeptideAbundance'] = np.where(df_peptides['PeptideAbundance'].isna(), 0, df_peptides['PeptideAbundance'])\n",
    "\n",
    "        for i in [0,6,12,24]:\n",
    "            temp = df_peptides[df_peptides['visit_month']==i]\n",
    "            full_test_data = full_test_data.append(temp)\n",
    "        \n",
    "        del df_proteins, df_peptides\n",
    "            \n",
    "        new_features = full_test_data.groupby(['visit_id','visit_month']).agg(peptide_mean=('PeptideAbundance', 'mean'), peptide_median=('PeptideAbundance', 'median')\n",
    "                                                              ).reset_index(level=['visit_id','visit_month'])\n",
    "\n",
    "        full_test_data = pd.merge(full_test_data, new_features, on=['visit_id','visit_month'], how='inner')\n",
    "        full_test_data['npx_mean'] = 0\n",
    "        full_test_data['npx_median'] = 0\n",
    "        full_test_data = full_test_data.drop_duplicates(keep='first')\n",
    "        full_test_data = full_test_data[['visit_id','visit_month','npx_mean','npx_median','peptide_mean','peptide_median']]\n",
    "\n",
    "        full_test_data = full_test_data.reset_index()\n",
    "        full_test_data = full_test_data.drop(columns=['index'])\n",
    "        \n",
    "        return full_test_data\n",
    "            \n",
    "    elif (df_peptides.shape[0] == 0) & (df_proteins.shape[0] != 0):\n",
    "        \n",
    "        print('no peptides only proteins')\n",
    "        full_test_data = pd.DataFrame()\n",
    "        \n",
    "        df_proteins = pd.merge(df_proteins, df_test, on=['patient_id','visit_id','visit_month'], suffixes=['_left','_right'], how='outer')\n",
    "        df_proteins['NPX'] = np.where(df_proteins['NPX'].isna(), 0, df_proteins['NPX'])\n",
    "\n",
    "        for i in [0,6,12,24]:\n",
    "            temp = df_proteins[df_proteins['visit_month']==i]\n",
    "            full_test_data = full_test_data.append(temp)\n",
    "            \n",
    "        new_features = full_test_data.groupby(['visit_id','visit_month']).agg(npx_mean=('NPX', 'mean'), npx_median=('NPX', 'median')\n",
    "                                                              ).reset_index(level=['visit_id','visit_month'])\n",
    "\n",
    "        full_test_data = pd.merge(full_test_data, new_features, on=['visit_id','visit_month'], how='inner')\n",
    "        full_test_data['peptide_mean'] = 0\n",
    "        full_test_data['peptide_median'] = 0\n",
    "        full_test_data = full_test_data.drop_duplicates(keep='first')\n",
    "        full_test_data = full_test_data[['visit_id','visit_month','npx_mean','npx_median','peptide_mean','peptide_median']]\n",
    "\n",
    "        full_test_data = full_test_data.reset_index()\n",
    "        full_test_data = full_test_data.drop(columns=['index'])\n",
    "        \n",
    "        return full_test_data\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        print('both proteins and peptides are present')\n",
    "        \n",
    "        pro_pep_join = pd.merge(df_proteins, df_peptides, on=['patient_id','visit_id','visit_month','UniProt'], suffixes=['_left','_right'], how='outer')\n",
    "        del df_proteins, df_peptides\n",
    "        \n",
    "        pro_pep_join_test = pd.merge(pro_pep_join, df_test, on=['patient_id','visit_id','visit_month'], suffixes=['_left','_right'], how='outer')\n",
    "        \n",
    "        pro_pep_join_test['NPX'] = np.where(pro_pep_join_test['NPX'].isna(), 0, pro_pep_join_test['NPX'])\n",
    "        pro_pep_join_test['PeptideAbundance'] = np.where(pro_pep_join_test['PeptideAbundance'].isna(), 0, pro_pep_join_test['PeptideAbundance'])\n",
    "        \n",
    "        del pro_pep_join\n",
    "        gc.collect()\n",
    "\n",
    "        full_test_data = pd.DataFrame()\n",
    "\n",
    "        for i in [0,6,12,24]:\n",
    "            temp = pro_pep_join_test[pro_pep_join_test['visit_month']==i]\n",
    "            full_test_data = full_test_data.append(temp)\n",
    "\n",
    "        new_features = full_test_data.groupby(['visit_id','visit_month']).agg(npx_mean=('NPX', 'mean'), npx_median=('NPX', 'median')\n",
    "                                                                                  , peptide_mean=('PeptideAbundance', 'mean')\n",
    "                                                                              , peptide_median=('PeptideAbundance', 'median')\n",
    "                                                                  ).reset_index(level=['visit_id','visit_month'])\n",
    "\n",
    "        full_test_data = pd.merge(full_test_data, new_features, on=['visit_id','visit_month'], how='inner')\n",
    "        full_test_data = full_test_data.drop_duplicates(keep='first')\n",
    "        full_test_data = full_test_data[['visit_id','visit_month','npx_mean','npx_median','peptide_mean','peptide_median']]\n",
    "\n",
    "        full_test_data = full_test_data.reset_index()\n",
    "        full_test_data = full_test_data.drop(columns=['index'])\n",
    "        \n",
    "        return full_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5585ed32",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T06:32:13.335261Z",
     "iopub.status.busy": "2023-03-26T06:32:13.334648Z",
     "iopub.status.idle": "2023-03-26T06:32:13.347353Z",
     "shell.execute_reply": "2023-03-26T06:32:13.345835Z"
    },
    "papermill": {
     "duration": 0.025568,
     "end_time": "2023-03-26T06:32:13.350048",
     "exception": false,
     "start_time": "2023-03-26T06:32:13.324480",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#def get_predictions(model_dict, sklearn_pipeline, df_test, df_proteins=pd.DataFrame(), df_peptides=pd.DataFrame()):\n",
    "def get_predictions(model_dict, df_test, df_proteins=pd.DataFrame(), df_peptides=pd.DataFrame()):\n",
    "    \n",
    "    list_of_updrs_tests = ['updrs_1','updrs_2','updrs_3','updrs_4']\n",
    "    result = pd.DataFrame()\n",
    "    \n",
    "    full_test_data = get_full_test_data(df_test=df_test, df_proteins=df_proteins, df_peptides=df_peptides)\n",
    "    \n",
    "    if full_test_data.shape[0] != 0:\n",
    "        \"\"\"df_prepared = sklearn_pipeline.transform(full_test_data)\n",
    "        print(df_prepared.shape)\"\"\"\n",
    "\n",
    "        for u in list_of_updrs_tests:\n",
    "            X = full_test_data[['visit_month','npx_mean','npx_median','peptide_mean','peptide_median']]\n",
    "            #full_test_data['result_' + str(u)] = pd.DataFrame(model_dict[u].predict(df_prepared),columns=['rating']).round(decimals=0)\n",
    "            full_test_data['result_' + str(u)] = np.ceil(model_dict[u].predict(X))\n",
    "\n",
    "        for m in [0, 6, 12, 24]:\n",
    "            for u in [1, 2, 3, 4]:\n",
    "                temp = full_test_data[['visit_id', 'visit_month', 'result_updrs_' + str(u)]]\n",
    "                temp['prediction_id'] = temp['visit_id'] + '_updrs_' + str(u) + '_plus_' + str(m) + '_months'\n",
    "                temp[\"rating\"] = temp[\"result_updrs_\" + str(u)]\n",
    "                \n",
    "                #temp = temp[['visit_id', 'visit_month', 'prediction_id', 'rating']]\n",
    "                temp = temp[['prediction_id', 'rating']]\n",
    "\n",
    "                result = result.append(temp)\n",
    "\n",
    "        #result.sort_values(by=['visit_id', 'visit_month'], inplace=True)\n",
    "        #result = result[['prediction_id', 'rating']]\n",
    "        #result['prediction_id'] = result['prediction_id'].astype('string') \n",
    "        #result['rating'] = result['rating'].astype('int') \n",
    "        result = result.drop_duplicates(subset=['prediction_id', 'rating'])\n",
    "        result = result.reset_index()\n",
    "        result.drop(columns=['index'], inplace=True)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f037ca3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T06:32:13.369051Z",
     "iopub.status.busy": "2023-03-26T06:32:13.368614Z",
     "iopub.status.idle": "2023-03-26T06:32:13.375916Z",
     "shell.execute_reply": "2023-03-26T06:32:13.374861Z"
    },
    "papermill": {
     "duration": 0.019635,
     "end_time": "2023-03-26T06:32:13.378156",
     "exception": false,
     "start_time": "2023-03-26T06:32:13.358521",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"df_test = pd.read_csv('/kaggle/input/amp-parkinsons-disease-progression-prediction/example_test_files/test.csv')\\n\\ntest_proteins = pd.read_csv('/kaggle/input/amp-parkinsons-disease-progression-prediction/example_test_files/test_proteins.csv')\\n#result = get_predictions(model_dict=model_dict, sklearn_pipeline=full_pipeline, df_test=df_test, df_proteins=test_proteins, df_peptides=pd.DataFrame())\\n\\ntest_peptides = pd.read_csv('/kaggle/input/amp-parkinsons-disease-progression-prediction/example_test_files/test_peptides.csv')\\n#result = get_predictions(model_dict=model_dict, sklearn_pipeline=full_pipeline, df_test=df_test, df_proteins=pd.DataFrame(), df_peptides=test_peptides)\\n\\nresult = get_predictions(model_dict=model_dict, sklearn_pipeline=full_pipeline, df_test=df_test, df_proteins=test_proteins, df_peptides=test_peptides)\\n\\n#result = get_predictions(model_dict=model_dict, sklearn_pipeline=full_pipeline)\\n\\nresult\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"df_test = pd.read_csv('/kaggle/input/amp-parkinsons-disease-progression-prediction/example_test_files/test.csv')\n",
    "\n",
    "test_proteins = pd.read_csv('/kaggle/input/amp-parkinsons-disease-progression-prediction/example_test_files/test_proteins.csv')\n",
    "#result = get_predictions(model_dict=model_dict, sklearn_pipeline=full_pipeline, df_test=df_test, df_proteins=test_proteins, df_peptides=pd.DataFrame())\n",
    "\n",
    "test_peptides = pd.read_csv('/kaggle/input/amp-parkinsons-disease-progression-prediction/example_test_files/test_peptides.csv')\n",
    "#result = get_predictions(model_dict=model_dict, sklearn_pipeline=full_pipeline, df_test=df_test, df_proteins=pd.DataFrame(), df_peptides=test_peptides)\n",
    "\n",
    "result = get_predictions(model_dict=model_dict, sklearn_pipeline=full_pipeline, df_test=df_test, df_proteins=test_proteins, df_peptides=test_peptides)\n",
    "\n",
    "#result = get_predictions(model_dict=model_dict, sklearn_pipeline=full_pipeline)\n",
    "\n",
    "result\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f4e3367",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T06:32:13.395428Z",
     "iopub.status.busy": "2023-03-26T06:32:13.395019Z",
     "iopub.status.idle": "2023-03-26T06:32:13.609773Z",
     "shell.execute_reply": "2023-03-26T06:32:13.608504Z"
    },
    "papermill": {
     "duration": 0.229386,
     "end_time": "2023-03-26T06:32:13.615359",
     "exception": false,
     "start_time": "2023-03-26T06:32:13.385973",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This version of the API is not optimized and should not be used to estimate the runtime of your code on the hidden test set.\n",
      "only the test dataframe has data, proteins and peptides info absent\n",
      "only the test dataframe has data, proteins and peptides info absent\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "import amp_pd_peptide\n",
    "env = amp_pd_peptide.make_env()   # initialize the environment\n",
    "iter_test = env.iter_test()\n",
    "\n",
    "for (test, test_peptides, test_proteins, submission) in iter_test:\n",
    "    #print(test.visit_id.unique())\n",
    "    #print(test_peptides.visit_id.unique())\n",
    "    #print(test_proteins.visit_id.unique())\n",
    "    #result = get_predictions(model_dict=model_dict, sklearn_pipeline=full_pipeline, df_test=test, df_proteins=test_proteins, df_peptides=test_peptides)\n",
    "    #result = get_predictions(model_dict=model_dict, df_test=test, df_proteins=test_proteins, df_peptides=test_peptides)\n",
    "    result = get_predictions(model_dict=model_dict, df_test=test)\n",
    "    env.predict(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf4acf3c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T06:32:13.633992Z",
     "iopub.status.busy": "2023-03-26T06:32:13.633587Z",
     "iopub.status.idle": "2023-03-26T06:32:13.641023Z",
     "shell.execute_reply": "2023-03-26T06:32:13.639823Z"
    },
    "papermill": {
     "duration": 0.019832,
     "end_time": "2023-03-26T06:32:13.643556",
     "exception": false,
     "start_time": "2023-03-26T06:32:13.623724",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'train = pd.read_csv(\"/kaggle/input/amp-parkinsons-disease-progression-prediction/train_clinical_data.csv\")\\nmodel = {}\\ntarget = [\"updrs_1\", \"updrs_2\", \"updrs_3\", \"updrs_4\"]\\n\\nfor u in target:\\n        \\n    # Drop NAs\\n    temp = train.dropna(subset=[u]) \\n    \\n    # Train data\\n    X = temp[\\'visit_month\\']\\n    y = temp[u]\\n        \\n    trained = LinearRegression().fit(X.values.reshape(-1, 1), y)\\n    \\n    # Save model\\n    model[u] = trained'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"train = pd.read_csv(\"/kaggle/input/amp-parkinsons-disease-progression-prediction/train_clinical_data.csv\")\n",
    "model = {}\n",
    "target = [\"updrs_1\", \"updrs_2\", \"updrs_3\", \"updrs_4\"]\n",
    "\n",
    "for u in target:\n",
    "        \n",
    "    # Drop NAs\n",
    "    temp = train.dropna(subset=[u]) \n",
    "    \n",
    "    # Train data\n",
    "    X = temp['visit_month']\n",
    "    y = temp[u]\n",
    "        \n",
    "    trained = LinearRegression().fit(X.values.reshape(-1, 1), y)\n",
    "    \n",
    "    # Save model\n",
    "    model[u] = trained\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "98deecbe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T06:32:13.663210Z",
     "iopub.status.busy": "2023-03-26T06:32:13.662534Z",
     "iopub.status.idle": "2023-03-26T06:32:13.668886Z",
     "shell.execute_reply": "2023-03-26T06:32:13.668051Z"
    },
    "papermill": {
     "duration": 0.019217,
     "end_time": "2023-03-26T06:32:13.671045",
     "exception": false,
     "start_time": "2023-03-26T06:32:13.651828",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def get_predictions(my_train, pro, model):\\n\\n    # Forecast\\n    my_train = my_train.fillna(0)\\n    \\n    for u in target:\\n        \\n        # Here is where we will save the final results\\n        my_train[\\'result_\\' + str(u)] = 0\\n  \\n        # Predict    \\n        X = my_train[\"visit_month\"]\\n        \\n        if u == \\'updrs_4\\':\\n            my_train[\\'result_\\' + str(u)] = 0\\n        else:\\n            my_train[\\'result_\\' + str(u)] = np.ceil(model[u].predict(X.values.reshape(-1, 1)))\\n\\n        \\n    # Format for final submission\\n    result = pd.DataFrame()\\n\\n    for m in [0, 6, 12, 24]:\\n        for u in [1, 2, 3, 4]:\\n\\n            temp = my_train[[\"visit_id\", \"result_updrs_\" + str(u)]]\\n            temp[\"prediction_id\"] = temp[\"visit_id\"] + \"_updrs_\" + str(u) + \"_plus_\" + str(m) + \"_months\"\\n            temp[\"rating\"] = temp[\"result_updrs_\" + str(u)]\\n            temp = temp [[\\'prediction_id\\', \\'rating\\']]\\n\\n            result = result.append(temp)            \\n    result = result.drop_duplicates(subset=[\\'prediction_id\\', \\'rating\\'])\\n\\n    return result'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"def get_predictions(my_train, pro, model):\n",
    "\n",
    "    # Forecast\n",
    "    my_train = my_train.fillna(0)\n",
    "    \n",
    "    for u in target:\n",
    "        \n",
    "        # Here is where we will save the final results\n",
    "        my_train['result_' + str(u)] = 0\n",
    "  \n",
    "        # Predict    \n",
    "        X = my_train[\"visit_month\"]\n",
    "        \n",
    "        if u == 'updrs_4':\n",
    "            my_train['result_' + str(u)] = 0\n",
    "        else:\n",
    "            my_train['result_' + str(u)] = np.ceil(model[u].predict(X.values.reshape(-1, 1)))\n",
    "\n",
    "        \n",
    "    # Format for final submission\n",
    "    result = pd.DataFrame()\n",
    "\n",
    "    for m in [0, 6, 12, 24]:\n",
    "        for u in [1, 2, 3, 4]:\n",
    "\n",
    "            temp = my_train[[\"visit_id\", \"result_updrs_\" + str(u)]]\n",
    "            temp[\"prediction_id\"] = temp[\"visit_id\"] + \"_updrs_\" + str(u) + \"_plus_\" + str(m) + \"_months\"\n",
    "            temp[\"rating\"] = temp[\"result_updrs_\" + str(u)]\n",
    "            temp = temp [['prediction_id', 'rating']]\n",
    "\n",
    "            result = result.append(temp)            \n",
    "    result = result.drop_duplicates(subset=['prediction_id', 'rating'])\n",
    "\n",
    "    return result\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bc37c6bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T06:32:13.690573Z",
     "iopub.status.busy": "2023-03-26T06:32:13.689927Z",
     "iopub.status.idle": "2023-03-26T06:32:13.694233Z",
     "shell.execute_reply": "2023-03-26T06:32:13.693075Z"
    },
    "papermill": {
     "duration": 0.017461,
     "end_time": "2023-03-26T06:32:13.696940",
     "exception": false,
     "start_time": "2023-03-26T06:32:13.679479",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run once to check results\n",
    "#get_predictions(train, None, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "251b6d62",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T06:32:13.716239Z",
     "iopub.status.busy": "2023-03-26T06:32:13.715817Z",
     "iopub.status.idle": "2023-03-26T06:32:13.723036Z",
     "shell.execute_reply": "2023-03-26T06:32:13.721786Z"
    },
    "papermill": {
     "duration": 0.019687,
     "end_time": "2023-03-26T06:32:13.725418",
     "exception": false,
     "start_time": "2023-03-26T06:32:13.705731",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"amp_pd_peptide.make_env.__called__ = False\\ntype(env)._state = type(type(env)._state).__dict__['INIT']\\niter_test = env.iter_test()\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"amp_pd_peptide.make_env.__called__ = False\n",
    "type(env)._state = type(type(env)._state).__dict__['INIT']\n",
    "iter_test = env.iter_test()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1f871f1d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T06:32:13.745430Z",
     "iopub.status.busy": "2023-03-26T06:32:13.744720Z",
     "iopub.status.idle": "2023-03-26T06:32:13.751671Z",
     "shell.execute_reply": "2023-03-26T06:32:13.750607Z"
    },
    "papermill": {
     "duration": 0.019526,
     "end_time": "2023-03-26T06:32:13.753986",
     "exception": false,
     "start_time": "2023-03-26T06:32:13.734460",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for (test, test_peptides, test_proteins, sample_submission) in iter_test:\\n        \\n    result = get_predictions(test, test_proteins, model)\\n\\n    env.predict(result)'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"for (test, test_peptides, test_proteins, sample_submission) in iter_test:\n",
    "        \n",
    "    result = get_predictions(test, test_proteins, model)\n",
    "\n",
    "    env.predict(result)\"\"\"   # register your predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4c95bef7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T06:32:13.773564Z",
     "iopub.status.busy": "2023-03-26T06:32:13.772881Z",
     "iopub.status.idle": "2023-03-26T06:32:13.779890Z",
     "shell.execute_reply": "2023-03-26T06:32:13.778732Z"
    },
    "papermill": {
     "duration": 0.019563,
     "end_time": "2023-03-26T06:32:13.782252",
     "exception": false,
     "start_time": "2023-03-26T06:32:13.762689",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'submission_copied = pd.read_csv(\"/kaggle/working/submission.csv\")\\nprint(submission_copied.shape)\\nprint(submission_copied.memory_usage(deep=True).sum()/1024/1024, \" MBs\")'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"submission_copied = pd.read_csv(\"/kaggle/working/submission.csv\")\n",
    "print(submission_copied.shape)\n",
    "print(submission_copied.memory_usage(deep=True).sum()/1024/1024, \" MBs\")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4bcdefa0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T06:32:13.802555Z",
     "iopub.status.busy": "2023-03-26T06:32:13.801873Z",
     "iopub.status.idle": "2023-03-26T06:32:13.809153Z",
     "shell.execute_reply": "2023-03-26T06:32:13.808188Z"
    },
    "papermill": {
     "duration": 0.020374,
     "end_time": "2023-03-26T06:32:13.811556",
     "exception": false,
     "start_time": "2023-03-26T06:32:13.791182",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'result_out = pd.DataFrame()\\n\\nfor (test, test_peptides, test_proteins, submission) in iter_test:\\n    print(test.visit_id.unique())\\n    print(test_peptides.visit_id.unique())\\n    print(test_proteins.visit_id.unique())\\n    result = get_predictions(model_dict=model_dict, sklearn_pipeline=full_pipeline, df_test=test, df_proteins=test_proteins, df_peptides=test_peptides)\\n    print(result.shape)\\n    result_out = result_out.append(result)\\n    print(result_out.shape)\\n    env.predict(result)'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"result_out = pd.DataFrame()\n",
    "\n",
    "for (test, test_peptides, test_proteins, submission) in iter_test:\n",
    "    print(test.visit_id.unique())\n",
    "    print(test_peptides.visit_id.unique())\n",
    "    print(test_proteins.visit_id.unique())\n",
    "    result = get_predictions(model_dict=model_dict, sklearn_pipeline=full_pipeline, df_test=test, df_proteins=test_proteins, df_peptides=test_peptides)\n",
    "    print(result.shape)\n",
    "    result_out = result_out.append(result)\n",
    "    print(result_out.shape)\n",
    "    env.predict(result)\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 16.703412,
   "end_time": "2023-03-26T06:32:14.643574",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-03-26T06:31:57.940162",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
