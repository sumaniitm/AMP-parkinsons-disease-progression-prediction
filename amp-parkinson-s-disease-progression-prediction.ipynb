{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nimport gc\nfrom pandas.plotting import scatter_matrix\n%matplotlib inline\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import StratifiedShuffleSplit\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\n\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.tree import DecisionTreeRegressor\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-03-27T18:30:44.678719Z","iopub.execute_input":"2023-03-27T18:30:44.679124Z","iopub.status.idle":"2023-03-27T18:30:45.494993Z","shell.execute_reply.started":"2023-03-27T18:30:44.679089Z","shell.execute_reply":"2023-03-27T18:30:45.493566Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/amp-parkinsons-disease-progression-prediction/train_proteins.csv\n/kaggle/input/amp-parkinsons-disease-progression-prediction/train_clinical_data.csv\n/kaggle/input/amp-parkinsons-disease-progression-prediction/public_timeseries_testing_util.py\n/kaggle/input/amp-parkinsons-disease-progression-prediction/supplemental_clinical_data.csv\n/kaggle/input/amp-parkinsons-disease-progression-prediction/train_peptides.csv\n/kaggle/input/amp-parkinsons-disease-progression-prediction/amp_pd_peptide/competition.cpython-37m-x86_64-linux-gnu.so\n/kaggle/input/amp-parkinsons-disease-progression-prediction/amp_pd_peptide/__init__.py\n/kaggle/input/amp-parkinsons-disease-progression-prediction/example_test_files/sample_submission.csv\n/kaggle/input/amp-parkinsons-disease-progression-prediction/example_test_files/test_proteins.csv\n/kaggle/input/amp-parkinsons-disease-progression-prediction/example_test_files/test_peptides.csv\n/kaggle/input/amp-parkinsons-disease-progression-prediction/example_test_files/test.csv\n","output_type":"stream"}]},{"cell_type":"markdown","source":"* #### Get the relevant training datasets and combine them to form the full training set with Proteins and Peptides\n* #### Remove the NaNs from the UPDRS test scores, using the mean from within the same group of UPDRS test scores, e.g. NaNs in updrs_4 are filled with mean of updrs_4\n* #### Create new mean and median based features and get rid of Proteins Expressions (NPX) and Peptide Abundance","metadata":{}},{"cell_type":"code","source":"train_proteins_df = pd.read_csv('/kaggle/input/amp-parkinsons-disease-progression-prediction/train_proteins.csv')\n\ntrain_peptides_df = pd.read_csv('/kaggle/input/amp-parkinsons-disease-progression-prediction/train_peptides.csv')\n\npro_pep_join = pd.merge(train_proteins_df, train_peptides_df, on=['patient_id','visit_id','visit_month','UniProt'], how='inner')\n\ndel train_proteins_df, train_peptides_df\ngc.collect()\n\ntrain_clinical_data_df = pd.read_csv('/kaggle/input/amp-parkinsons-disease-progression-prediction/train_clinical_data.csv')\n\nmerged_data = pd.merge(pro_pep_join, train_clinical_data_df, on=['patient_id','visit_id','visit_month'], how='inner')\n\ndel pro_pep_join, train_clinical_data_df\ngc.collect()\n\nfull_training_data = pd.DataFrame()\n\nfor i in [0,6,12,24]:\n    temp = merged_data[merged_data['visit_month']==i]\n    full_training_data = full_training_data.append(temp)\n    \nfull_training_data = full_training_data.drop(columns=['UniProt','Peptide','upd23b_clinical_state_on_medication','patient_id'])\n\nlist_of_updrs_tests = ['updrs_1','updrs_2','updrs_3','updrs_4']\n\nfor i in range(len(list_of_updrs_tests)):\n    full_training_data[list_of_updrs_tests[i]].fillna(full_training_data[list_of_updrs_tests[i]].mean().round(decimals = 0), inplace=True)\n\nnew_features = full_training_data.groupby(['visit_id','visit_month']).agg(npx_mean=('NPX', 'mean'), npx_median=('NPX', 'median')\n                                                                          , peptide_mean=('PeptideAbundance', 'mean'), peptide_median=('PeptideAbundance', 'median')\n                                                          ).reset_index(level=['visit_id','visit_month'])\n\nfull_training_data = pd.merge(full_training_data, new_features, on=['visit_id','visit_month'], how='inner')\n\n#full_training_data['NPX_standardised'] = (full_training_data['NPX'] - full_training_data['NPX'].mean())/full_training_data['NPX'].std()\n#full_training_data['Pep_standardised'] = (full_training_data['PeptideAbundance'] - full_training_data['PeptideAbundance'].mean())/full_training_data['PeptideAbundance'].std()\n\nfull_training_data = full_training_data.drop(columns=['NPX','PeptideAbundance'])\nfull_training_data = full_training_data.drop_duplicates(keep='first')\nfull_training_data = full_training_data[['visit_id','visit_month','npx_mean','npx_median','peptide_mean','peptide_median','updrs_1','updrs_2','updrs_3','updrs_4']]\n#full_training_data = full_training_data[['visit_id','visit_month','NPX_standardised','Pep_standardised','updrs_1','updrs_2','updrs_3','updrs_4']]\n\nfull_training_data = full_training_data.reset_index()\nfull_training_data.head(10)","metadata":{"execution":{"iopub.status.busy":"2023-03-27T18:30:50.009520Z","iopub.execute_input":"2023-03-27T18:30:50.009983Z","iopub.status.idle":"2023-03-27T18:30:53.485623Z","shell.execute_reply.started":"2023-03-27T18:30:50.009939Z","shell.execute_reply":"2023-03-27T18:30:53.484346Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"   index visit_id  visit_month      npx_mean  npx_median   peptide_mean  \\\n0      0     55_0            0  2.028789e+07   1221530.0  748153.907014   \n1    931   1517_0            0  1.579576e+07    897182.0  618823.150490   \n2   1833   1923_0            0  1.889800e+07   1299230.0  763459.201459   \n3   2710   2660_0            0  1.298973e+07   1078570.0  532250.381374   \n4   3620   3636_0            0  1.367422e+07    776581.0  501743.931250   \n5   4495   3863_0            0  2.279134e+07    885864.0  806928.584862   \n6   5291   4161_0            0  1.647734e+07   1067620.0  699803.391029   \n7   6191   4172_0            0  1.729472e+07    874171.0  620558.476752   \n8   7115   5027_0            0  2.281632e+07   1134880.0  764893.568584   \n9   8025   5178_0            0  1.815310e+07    998682.0  689200.799757   \n\n   peptide_median  updrs_1  updrs_2  updrs_3  updrs_4  \n0        93134.80     10.0      6.0     15.0      2.0  \n1        65253.60     11.0      6.0     25.0      5.0  \n2        92280.90      2.0      0.0      0.0      2.0  \n3        73461.05      2.0      0.0      0.0      2.0  \n4        54660.20      1.0      2.0      9.0      2.0  \n5        78719.90      8.0     13.0     36.0      4.0  \n6        77037.80      6.0      1.0      0.0      2.0  \n7        68208.05      2.0      0.0      0.0      2.0  \n8        71828.35      1.0      0.0      0.0      2.0  \n9        79225.50      9.0      1.0      3.0      2.0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>visit_id</th>\n      <th>visit_month</th>\n      <th>npx_mean</th>\n      <th>npx_median</th>\n      <th>peptide_mean</th>\n      <th>peptide_median</th>\n      <th>updrs_1</th>\n      <th>updrs_2</th>\n      <th>updrs_3</th>\n      <th>updrs_4</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>55_0</td>\n      <td>0</td>\n      <td>2.028789e+07</td>\n      <td>1221530.0</td>\n      <td>748153.907014</td>\n      <td>93134.80</td>\n      <td>10.0</td>\n      <td>6.0</td>\n      <td>15.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>931</td>\n      <td>1517_0</td>\n      <td>0</td>\n      <td>1.579576e+07</td>\n      <td>897182.0</td>\n      <td>618823.150490</td>\n      <td>65253.60</td>\n      <td>11.0</td>\n      <td>6.0</td>\n      <td>25.0</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1833</td>\n      <td>1923_0</td>\n      <td>0</td>\n      <td>1.889800e+07</td>\n      <td>1299230.0</td>\n      <td>763459.201459</td>\n      <td>92280.90</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2710</td>\n      <td>2660_0</td>\n      <td>0</td>\n      <td>1.298973e+07</td>\n      <td>1078570.0</td>\n      <td>532250.381374</td>\n      <td>73461.05</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3620</td>\n      <td>3636_0</td>\n      <td>0</td>\n      <td>1.367422e+07</td>\n      <td>776581.0</td>\n      <td>501743.931250</td>\n      <td>54660.20</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>9.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>4495</td>\n      <td>3863_0</td>\n      <td>0</td>\n      <td>2.279134e+07</td>\n      <td>885864.0</td>\n      <td>806928.584862</td>\n      <td>78719.90</td>\n      <td>8.0</td>\n      <td>13.0</td>\n      <td>36.0</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>5291</td>\n      <td>4161_0</td>\n      <td>0</td>\n      <td>1.647734e+07</td>\n      <td>1067620.0</td>\n      <td>699803.391029</td>\n      <td>77037.80</td>\n      <td>6.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>6191</td>\n      <td>4172_0</td>\n      <td>0</td>\n      <td>1.729472e+07</td>\n      <td>874171.0</td>\n      <td>620558.476752</td>\n      <td>68208.05</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>7115</td>\n      <td>5027_0</td>\n      <td>0</td>\n      <td>2.281632e+07</td>\n      <td>1134880.0</td>\n      <td>764893.568584</td>\n      <td>71828.35</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>8025</td>\n      <td>5178_0</td>\n      <td>0</td>\n      <td>1.815310e+07</td>\n      <td>998682.0</td>\n      <td>689200.799757</td>\n      <td>79225.50</td>\n      <td>9.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>2.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"#### Check for NaNs","metadata":{}},{"cell_type":"code","source":"full_training_data.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2023-03-27T15:40:47.431350Z","iopub.execute_input":"2023-03-27T15:40:47.431786Z","iopub.status.idle":"2023-03-27T15:40:47.444792Z","shell.execute_reply.started":"2023-03-27T15:40:47.431750Z","shell.execute_reply":"2023-03-27T15:40:47.442978Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"index             0\nvisit_id          0\nvisit_month       0\nnpx_mean          0\nnpx_median        0\npeptide_mean      0\npeptide_median    0\nupdrs_1           0\nupdrs_2           0\nupdrs_3           0\nupdrs_4           0\ndtype: int64"},"metadata":{}}]},{"cell_type":"markdown","source":"#### We will attempt to train one model each for each of the UPDRS tests. To do that, we will also proceed to create a train-test split on the Training dataset specific to each of the UPDRS test, to test out the accuracy of the developed models\n#### We will store all the models in a dictionary\n#### The following cells (except the declaration of the model dict) will be repeated for all UPDRS tests","metadata":{}},{"cell_type":"code","source":"\"\"\"model_dict = {}\n\nfor i in [1,2,3,4]:\n    if (i == 1) | (i == 2):\n        full_training_data['updrs_'+str(i)+'_category'] = pd.cut(full_training_data['updrs_'+str(i)],bins=[-np.inf, 15., np.inf],labels=[1,2])\n    elif i == 3:\n        full_training_data['updrs_'+str(i)+'_category'] = pd.cut(full_training_data['updrs_'+str(i)],bins=[-np.inf, 20., 40., np.inf],labels=[1,2,3])\n    else:\n        full_training_data['updrs_'+str(i)+'_category'] = pd.cut(full_training_data['updrs_'+str(i)],bins=[-np.inf, 7.5, np.inf],labels=[1,2])\n        \n    split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n    for train_index, test_index in split.split(full_training_data, full_training_data['updrs_'+str(i)+'_category']):\n        strat_train_set = full_training_data.loc[train_index]\n        strat_test_set = full_training_data.loc[test_index]\n        \n    if i == 1:\n        strat_train_set = strat_train_set.drop(columns=['updrs_1_category'])\n        strat_test_set = strat_test_set.drop(columns=['updrs_1_category'])\n    elif i == 2:\n        strat_train_set = strat_train_set.drop(columns=['updrs_1_category','updrs_2_category'])\n        strat_test_set = strat_test_set.drop(columns=['updrs_1_category','updrs_2_category'])\n    elif i == 3:\n        strat_train_set = strat_train_set.drop(columns=['updrs_1_category','updrs_2_category','updrs_3_category'])\n        strat_test_set = strat_test_set.drop(columns=['updrs_1_category','updrs_2_category','updrs_3_category'])\n    else:\n        strat_train_set = strat_train_set.drop(columns=['updrs_1_category','updrs_2_category','updrs_3_category','updrs_4_category'])\n        strat_test_set = strat_test_set.drop(columns=['updrs_1_category','updrs_2_category','updrs_3_category','updrs_4_category'])\n    \n    strat_train_set_wo_labels = strat_train_set.drop(columns=['updrs_1','updrs_2','updrs_3','updrs_4','index'])\n    strat_train_set_labels = strat_train_set['updrs_'+str(i)].copy()\n    strat_train_set_numeric = strat_train_set_wo_labels.drop(columns=['visit_id','visit_month'])\n    strat_train_set_cat = strat_train_set_wo_labels[['visit_month']]\n\n    strat_test_set_wo_labels = strat_test_set.drop(columns=['updrs_1','updrs_2','updrs_3','updrs_4','index'])\n    strat_test_set_labels = strat_test_set['updrs_'+str(i)].copy()\n    \n    numeric_pipeline = Pipeline([\n        ('standard_scaler', StandardScaler())\n    ])\n\n    numeric_attributes = list(strat_train_set_numeric)\n    categorical_attributes = list(strat_train_set_cat)\n\n    full_pipeline = ColumnTransformer([\n        ('num', numeric_pipeline, numeric_attributes),\n        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_attributes)\n    ])\n\n    strat_train_set_prepared = full_pipeline.fit_transform(strat_train_set_wo_labels)\n    print(strat_train_set_prepared.shape)\n    strat_test_set_prepared = full_pipeline.transform(strat_test_set_wo_labels)\n    print(strat_test_set_prepared.shape)\n    \n    lin_reg = LinearRegression()\n\n    model_dict['updrs_'+str(i)] = lin_reg.fit(strat_train_set_prepared, strat_train_set_labels)\n    print(model_dict)\"\"\"","metadata":{"execution":{"iopub.status.busy":"2023-03-26T05:11:20.768067Z","iopub.execute_input":"2023-03-26T05:11:20.768490Z","iopub.status.idle":"2023-03-26T05:11:20.888631Z","shell.execute_reply.started":"2023-03-26T05:11:20.768454Z","shell.execute_reply":"2023-03-26T05:11:20.887060Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"model_dict = {}\n\nfor u in list_of_updrs_tests:\n        \n    # Drop NAs\n    temp = full_training_data.dropna(subset=[u]) \n    print(u)\n    # Train data\n    #X = temp[['visit_month','npx_mean','npx_median','peptide_mean','peptide_median']]\n    X = temp[['visit_month','NPX_standardised','Pep_standardised']]\n    print(X.shape)\n    y = temp[u]\n    print(y.shape)\n    trained = LinearRegression().fit(X, y)\n    \n    # Save model\n    model_dict[u] = trained\"\"\"","metadata":{"execution":{"iopub.status.busy":"2023-03-26T13:28:07.753185Z","iopub.execute_input":"2023-03-26T13:28:07.753995Z","iopub.status.idle":"2023-03-26T13:28:08.120896Z","shell.execute_reply.started":"2023-03-26T13:28:07.753944Z","shell.execute_reply":"2023-03-26T13:28:08.119749Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"poly_model_dict = {}\n\nfor u in list_of_updrs_tests:\n        \n    # Drop NAs\n    temp = full_training_data.dropna(subset=[u]) \n    print(u)\n    # Train data\n    X = temp[['visit_month','npx_mean','npx_median','peptide_mean','peptide_median']]\n    #X = temp[['visit_month','NPX_standardised','Pep_standardised']]\n    print(X.shape)\n    y = temp[u]\n    print(y.shape)\n    poly = PolynomialFeatures(degree = 7)\n    X_poly = poly.fit_transform(X)\n    poly.fit(X_poly, y)\n    trained = LinearRegression().fit(X_poly, y)\n    \n    # Save model\n    poly_model_dict[u] = trained","metadata":{"execution":{"iopub.status.busy":"2023-03-27T18:31:00.493973Z","iopub.execute_input":"2023-03-27T18:31:00.494491Z","iopub.status.idle":"2023-03-27T18:31:01.086389Z","shell.execute_reply.started":"2023-03-27T18:31:00.494448Z","shell.execute_reply":"2023-03-27T18:31:01.084441Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"updrs_1\n(632, 5)\n(632,)\nupdrs_2\n(632, 5)\n(632,)\nupdrs_3\n(632, 5)\n(632,)\nupdrs_4\n(632, 5)\n(632,)\n","output_type":"stream"}]},{"cell_type":"code","source":"\"\"\"decision_model_dict = {}\n\nfor u in list_of_updrs_tests:\n        \n    # Drop NAs\n    temp = full_training_data.dropna(subset=[u]) \n    print(u)\n    # Train data\n    X = temp[['visit_month','npx_mean','npx_median','peptide_mean','peptide_median']]\n    print(X.shape)\n    y = temp[u]\n    print(y.shape)\n    trained = DecisionTreeRegressor().fit(X, y)\n    \n    # Save model\n    decision_model_dict[u] = trained\"\"\"","metadata":{"execution":{"iopub.status.busy":"2023-03-27T18:10:24.776985Z","iopub.execute_input":"2023-03-27T18:10:24.777465Z","iopub.status.idle":"2023-03-27T18:10:24.822656Z","shell.execute_reply.started":"2023-03-27T18:10:24.777419Z","shell.execute_reply":"2023-03-27T18:10:24.821093Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"updrs_1\n(632, 5)\n(632,)\nupdrs_2\n(632, 5)\n(632,)\nupdrs_3\n(632, 5)\n(632,)\nupdrs_4\n(632, 5)\n(632,)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"#### The commands below are for debugging only, these were used to determine the bins corresponding to the train-test split specific to UPDRS tests","metadata":{}},{"cell_type":"code","source":"def smape(y_true, y_pred):\n    smap = np.zeros(len(y_true))\n\n    num = np.abs(y_true - y_pred)\n    dem = ((np.abs(y_true) + np.abs(y_pred)) / 2)\n\n    pos_ind = dem != 0\n    smap[pos_ind] = num[pos_ind] / dem[pos_ind]\n\n    return 100 * np.mean(smap)\n\n\"\"\"train_true_all = [1,2,3,4,150,0,0,0,0]\ntrain_yhat_all = [0,0,0,0,0,0,0,0,0]\nprint('SMAPE: ',smape(np.array(train_true_all), np.round(np.array(train_yhat_all))))\nprint('SMAPE+1: ',smape(np.array(train_true_all)+1, np.round(np.array(train_yhat_all)+1)))\"\"\"","metadata":{"execution":{"iopub.status.busy":"2023-03-27T18:31:06.875255Z","iopub.execute_input":"2023-03-27T18:31:06.876052Z","iopub.status.idle":"2023-03-27T18:31:06.886614Z","shell.execute_reply.started":"2023-03-27T18:31:06.875996Z","shell.execute_reply":"2023-03-27T18:31:06.885200Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"\"train_true_all = [1,2,3,4,150,0,0,0,0]\\ntrain_yhat_all = [0,0,0,0,0,0,0,0,0]\\nprint('SMAPE: ',smape(np.array(train_true_all), np.round(np.array(train_yhat_all))))\\nprint('SMAPE+1: ',smape(np.array(train_true_all)+1, np.round(np.array(train_yhat_all)+1)))\""},"metadata":{}}]},{"cell_type":"code","source":"\"\"\"for u in list_of_updrs_tests:\n    \n    #X = full_training_data[['visit_month','npx_mean','npx_median','peptide_mean','peptide_median']]\n    X = full_training_data[['visit_month','NPX_standardised','Pep_standardised']]\n\n    y_true = full_training_data[u]\n    y_pred = np.ceil(model_dict[u].predict(X))\n    \n    print('Linear regression SMAPE + 1 for', u, ':', smape(np.array(y_true), np.array(y_pred)))\"\"\"","metadata":{"execution":{"iopub.status.busy":"2023-03-26T13:29:18.275687Z","iopub.execute_input":"2023-03-26T13:29:18.276087Z","iopub.status.idle":"2023-03-26T13:29:18.427565Z","shell.execute_reply.started":"2023-03-26T13:29:18.276036Z","shell.execute_reply":"2023-03-26T13:29:18.426261Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for u in list_of_updrs_tests:\n    \n    X = full_training_data[['visit_month','npx_mean','npx_median','peptide_mean','peptide_median']]\n    #X = full_training_data[['visit_month','NPX_standardised','Pep_standardised']]\n    poly = PolynomialFeatures(degree = 7)\n    X_poly = poly.fit_transform(X)\n    \n    y_true = full_training_data[u]\n    y_pred = np.ceil(poly_model_dict[u].predict(X_poly))\n    \n    print('Polynomial regression SMAPE + 1 for', u, ':', smape(np.array(y_true), np.array(y_pred)))","metadata":{"execution":{"iopub.status.busy":"2023-03-27T18:34:45.125923Z","iopub.execute_input":"2023-03-27T18:34:45.126398Z","iopub.status.idle":"2023-03-27T18:34:45.192311Z","shell.execute_reply.started":"2023-03-27T18:34:45.126364Z","shell.execute_reply":"2023-03-27T18:34:45.190541Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Polynomial regression SMAPE + 1 for updrs_1 : 71.77481087470822\nPolynomial regression SMAPE + 1 for updrs_2 : 90.73058467835861\nPolynomial regression SMAPE + 1 for updrs_3 : 81.75176110594164\nPolynomial regression SMAPE + 1 for updrs_4 : 70.88299025166116\n","output_type":"stream"}]},{"cell_type":"code","source":"\"\"\"for u in list_of_updrs_tests:\n    \n    X = full_training_data[['visit_month','npx_mean','npx_median','peptide_mean','peptide_median']]\n\n    y_true = full_training_data[u]\n    y_pred = np.ceil(decision_model_dict[u].predict(X))\n    \n    print('Decision Tree regression SMAPE + 1 for', u, ':', smape(np.array(y_true), np.array(y_pred)))\n    \n    mse = mean_squared_error(y_true, y_pred)\n    rmse = np.sqrt(mse)\n    print('RMSE with Decision Tree Regressor model', rmse)\"\"\"","metadata":{"execution":{"iopub.status.busy":"2023-03-27T18:10:33.260831Z","iopub.execute_input":"2023-03-27T18:10:33.261258Z","iopub.status.idle":"2023-03-27T18:10:33.282762Z","shell.execute_reply.started":"2023-03-27T18:10:33.261220Z","shell.execute_reply":"2023-03-27T18:10:33.281376Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Decision Tree regression SMAPE + 1 for updrs_1 : 0.0\nRMSE with Decision Tree Regressor model 0.0\nDecision Tree regression SMAPE + 1 for updrs_2 : 0.0\nRMSE with Decision Tree Regressor model 0.0\nDecision Tree regression SMAPE + 1 for updrs_3 : 0.0\nRMSE with Decision Tree Regressor model 0.0\nDecision Tree regression SMAPE + 1 for updrs_4 : 0.0\nRMSE with Decision Tree Regressor model 0.0\n","output_type":"stream"}]},{"cell_type":"code","source":"#full_training_data[['updrs_1','updrs_2','updrs_3','updrs_4']].hist(figsize=(20,15))","metadata":{"execution":{"iopub.status.busy":"2023-03-22T12:22:49.299064Z","iopub.execute_input":"2023-03-22T12:22:49.300575Z","iopub.status.idle":"2023-03-22T12:22:50.277328Z","shell.execute_reply.started":"2023-03-22T12:22:49.300526Z","shell.execute_reply":"2023-03-22T12:22:50.275981Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"full_training_data['updrs_2_category'] = pd.cut(full_training_data['updrs_2'],\n                                                          bins=[-np.inf, 15., np.inf],\n                                                          labels=[1,2])\n\nfull_training_data['updrs_3_category'] = pd.cut(full_training_data['updrs_3'],\n                                                          bins=[-np.inf, 20., 40., np.inf],\n                                                          labels=[1,2,3])\n\nfull_training_data['updrs_4_category'] = pd.cut(full_training_data['updrs_4'],\n                                                          bins=[-np.inf, 7.5, np.inf],\n                                                          labels=[1,2])\n\nfull_training_data['updrs_4_category'].hist()\n\nfull_training_data['updrs_4_category'].unique()\nsplit = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\nfor train_index, test_index in split.split(full_training_data, full_training_data['updrs_4_category']):\n    strat_train_set = full_training_data.loc[train_index]\n    strat_test_set = full_training_data.loc[test_index]\n    \nprint(strat_test_set['updrs_4_category'].value_counts()/len(strat_test_set))\nprint(strat_train_set['updrs_4_category'].value_counts()/len(strat_train_set))\n\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2023-03-22T11:44:02.441395Z","iopub.execute_input":"2023-03-22T11:44:02.441911Z","iopub.status.idle":"2023-03-22T11:44:02.670492Z","shell.execute_reply.started":"2023-03-22T11:44:02.441872Z","shell.execute_reply":"2023-03-22T11:44:02.668016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Testing the RMSE\n#### RMSE <= 0.75 : Very good accuracy | 0.75 < RMSE <= 1.0 : Good accuracy","metadata":{}},{"cell_type":"markdown","source":"#### First on train data (train split from the full training dataset)\n#### 2nd on test data (test split from the full training dataset)","metadata":{}},{"cell_type":"code","source":"\"\"\"train_df_predictions = lin_reg_model_updrs_4.predict(strat_train_set_prepared)\nmse = mean_squared_error(strat_train_set_labels, train_df_predictions)\nrmse = np.sqrt(mse)\nprint(rmse)\n\ntest_df_predictions = lin_reg_model_updrs_4.predict(strat_test_set_prepared)\nmse = mean_squared_error(strat_test_set_labels, test_df_predictions)\nrmse = np.sqrt(mse)\nprint(rmse)\n\nmodel_dict['updrs_4'] = lin_reg_model_updrs_4\nmodel_dict\"\"\"","metadata":{"execution":{"iopub.status.busy":"2023-03-22T11:45:29.720400Z","iopub.execute_input":"2023-03-22T11:45:29.720875Z","iopub.status.idle":"2023-03-22T11:45:29.730490Z","shell.execute_reply.started":"2023-03-22T11:45:29.720835Z","shell.execute_reply":"2023-03-22T11:45:29.728867Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### The below cell is only for debugging the function get_predictions()","metadata":{}},{"cell_type":"code","source":"def get_full_test_data(df_test, df_proteins=pd.DataFrame(), df_peptides=pd.DataFrame()):\n    \n    if  (df_proteins.shape[0] == 0) & (df_peptides.shape[0] == 0):\n        \n        print('only the test dataframe has data, proteins and peptides info absent')\n        full_test_data = df_test[['visit_id','visit_month']]\n        full_test_data['npx_mean'] = 0\n        full_test_data['npx_median'] = 0\n        full_test_data['peptide_mean'] = 0\n        full_test_data['peptide_median'] = 0\n        \n        full_test_data = full_test_data.drop_duplicates(keep='first')\n        full_test_data = full_test_data[['visit_id','visit_month','npx_mean','npx_median','peptide_mean','peptide_median']]\n\n        full_test_data = full_test_data.reset_index()\n        full_test_data = full_test_data.drop(columns=['index'])\n        return full_test_data\n    \n    elif (df_proteins.shape[0] == 0) & (df_peptides.shape[0] != 0):\n        \n        print('no proteins only peptides')\n        full_test_data = pd.DataFrame()\n        \n        df_peptides = pd.merge(df_peptides, df_test, on=['patient_id','visit_id','visit_month'], suffixes=['_left','_right'], how='outer')\n        df_peptides['PeptideAbundance'] = np.where(df_peptides['PeptideAbundance'].isna(), 0, df_peptides['PeptideAbundance'])\n\n        for i in [0,6,12,24]:\n            temp = df_peptides[df_peptides['visit_month']==i]\n            full_test_data = full_test_data.append(temp)\n        \n        del df_proteins, df_peptides\n            \n        new_features = full_test_data.groupby(['visit_id','visit_month']).agg(peptide_mean=('PeptideAbundance', 'mean'), peptide_median=('PeptideAbundance', 'median')\n                                                              ).reset_index(level=['visit_id','visit_month'])\n\n        full_test_data = pd.merge(full_test_data, new_features, on=['visit_id','visit_month'], how='inner')\n        full_test_data['npx_mean'] = 0\n        full_test_data['npx_median'] = 0\n        full_test_data = full_test_data.drop_duplicates(keep='first')\n        full_test_data = full_test_data[['visit_id','visit_month','npx_mean','npx_median','peptide_mean','peptide_median']]\n\n        full_test_data = full_test_data.reset_index()\n        full_test_data = full_test_data.drop(columns=['index'])\n        \n        return full_test_data\n            \n    elif (df_peptides.shape[0] == 0) & (df_proteins.shape[0] != 0):\n        \n        print('no peptides only proteins')\n        full_test_data = pd.DataFrame()\n        \n        df_proteins = pd.merge(df_proteins, df_test, on=['patient_id','visit_id','visit_month'], suffixes=['_left','_right'], how='outer')\n        df_proteins['NPX'] = np.where(df_proteins['NPX'].isna(), 0, df_proteins['NPX'])\n\n        for i in [0,6,12,24]:\n            temp = df_proteins[df_proteins['visit_month']==i]\n            full_test_data = full_test_data.append(temp)\n            \n        new_features = full_test_data.groupby(['visit_id','visit_month']).agg(npx_mean=('NPX', 'mean'), npx_median=('NPX', 'median')\n                                                              ).reset_index(level=['visit_id','visit_month'])\n\n        full_test_data = pd.merge(full_test_data, new_features, on=['visit_id','visit_month'], how='inner')\n        full_test_data['peptide_mean'] = 0\n        full_test_data['peptide_median'] = 0\n        full_test_data = full_test_data.drop_duplicates(keep='first')\n        full_test_data = full_test_data[['visit_id','visit_month','npx_mean','npx_median','peptide_mean','peptide_median']]\n\n        full_test_data = full_test_data.reset_index()\n        full_test_data = full_test_data.drop(columns=['index'])\n        \n        return full_test_data\n        \n    else:\n        \n        print('both proteins and peptides are present')\n        \n        pro_pep_join = pd.merge(df_proteins, df_peptides, on=['patient_id','visit_id','visit_month','UniProt'], suffixes=['_left','_right'], how='outer')\n        del df_proteins, df_peptides\n        \n        pro_pep_join_test = pd.merge(pro_pep_join, df_test, on=['patient_id','visit_id','visit_month'], suffixes=['_left','_right'], how='outer')\n        \n        pro_pep_join_test['NPX'] = np.where(pro_pep_join_test['NPX'].isna(), 0, pro_pep_join_test['NPX'])\n        pro_pep_join_test['PeptideAbundance'] = np.where(pro_pep_join_test['PeptideAbundance'].isna(), 0, pro_pep_join_test['PeptideAbundance'])\n        \n        del pro_pep_join\n        gc.collect()\n\n        full_test_data = pd.DataFrame()\n\n        for i in [0,6,12,24]:\n            temp = pro_pep_join_test[pro_pep_join_test['visit_month']==i]\n            full_test_data = full_test_data.append(temp)\n\n        new_features = full_test_data.groupby(['visit_id','visit_month']).agg(npx_mean=('NPX', 'mean'), npx_median=('NPX', 'median')\n                                                                                  , peptide_mean=('PeptideAbundance', 'mean')\n                                                                              , peptide_median=('PeptideAbundance', 'median')\n                                                                  ).reset_index(level=['visit_id','visit_month'])\n\n        full_test_data = pd.merge(full_test_data, new_features, on=['visit_id','visit_month'], how='inner')\n        full_test_data = full_test_data.drop_duplicates(keep='first')\n        full_test_data = full_test_data[['visit_id','visit_month','npx_mean','npx_median','peptide_mean','peptide_median']]\n\n        full_test_data = full_test_data.reset_index()\n        full_test_data = full_test_data.drop(columns=['index'])\n        \n        return full_test_data","metadata":{"execution":{"iopub.status.busy":"2023-03-27T18:31:18.338331Z","iopub.execute_input":"2023-03-27T18:31:18.338758Z","iopub.status.idle":"2023-03-27T18:31:18.365900Z","shell.execute_reply.started":"2023-03-27T18:31:18.338721Z","shell.execute_reply":"2023-03-27T18:31:18.364361Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"#def get_predictions(model_dict, sklearn_pipeline, df_test, df_proteins=pd.DataFrame(), df_peptides=pd.DataFrame()):\ndef get_predictions(model_dict, df_test, df_proteins=pd.DataFrame(), df_peptides=pd.DataFrame()):\n    \n    list_of_updrs_tests = ['updrs_1','updrs_2','updrs_3','updrs_4']\n    result = pd.DataFrame()\n    \n    full_test_data = get_full_test_data(df_test=df_test, df_proteins=df_proteins, df_peptides=df_peptides)\n    \n    if full_test_data.shape[0] != 0:\n        \"\"\"df_prepared = sklearn_pipeline.transform(full_test_data)\n        print(df_prepared.shape)\"\"\"\n\n        for u in list_of_updrs_tests:\n            X = full_test_data[['visit_month','npx_mean','npx_median','peptide_mean','peptide_median']]\n            ## for poly model\n            poly = PolynomialFeatures(degree = 7)\n            X_poly = poly.fit_transform(X)\n            full_test_data['result_' + str(u)] = np.ceil(model_dict[u].predict(X_poly))\n            #full_test_data['result_' + str(u)] = pd.DataFrame(model_dict[u].predict(df_prepared),columns=['rating']).round(decimals=0)\n            ## for all other models\n            #full_test_data['result_' + str(u)] = np.ceil(model_dict[u].predict(X))\n\n        for m in [0, 6, 12, 24]:\n            for u in [1, 2, 3, 4]:\n                temp = full_test_data[['visit_id', 'visit_month', 'result_updrs_' + str(u)]]\n                temp['prediction_id'] = temp['visit_id'] + '_updrs_' + str(u) + '_plus_' + str(m) + '_months'\n                \n                if u == 4:\n                    temp[\"rating\"] = 0\n                else:\n                    temp[\"rating\"] = temp[\"result_updrs_\" + str(u)]\n                \n                #temp = temp[['visit_id', 'visit_month', 'prediction_id', 'rating']]\n                temp = temp[['prediction_id', 'rating']]\n\n                result = result.append(temp)\n\n        #result.sort_values(by=['visit_id', 'visit_month'], inplace=True)\n        #result = result[['prediction_id', 'rating']]\n        #result['prediction_id'] = result['prediction_id'].astype('string') \n        #result['rating'] = result['rating'].astype('int') \n        result = result.drop_duplicates(subset=['prediction_id', 'rating'])\n        result = result.reset_index()\n        result.drop(columns=['index'], inplace=True)\n    \n    return result","metadata":{"execution":{"iopub.status.busy":"2023-03-27T18:39:48.188230Z","iopub.execute_input":"2023-03-27T18:39:48.188665Z","iopub.status.idle":"2023-03-27T18:39:48.201490Z","shell.execute_reply.started":"2023-03-27T18:39:48.188627Z","shell.execute_reply":"2023-03-27T18:39:48.200324Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"\"\"\"df_test = pd.read_csv('/kaggle/input/amp-parkinsons-disease-progression-prediction/example_test_files/test.csv')\n\ntest_proteins = pd.read_csv('/kaggle/input/amp-parkinsons-disease-progression-prediction/example_test_files/test_proteins.csv')\n#result = get_predictions(model_dict=model_dict, sklearn_pipeline=full_pipeline, df_test=df_test, df_proteins=test_proteins, df_peptides=pd.DataFrame())\n\ntest_peptides = pd.read_csv('/kaggle/input/amp-parkinsons-disease-progression-prediction/example_test_files/test_peptides.csv')\n#result = get_predictions(model_dict=model_dict, sklearn_pipeline=full_pipeline, df_test=df_test, df_proteins=pd.DataFrame(), df_peptides=test_peptides)\n\n#result = get_predictions(model_dict=model_dict, sklearn_pipeline=full_pipeline, df_test=df_test, df_proteins=test_proteins, df_peptides=test_peptides)\nresult = get_predictions(model_dict=poly_model_dict, df_test=df_test)\n\n#result = get_predictions(model_dict=model_dict, sklearn_pipeline=full_pipeline)\n\nresult\"\"\"","metadata":{"execution":{"iopub.status.busy":"2023-03-27T18:39:53.231860Z","iopub.execute_input":"2023-03-27T18:39:53.232266Z","iopub.status.idle":"2023-03-27T18:39:53.339469Z","shell.execute_reply.started":"2023-03-27T18:39:53.232232Z","shell.execute_reply":"2023-03-27T18:39:53.338588Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"only the test dataframe has data, proteins and peptides info absent\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  import sys\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  if __name__ == \"__main__\":\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:26: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:31: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:29: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","output_type":"stream"},{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"                     prediction_id  rating\n0     3342_0_updrs_1_plus_0_months     8.0\n1    50423_0_updrs_1_plus_0_months     8.0\n2     3342_6_updrs_1_plus_0_months     8.0\n3    50423_6_updrs_1_plus_0_months     8.0\n4     3342_0_updrs_2_plus_0_months     9.0\n..                             ...     ...\n59  50423_6_updrs_3_plus_24_months    23.0\n60   3342_0_updrs_4_plus_24_months     0.0\n61  50423_0_updrs_4_plus_24_months     0.0\n62   3342_6_updrs_4_plus_24_months     0.0\n63  50423_6_updrs_4_plus_24_months     0.0\n\n[64 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>prediction_id</th>\n      <th>rating</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3342_0_updrs_1_plus_0_months</td>\n      <td>8.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>50423_0_updrs_1_plus_0_months</td>\n      <td>8.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3342_6_updrs_1_plus_0_months</td>\n      <td>8.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>50423_6_updrs_1_plus_0_months</td>\n      <td>8.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3342_0_updrs_2_plus_0_months</td>\n      <td>9.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>59</th>\n      <td>50423_6_updrs_3_plus_24_months</td>\n      <td>23.0</td>\n    </tr>\n    <tr>\n      <th>60</th>\n      <td>3342_0_updrs_4_plus_24_months</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>61</th>\n      <td>50423_0_updrs_4_plus_24_months</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>62</th>\n      <td>3342_6_updrs_4_plus_24_months</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>63</th>\n      <td>50423_6_updrs_4_plus_24_months</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>64 rows Ã— 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"import amp_pd_peptide\n\nenv = amp_pd_peptide.make_env()   # initialize the environment for one run only\n\n#amp_pd_peptide.make_env.__called__ = False\n#type(env)._state = type(type(env)._state).__dict__['INIT']\n\niter_test = env.iter_test()\n\nfor (test, test_peptides, test_proteins, submission) in iter_test:\n    result = get_predictions(model_dict=poly_model_dict, df_test=test)\n    #result = get_predictions(model_dict=decision_model_dict, df_test=test, df_peptides=test_peptides)\n    #result = get_predictions(model_dict=decision_model_dict, df_test=test, df_proteins=test_proteins, df_peptides=test_peptides)\n    env.predict(result)\n    ","metadata":{"execution":{"iopub.status.busy":"2023-03-27T18:31:26.132964Z","iopub.execute_input":"2023-03-27T18:31:26.133418Z","iopub.status.idle":"2023-03-27T18:31:26.326427Z","shell.execute_reply.started":"2023-03-27T18:31:26.133373Z","shell.execute_reply":"2023-03-27T18:31:26.324576Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"This version of the API is not optimized and should not be used to estimate the runtime of your code on the hidden test set.\nonly the test dataframe has data, proteins and peptides info absent\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  import sys\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n/opt/conda/lib/python3.7/site-packages/sklearn/base.py:444: UserWarning: X has feature names, but LinearRegression was fitted without feature names\n  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_27/2627799910.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_peptides\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_proteins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubmission\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miter_test\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpoly_model_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0;31m#result = get_predictions(model_dict=decision_model_dict, df_test=test, df_peptides=test_peptides)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m#result = get_predictions(model_dict=decision_model_dict, df_test=test, df_proteins=test_proteins, df_peptides=test_peptides)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_27/3460894257.py\u001b[0m in \u001b[0;36mget_predictions\u001b[0;34m(model_dict, df_test, df_proteins, df_peptides)\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfull_test_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'visit_month'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'npx_mean'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'npx_median'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'peptide_mean'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'peptide_median'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0;31m#full_test_data['result_' + str(u)] = pd.DataFrame(model_dict[u].predict(df_prepared),columns=['rating']).round(decimals=0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0mfull_test_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'result_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m24\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    360\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \"\"\"\n\u001b[0;32m--> 362\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m     \u001b[0m_preprocess_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstaticmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_preprocess_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36m_decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    343\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"coo\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdense_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintercept_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcheck_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ensure_2d\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 585\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_n_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_check_n_features\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    399\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_features_in_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m             raise ValueError(\n\u001b[0;32m--> 401\u001b[0;31m                 \u001b[0;34mf\"X has {n_features} features, but {self.__class__.__name__} \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    402\u001b[0m                 \u001b[0;34mf\"is expecting {self.n_features_in_} features as input.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m             )\n","\u001b[0;31mValueError\u001b[0m: X has 5 features, but LinearRegression is expecting 792 features as input."],"ename":"ValueError","evalue":"X has 5 features, but LinearRegression is expecting 792 features as input.","output_type":"error"}]},{"cell_type":"code","source":"\"\"\"submission = pd.read_csv('/kaggle/working/submission.csv')\nsubmission.drop_duplicates()\"\"\"","metadata":{"execution":{"iopub.status.busy":"2023-03-27T18:15:37.477579Z","iopub.execute_input":"2023-03-27T18:15:37.478615Z","iopub.status.idle":"2023-03-27T18:15:37.498215Z","shell.execute_reply.started":"2023-03-27T18:15:37.478558Z","shell.execute_reply":"2023-03-27T18:15:37.496929Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"                     prediction_id  rating\n0    50423_0_updrs_1_plus_0_months     1.0\n1     3342_0_updrs_1_plus_0_months     1.0\n2    50423_0_updrs_2_plus_0_months     0.0\n3     3342_0_updrs_2_plus_0_months    13.0\n4    50423_0_updrs_3_plus_0_months    25.0\n..                             ...     ...\n60   3342_6_updrs_3_plus_24_months    35.0\n61  50423_6_updrs_3_plus_24_months    68.0\n62   3342_6_updrs_4_plus_24_months     2.0\n63  50423_6_updrs_4_plus_24_months     0.0\n64                   prediction_id  rating\n\n[65 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>prediction_id</th>\n      <th>rating</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>50423_0_updrs_1_plus_0_months</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3342_0_updrs_1_plus_0_months</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>50423_0_updrs_2_plus_0_months</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3342_0_updrs_2_plus_0_months</td>\n      <td>13.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>50423_0_updrs_3_plus_0_months</td>\n      <td>25.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>60</th>\n      <td>3342_6_updrs_3_plus_24_months</td>\n      <td>35.0</td>\n    </tr>\n    <tr>\n      <th>61</th>\n      <td>50423_6_updrs_3_plus_24_months</td>\n      <td>68.0</td>\n    </tr>\n    <tr>\n      <th>62</th>\n      <td>3342_6_updrs_4_plus_24_months</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>63</th>\n      <td>50423_6_updrs_4_plus_24_months</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>64</th>\n      <td>prediction_id</td>\n      <td>rating</td>\n    </tr>\n  </tbody>\n</table>\n<p>65 rows Ã— 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"\"\"\"import amp_pd_peptide\nenv = amp_pd_peptide.make_env()\n\namp_pd_peptide.make_env.__called__ = False\ntype(env)._state = type(type(env)._state).__dict__['INIT'] # initialize the environment for multiple runs\niter_test = env.iter_test()\n\nfor (test, test_peptides, test_proteins, submission) in iter_test:\n    result = get_predictions(model_dict=decision_model_dict, df_test=test, df_proteins=test_proteins, df_peptides=test_peptides)\n    env.predict(result)\"\"\"","metadata":{"execution":{"iopub.status.busy":"2023-03-26T12:46:06.373392Z","iopub.execute_input":"2023-03-26T12:46:06.373894Z","iopub.status.idle":"2023-03-26T12:46:07.125058Z","shell.execute_reply.started":"2023-03-26T12:46:06.373850Z","shell.execute_reply":"2023-03-26T12:46:07.123605Z"},"trusted":true},"execution_count":null,"outputs":[]}]}